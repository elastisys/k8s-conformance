I0527 05:16:49.881153      15 e2e.go:129] Starting e2e run "aec79d35-0b81-4f72-859e-66637ea7da42" on Ginkgo node 1
{"msg":"Test Suite starting","total":356,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1653628609 - Will randomize all specs
Will run 356 of 6965 specs

May 27 05:16:52.710: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:16:52.718: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 27 05:16:52.795: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 27 05:16:52.843: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 27 05:16:52.843: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
May 27 05:16:52.843: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 27 05:16:52.856: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cilium' (0 seconds elapsed)
May 27 05:16:52.856: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cilium-node-init' (0 seconds elapsed)
May 27 05:16:52.856: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May 27 05:16:52.856: INFO: e2e test version: v1.24.1
May 27 05:16:52.858: INFO: kube-apiserver version: v1.24.1
May 27 05:16:52.859: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:16:52.866: INFO: Cluster IP family: ipv4
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:16:52.866: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
May 27 05:16:52.915: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
W0527 05:16:52.915062      15 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-4057e18a-373a-4268-926a-68c5bacf8c3d
STEP: Creating a pod to test consume configMaps
May 27 05:16:52.947: INFO: Waiting up to 5m0s for pod "pod-configmaps-1d25404a-9b36-4a46-8a18-decf7dde02de" in namespace "configmap-7061" to be "Succeeded or Failed"
May 27 05:16:52.953: INFO: Pod "pod-configmaps-1d25404a-9b36-4a46-8a18-decf7dde02de": Phase="Pending", Reason="", readiness=false. Elapsed: 6.155564ms
May 27 05:16:54.985: INFO: Pod "pod-configmaps-1d25404a-9b36-4a46-8a18-decf7dde02de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037929561s
May 27 05:16:57.006: INFO: Pod "pod-configmaps-1d25404a-9b36-4a46-8a18-decf7dde02de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058371037s
May 27 05:16:59.018: INFO: Pod "pod-configmaps-1d25404a-9b36-4a46-8a18-decf7dde02de": Phase="Pending", Reason="", readiness=false. Elapsed: 6.071198471s
May 27 05:17:01.035: INFO: Pod "pod-configmaps-1d25404a-9b36-4a46-8a18-decf7dde02de": Phase="Pending", Reason="", readiness=false. Elapsed: 8.088222727s
May 27 05:17:03.058: INFO: Pod "pod-configmaps-1d25404a-9b36-4a46-8a18-decf7dde02de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.111147666s
STEP: Saw pod success
May 27 05:17:03.058: INFO: Pod "pod-configmaps-1d25404a-9b36-4a46-8a18-decf7dde02de" satisfied condition "Succeeded or Failed"
May 27 05:17:03.070: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-configmaps-1d25404a-9b36-4a46-8a18-decf7dde02de container agnhost-container: <nil>
STEP: delete the pod
May 27 05:17:03.154: INFO: Waiting for pod pod-configmaps-1d25404a-9b36-4a46-8a18-decf7dde02de to disappear
May 27 05:17:03.162: INFO: Pod pod-configmaps-1d25404a-9b36-4a46-8a18-decf7dde02de no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
May 27 05:17:03.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7061" for this suite.

• [SLOW TEST:10.339 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":1,"skipped":5,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:17:03.221: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
May 27 05:17:17.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2379" for this suite.

• [SLOW TEST:14.128 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":356,"completed":2,"skipped":29,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:17:17.350: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
May 27 05:17:17.426: INFO: The status of Pod annotationupdate1ccd05fd-4d8f-40f9-a0a2-c6de7468dce7 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:17:19.441: INFO: The status of Pod annotationupdate1ccd05fd-4d8f-40f9-a0a2-c6de7468dce7 is Running (Ready = true)
May 27 05:17:19.993: INFO: Successfully updated pod "annotationupdate1ccd05fd-4d8f-40f9-a0a2-c6de7468dce7"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
May 27 05:17:24.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2267" for this suite.

• [SLOW TEST:6.727 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":3,"skipped":43,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity 
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:17:24.078: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename csistoragecapacity
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/storage.k8s.io
STEP: getting /apis/storage.k8s.io/v1
STEP: creating
STEP: watching
May 27 05:17:24.221: INFO: starting watch
STEP: getting
STEP: listing in namespace
STEP: listing across namespaces
STEP: patching
STEP: updating
May 27 05:17:24.281: INFO: waiting for watch events with expected annotations in namespace
May 27 05:17:24.281: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:188
May 27 05:17:24.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-8319" for this suite.
•{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","total":356,"completed":4,"skipped":73,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:17:24.359: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
May 27 05:17:24.418: INFO: Waiting up to 5m0s for pod "pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df" in namespace "emptydir-5073" to be "Succeeded or Failed"
May 27 05:17:24.442: INFO: Pod "pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df": Phase="Pending", Reason="", readiness=false. Elapsed: 23.877095ms
May 27 05:17:26.456: INFO: Pod "pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038346472s
May 27 05:17:28.472: INFO: Pod "pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df": Phase="Pending", Reason="", readiness=false. Elapsed: 4.053587875s
May 27 05:17:30.515: INFO: Pod "pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df": Phase="Pending", Reason="", readiness=false. Elapsed: 6.096724383s
May 27 05:17:32.536: INFO: Pod "pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df": Phase="Pending", Reason="", readiness=false. Elapsed: 8.118191248s
May 27 05:17:34.554: INFO: Pod "pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df": Phase="Pending", Reason="", readiness=false. Elapsed: 10.136196338s
May 27 05:17:36.590: INFO: Pod "pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df": Phase="Pending", Reason="", readiness=false. Elapsed: 12.172468674s
May 27 05:17:38.612: INFO: Pod "pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df": Phase="Pending", Reason="", readiness=false. Elapsed: 14.193763515s
May 27 05:17:40.627: INFO: Pod "pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.209147968s
STEP: Saw pod success
May 27 05:17:40.627: INFO: Pod "pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df" satisfied condition "Succeeded or Failed"
May 27 05:17:40.633: INFO: Trying to get logs from node bohc9zohd7ee-2 pod pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df container test-container: <nil>
STEP: delete the pod
May 27 05:17:40.693: INFO: Waiting for pod pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df to disappear
May 27 05:17:40.706: INFO: Pod pod-a1e6bc23-3093-4a18-87c1-65aa7f7a37df no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 05:17:40.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5073" for this suite.

• [SLOW TEST:16.373 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":5,"skipped":76,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:17:40.733: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 05:17:40.812: INFO: Waiting up to 5m0s for pod "downwardapi-volume-443bfefb-c30e-4fd4-b3ad-499dbf6b8be0" in namespace "downward-api-3956" to be "Succeeded or Failed"
May 27 05:17:40.818: INFO: Pod "downwardapi-volume-443bfefb-c30e-4fd4-b3ad-499dbf6b8be0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.289726ms
May 27 05:17:42.836: INFO: Pod "downwardapi-volume-443bfefb-c30e-4fd4-b3ad-499dbf6b8be0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023766511s
May 27 05:17:44.850: INFO: Pod "downwardapi-volume-443bfefb-c30e-4fd4-b3ad-499dbf6b8be0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038049134s
May 27 05:17:46.864: INFO: Pod "downwardapi-volume-443bfefb-c30e-4fd4-b3ad-499dbf6b8be0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.051597427s
STEP: Saw pod success
May 27 05:17:46.864: INFO: Pod "downwardapi-volume-443bfefb-c30e-4fd4-b3ad-499dbf6b8be0" satisfied condition "Succeeded or Failed"
May 27 05:17:46.869: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-443bfefb-c30e-4fd4-b3ad-499dbf6b8be0 container client-container: <nil>
STEP: delete the pod
May 27 05:17:46.914: INFO: Waiting for pod downwardapi-volume-443bfefb-c30e-4fd4-b3ad-499dbf6b8be0 to disappear
May 27 05:17:46.921: INFO: Pod downwardapi-volume-443bfefb-c30e-4fd4-b3ad-499dbf6b8be0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
May 27 05:17:46.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3956" for this suite.

• [SLOW TEST:6.220 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":6,"skipped":123,"failed":0}
[sig-network] Ingress API 
  should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:17:46.954: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename ingress
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
May 27 05:17:47.074: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
May 27 05:17:47.082: INFO: starting watch
STEP: patching
STEP: updating
May 27 05:17:47.108: INFO: waiting for watch events with expected annotations
May 27 05:17:47.109: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:188
May 27 05:17:47.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-1856" for this suite.
•{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":356,"completed":7,"skipped":123,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:17:47.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with configMap that has name projected-configmap-test-upd-52eeea82-73cd-4ecb-9e7e-dd147a373acd
STEP: Creating the pod
May 27 05:17:47.355: INFO: The status of Pod pod-projected-configmaps-335aa5e1-ac31-4457-932e-f178fe21c4a1 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:17:49.369: INFO: The status of Pod pod-projected-configmaps-335aa5e1-ac31-4457-932e-f178fe21c4a1 is Running (Ready = true)
STEP: Updating configmap projected-configmap-test-upd-52eeea82-73cd-4ecb-9e7e-dd147a373acd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
May 27 05:17:51.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2885" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":8,"skipped":147,"failed":0}
SSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:17:51.478: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
May 27 05:17:51.577: INFO: Waiting up to 1m0s for all nodes to be ready
May 27 05:18:51.639: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
May 27 05:18:51.704: INFO: Created pod: pod0-0-sched-preemption-low-priority
May 27 05:18:51.715: INFO: Created pod: pod0-1-sched-preemption-medium-priority
May 27 05:18:51.749: INFO: Created pod: pod1-0-sched-preemption-medium-priority
May 27 05:18:51.758: INFO: Created pod: pod1-1-sched-preemption-medium-priority
May 27 05:18:51.794: INFO: Created pod: pod2-0-sched-preemption-medium-priority
May 27 05:18:51.810: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a critical pod that use same resources as that of a lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
May 27 05:19:22.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8742" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:90.689 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","total":356,"completed":9,"skipped":150,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:19:22.171: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-6067
May 27 05:19:22.231: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May 27 05:19:24.246: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May 27 05:19:26.249: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May 27 05:19:28.309: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May 27 05:19:30.248: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May 27 05:19:32.252: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May 27 05:19:34.243: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May 27 05:19:36.245: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May 27 05:19:38.245: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May 27 05:19:40.245: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
May 27 05:19:40.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-6067 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
May 27 05:19:40.746: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
May 27 05:19:40.746: INFO: stdout: "iptables"
May 27 05:19:40.746: INFO: proxyMode: iptables
May 27 05:19:40.795: INFO: Waiting for pod kube-proxy-mode-detector to disappear
May 27 05:19:40.801: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-6067
STEP: creating replication controller affinity-nodeport-timeout in namespace services-6067
I0527 05:19:40.858021      15 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-6067, replica count: 3
I0527 05:19:43.908974      15 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 27 05:19:43.938: INFO: Creating new exec pod
May 27 05:19:46.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-6067 exec execpod-affinityfdlz9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
May 27 05:19:47.259: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
May 27 05:19:47.259: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:19:47.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-6067 exec execpod-affinityfdlz9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.51.43 80'
May 27 05:19:47.485: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.51.43 80\nConnection to 10.233.51.43 80 port [tcp/http] succeeded!\n"
May 27 05:19:47.485: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:19:47.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-6067 exec execpod-affinityfdlz9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.117 30458'
May 27 05:19:47.732: INFO: stderr: "+ nc -v -t -w 2 192.168.121.117 30458\n+ echo hostName\nConnection to 192.168.121.117 30458 port [tcp/*] succeeded!\n"
May 27 05:19:47.732: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:19:47.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-6067 exec execpod-affinityfdlz9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.180 30458'
May 27 05:19:47.952: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.180 30458\nConnection to 192.168.121.180 30458 port [tcp/*] succeeded!\n"
May 27 05:19:47.953: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:19:47.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-6067 exec execpod-affinityfdlz9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.180:30458/ ; done'
May 27 05:19:48.411: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n"
May 27 05:19:48.411: INFO: stdout: "\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq\naffinity-nodeport-timeout-2frlq"
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.411: INFO: Received response from host: affinity-nodeport-timeout-2frlq
May 27 05:19:48.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-6067 exec execpod-affinityfdlz9 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.121.180:30458/'
May 27 05:19:48.635: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n"
May 27 05:19:48.635: INFO: stdout: "affinity-nodeport-timeout-2frlq"
May 27 05:20:08.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-6067 exec execpod-affinityfdlz9 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.121.180:30458/'
May 27 05:20:08.874: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.121.180:30458/\n"
May 27 05:20:08.874: INFO: stdout: "affinity-nodeport-timeout-5xhkm"
May 27 05:20:08.874: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-6067, will wait for the garbage collector to delete the pods
May 27 05:20:09.012: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 19.432875ms
May 27 05:20:09.112: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.361175ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 05:20:11.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6067" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:49.638 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":10,"skipped":207,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:20:11.813: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 27 05:20:11.870: INFO: Waiting up to 5m0s for pod "pod-3e37b57c-c99f-477e-8f64-5f0e5e4814e9" in namespace "emptydir-9950" to be "Succeeded or Failed"
May 27 05:20:11.874: INFO: Pod "pod-3e37b57c-c99f-477e-8f64-5f0e5e4814e9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.164707ms
May 27 05:20:13.892: INFO: Pod "pod-3e37b57c-c99f-477e-8f64-5f0e5e4814e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022040779s
May 27 05:20:15.902: INFO: Pod "pod-3e37b57c-c99f-477e-8f64-5f0e5e4814e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031490954s
STEP: Saw pod success
May 27 05:20:15.902: INFO: Pod "pod-3e37b57c-c99f-477e-8f64-5f0e5e4814e9" satisfied condition "Succeeded or Failed"
May 27 05:20:15.909: INFO: Trying to get logs from node bohc9zohd7ee-1 pod pod-3e37b57c-c99f-477e-8f64-5f0e5e4814e9 container test-container: <nil>
STEP: delete the pod
May 27 05:20:15.984: INFO: Waiting for pod pod-3e37b57c-c99f-477e-8f64-5f0e5e4814e9 to disappear
May 27 05:20:15.990: INFO: Pod pod-3e37b57c-c99f-477e-8f64-5f0e5e4814e9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 05:20:15.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9950" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":11,"skipped":226,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:20:16.016: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
May 27 05:20:16.209: INFO: Waiting up to 5m0s for pod "pod-8591d897-906f-4720-9c6c-97df399643ca" in namespace "emptydir-7611" to be "Succeeded or Failed"
May 27 05:20:16.226: INFO: Pod "pod-8591d897-906f-4720-9c6c-97df399643ca": Phase="Pending", Reason="", readiness=false. Elapsed: 17.431714ms
May 27 05:20:18.247: INFO: Pod "pod-8591d897-906f-4720-9c6c-97df399643ca": Phase="Running", Reason="", readiness=true. Elapsed: 2.037660353s
May 27 05:20:20.262: INFO: Pod "pod-8591d897-906f-4720-9c6c-97df399643ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053025632s
STEP: Saw pod success
May 27 05:20:20.262: INFO: Pod "pod-8591d897-906f-4720-9c6c-97df399643ca" satisfied condition "Succeeded or Failed"
May 27 05:20:20.268: INFO: Trying to get logs from node bohc9zohd7ee-1 pod pod-8591d897-906f-4720-9c6c-97df399643ca container test-container: <nil>
STEP: delete the pod
May 27 05:20:20.309: INFO: Waiting for pod pod-8591d897-906f-4720-9c6c-97df399643ca to disappear
May 27 05:20:20.314: INFO: Pod pod-8591d897-906f-4720-9c6c-97df399643ca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 05:20:20.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7611" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":12,"skipped":274,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:20:20.340: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-575
STEP: creating service affinity-nodeport in namespace services-575
STEP: creating replication controller affinity-nodeport in namespace services-575
I0527 05:20:20.436382      15 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-575, replica count: 3
I0527 05:20:23.487869      15 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 27 05:20:23.524: INFO: Creating new exec pod
May 27 05:20:28.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-575 exec execpod-affinity9jnff -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
May 27 05:20:28.931: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
May 27 05:20:28.931: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:20:28.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-575 exec execpod-affinity9jnff -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.22.212 80'
May 27 05:20:29.181: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.22.212 80\nConnection to 10.233.22.212 80 port [tcp/http] succeeded!\n"
May 27 05:20:29.181: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:20:29.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-575 exec execpod-affinity9jnff -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.180 31870'
May 27 05:20:29.449: INFO: stderr: "+ + echonc hostName\n -v -t -w 2 192.168.121.180 31870\nConnection to 192.168.121.180 31870 port [tcp/*] succeeded!\n"
May 27 05:20:29.449: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:20:29.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-575 exec execpod-affinity9jnff -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.16 31870'
May 27 05:20:29.706: INFO: stderr: "+ + nc -v -t -w 2 192.168.121.16 31870\necho hostName\nConnection to 192.168.121.16 31870 port [tcp/*] succeeded!\n"
May 27 05:20:29.706: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:20:29.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-575 exec execpod-affinity9jnff -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.180:31870/ ; done'
May 27 05:20:30.178: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:31870/\n"
May 27 05:20:30.179: INFO: stdout: "\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl\naffinity-nodeport-8wqcl"
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Received response from host: affinity-nodeport-8wqcl
May 27 05:20:30.179: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-575, will wait for the garbage collector to delete the pods
May 27 05:20:30.285: INFO: Deleting ReplicationController affinity-nodeport took: 15.950373ms
May 27 05:20:30.486: INFO: Terminating ReplicationController affinity-nodeport pods took: 201.530846ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 05:20:32.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-575" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:12.627 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":13,"skipped":296,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:20:32.967: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
May 27 05:20:47.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9108" for this suite.
STEP: Destroying namespace "nsdeletetest-8097" for this suite.
May 27 05:20:47.191: INFO: Namespace nsdeletetest-8097 was already deleted
STEP: Destroying namespace "nsdeletetest-464" for this suite.

• [SLOW TEST:14.242 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":356,"completed":14,"skipped":317,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:20:47.211: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption is created
May 27 05:20:47.298: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
May 27 05:20:49.314: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
May 27 05:20:51.315: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
May 27 05:20:53.311: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
May 27 05:20:55.315: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
May 27 05:20:57.314: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
May 27 05:20:59.312: INFO: The status of Pod pod-adoption is Running (Ready = true)
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
May 27 05:21:00.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1138" for this suite.

• [SLOW TEST:13.165 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":356,"completed":15,"skipped":334,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:21:00.382: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:21:00.449: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 27 05:21:00.467: INFO: Pod name sample-pod: Found 0 pods out of 1
May 27 05:21:05.508: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 27 05:21:13.533: INFO: Creating deployment "test-rolling-update-deployment"
May 27 05:21:13.547: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 27 05:21:13.572: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 27 05:21:15.595: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 27 05:21:15.602: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May 27 05:21:15.634: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-6544  6d57e62f-0311-4b4b-8eb9-c813a701e3ec 4605 1 2022-05-27 05:21:13 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2022-05-27 05:21:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:21:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.36 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002745d48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-05-27 05:21:13 +0000 UTC,LastTransitionTime:2022-05-27 05:21:13 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-5579c56cf8" has successfully progressed.,LastUpdateTime:2022-05-27 05:21:14 +0000 UTC,LastTransitionTime:2022-05-27 05:21:13 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May 27 05:21:15.645: INFO: New ReplicaSet "test-rolling-update-deployment-5579c56cf8" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-5579c56cf8  deployment-6544  5c4a166f-f5f2-49d6-bef5-95a41ae5df2e 4595 1 2022-05-27 05:21:13 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5579c56cf8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 6d57e62f-0311-4b4b-8eb9-c813a701e3ec 0xc00297c1f7 0xc00297c1f8}] []  [{kube-controller-manager Update apps/v1 2022-05-27 05:21:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6d57e62f-0311-4b4b-8eb9-c813a701e3ec\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:21:14 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 5579c56cf8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5579c56cf8] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.36 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00297c2a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May 27 05:21:15.645: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 27 05:21:15.645: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-6544  566232b2-95f4-4fcd-8327-0c6994b147ef 4603 2 2022-05-27 05:21:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 6d57e62f-0311-4b4b-8eb9-c813a701e3ec 0xc00297c0d7 0xc00297c0d8}] []  [{e2e.test Update apps/v1 2022-05-27 05:21:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:21:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6d57e62f-0311-4b4b-8eb9-c813a701e3ec\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:21:14 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00297c198 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 27 05:21:15.654: INFO: Pod "test-rolling-update-deployment-5579c56cf8-57kjz" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-5579c56cf8-57kjz test-rolling-update-deployment-5579c56cf8- deployment-6544  a8371827-5c81-43d8-8d2e-15688b383fe5 4594 0 2022-05-27 05:21:13 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5579c56cf8] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-5579c56cf8 5c4a166f-f5f2-49d6-bef5-95a41ae5df2e 0xc002863037 0xc002863038}] []  [{kube-controller-manager Update v1 2022-05-27 05:21:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5c4a166f-f5f2-49d6-bef5-95a41ae5df2e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:21:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.71\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6p9rv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.36,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6p9rv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:21:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:21:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:21:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:21:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.16,PodIP:10.233.65.71,StartTime:2022-05-27 05:21:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 05:21:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.36,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:c8cf9027e6db0e7de9b172400b209da8fe7aac863d19352723d2457847457403,ContainerID:cri-o://5fcd57cbebbfe0cba7d03cd377b82297cae749c70382b3295fb7947124041571,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.71,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
May 27 05:21:15.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6544" for this suite.

• [SLOW TEST:15.305 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":16,"skipped":346,"failed":0}
S
------------------------------
[sig-auth] ServiceAccounts 
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:21:15.686: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:21:15.740: INFO: Got root ca configmap in namespace "svcaccounts-3727"
May 27 05:21:15.750: INFO: Deleted root ca configmap in namespace "svcaccounts-3727"
STEP: waiting for a new root ca configmap created
May 27 05:21:16.260: INFO: Recreated root ca configmap in namespace "svcaccounts-3727"
May 27 05:21:16.270: INFO: Updated root ca configmap in namespace "svcaccounts-3727"
STEP: waiting for the root ca configmap reconciled
May 27 05:21:16.781: INFO: Reconciled root ca configmap in namespace "svcaccounts-3727"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
May 27 05:21:16.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3727" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","total":356,"completed":17,"skipped":347,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:21:16.808: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-08e4e13c-7683-412c-8649-e42b82aa9126
STEP: Creating a pod to test consume secrets
May 27 05:21:16.881: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b48e864b-5a66-431d-8790-bd30e08c6784" in namespace "projected-8280" to be "Succeeded or Failed"
May 27 05:21:16.890: INFO: Pod "pod-projected-secrets-b48e864b-5a66-431d-8790-bd30e08c6784": Phase="Pending", Reason="", readiness=false. Elapsed: 9.378307ms
May 27 05:21:18.905: INFO: Pod "pod-projected-secrets-b48e864b-5a66-431d-8790-bd30e08c6784": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024520911s
May 27 05:21:20.923: INFO: Pod "pod-projected-secrets-b48e864b-5a66-431d-8790-bd30e08c6784": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042739044s
May 27 05:21:22.941: INFO: Pod "pod-projected-secrets-b48e864b-5a66-431d-8790-bd30e08c6784": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.060145834s
STEP: Saw pod success
May 27 05:21:22.941: INFO: Pod "pod-projected-secrets-b48e864b-5a66-431d-8790-bd30e08c6784" satisfied condition "Succeeded or Failed"
May 27 05:21:22.948: INFO: Trying to get logs from node bohc9zohd7ee-1 pod pod-projected-secrets-b48e864b-5a66-431d-8790-bd30e08c6784 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 27 05:21:22.986: INFO: Waiting for pod pod-projected-secrets-b48e864b-5a66-431d-8790-bd30e08c6784 to disappear
May 27 05:21:22.994: INFO: Pod pod-projected-secrets-b48e864b-5a66-431d-8790-bd30e08c6784 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
May 27 05:21:22.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8280" for this suite.

• [SLOW TEST:6.211 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":18,"skipped":354,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:21:23.029: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:21:23.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-538" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":356,"completed":19,"skipped":400,"failed":0}
SSSSSS
------------------------------
[sig-apps] DisruptionController 
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:21:23.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Updating PodDisruptionBudget status
STEP: Waiting for all pods to be running
May 27 05:21:25.261: INFO: running pods: 0 < 1
STEP: locating a running pod
STEP: Waiting for the pdb to be processed
STEP: Patching PodDisruptionBudget status
STEP: Waiting for the pdb to be processed
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
May 27 05:21:27.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5733" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","total":356,"completed":20,"skipped":406,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:21:27.367: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
May 27 05:21:43.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5620" for this suite.

• [SLOW TEST:16.317 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":356,"completed":21,"skipped":421,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:21:43.686: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override command
May 27 05:21:43.767: INFO: Waiting up to 5m0s for pod "client-containers-1cd87630-d20b-4aec-aea0-3949fa4b6184" in namespace "containers-685" to be "Succeeded or Failed"
May 27 05:21:43.776: INFO: Pod "client-containers-1cd87630-d20b-4aec-aea0-3949fa4b6184": Phase="Pending", Reason="", readiness=false. Elapsed: 9.685126ms
May 27 05:21:45.794: INFO: Pod "client-containers-1cd87630-d20b-4aec-aea0-3949fa4b6184": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027702407s
May 27 05:21:47.807: INFO: Pod "client-containers-1cd87630-d20b-4aec-aea0-3949fa4b6184": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040114738s
STEP: Saw pod success
May 27 05:21:47.807: INFO: Pod "client-containers-1cd87630-d20b-4aec-aea0-3949fa4b6184" satisfied condition "Succeeded or Failed"
May 27 05:21:47.816: INFO: Trying to get logs from node bohc9zohd7ee-3 pod client-containers-1cd87630-d20b-4aec-aea0-3949fa4b6184 container agnhost-container: <nil>
STEP: delete the pod
May 27 05:21:47.883: INFO: Waiting for pod client-containers-1cd87630-d20b-4aec-aea0-3949fa4b6184 to disappear
May 27 05:21:47.892: INFO: Pod client-containers-1cd87630-d20b-4aec-aea0-3949fa4b6184 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
May 27 05:21:47.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-685" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","total":356,"completed":22,"skipped":430,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:21:47.924: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating secret secrets-749/secret-test-305b923a-1109-4013-9de0-38ac590409da
STEP: Creating a pod to test consume secrets
May 27 05:21:48.007: INFO: Waiting up to 5m0s for pod "pod-configmaps-c2f868f0-5224-43fe-8bcf-68d25123eb9d" in namespace "secrets-749" to be "Succeeded or Failed"
May 27 05:21:48.016: INFO: Pod "pod-configmaps-c2f868f0-5224-43fe-8bcf-68d25123eb9d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.456091ms
May 27 05:21:50.048: INFO: Pod "pod-configmaps-c2f868f0-5224-43fe-8bcf-68d25123eb9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040622329s
May 27 05:21:52.062: INFO: Pod "pod-configmaps-c2f868f0-5224-43fe-8bcf-68d25123eb9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054971271s
STEP: Saw pod success
May 27 05:21:52.062: INFO: Pod "pod-configmaps-c2f868f0-5224-43fe-8bcf-68d25123eb9d" satisfied condition "Succeeded or Failed"
May 27 05:21:52.068: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-configmaps-c2f868f0-5224-43fe-8bcf-68d25123eb9d container env-test: <nil>
STEP: delete the pod
May 27 05:21:52.247: INFO: Waiting for pod pod-configmaps-c2f868f0-5224-43fe-8bcf-68d25123eb9d to disappear
May 27 05:21:52.255: INFO: Pod pod-configmaps-c2f868f0-5224-43fe-8bcf-68d25123eb9d no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
May 27 05:21:52.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-749" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":23,"skipped":444,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:21:52.288: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 27 05:21:52.873: INFO: Pod name wrapped-volume-race-394bfeff-9581-4848-ae63-e1ca073cc089: Found 0 pods out of 5
May 27 05:21:57.892: INFO: Pod name wrapped-volume-race-394bfeff-9581-4848-ae63-e1ca073cc089: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-394bfeff-9581-4848-ae63-e1ca073cc089 in namespace emptydir-wrapper-3688, will wait for the garbage collector to delete the pods
May 27 05:22:10.037: INFO: Deleting ReplicationController wrapped-volume-race-394bfeff-9581-4848-ae63-e1ca073cc089 took: 24.979087ms
May 27 05:22:10.238: INFO: Terminating ReplicationController wrapped-volume-race-394bfeff-9581-4848-ae63-e1ca073cc089 pods took: 200.950739ms
STEP: Creating RC which spawns configmap-volume pods
May 27 05:22:12.485: INFO: Pod name wrapped-volume-race-71ee79f3-ec1a-40ad-845c-23f72c00b0b7: Found 0 pods out of 5
May 27 05:22:17.508: INFO: Pod name wrapped-volume-race-71ee79f3-ec1a-40ad-845c-23f72c00b0b7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-71ee79f3-ec1a-40ad-845c-23f72c00b0b7 in namespace emptydir-wrapper-3688, will wait for the garbage collector to delete the pods
May 27 05:22:27.658: INFO: Deleting ReplicationController wrapped-volume-race-71ee79f3-ec1a-40ad-845c-23f72c00b0b7 took: 30.574708ms
May 27 05:22:27.859: INFO: Terminating ReplicationController wrapped-volume-race-71ee79f3-ec1a-40ad-845c-23f72c00b0b7 pods took: 200.981382ms
STEP: Creating RC which spawns configmap-volume pods
May 27 05:22:31.115: INFO: Pod name wrapped-volume-race-4d4fe990-6d57-4164-b801-aa77b7dec456: Found 0 pods out of 5
May 27 05:22:36.178: INFO: Pod name wrapped-volume-race-4d4fe990-6d57-4164-b801-aa77b7dec456: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4d4fe990-6d57-4164-b801-aa77b7dec456 in namespace emptydir-wrapper-3688, will wait for the garbage collector to delete the pods
May 27 05:22:48.319: INFO: Deleting ReplicationController wrapped-volume-race-4d4fe990-6d57-4164-b801-aa77b7dec456 took: 15.342224ms
May 27 05:22:48.520: INFO: Terminating ReplicationController wrapped-volume-race-4d4fe990-6d57-4164-b801-aa77b7dec456 pods took: 200.547536ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
May 27 05:22:51.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3688" for this suite.

• [SLOW TEST:59.683 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":356,"completed":24,"skipped":457,"failed":0}
S
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:22:51.971: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:58
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod test-webserver-e4cc7039-72d4-4acd-bf72-babbd910a1a2 in namespace container-probe-3286
May 27 05:22:54.095: INFO: Started pod test-webserver-e4cc7039-72d4-4acd-bf72-babbd910a1a2 in namespace container-probe-3286
STEP: checking the pod's current state and verifying that restartCount is present
May 27 05:22:54.106: INFO: Initial restart count of pod test-webserver-e4cc7039-72d4-4acd-bf72-babbd910a1a2 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
May 27 05:26:56.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3286" for this suite.

• [SLOW TEST:244.263 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":25,"skipped":458,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:26:56.236: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:26:56.353: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-531e10bb-d984-4b76-9362-d735ab0a9f67" in namespace "security-context-test-9678" to be "Succeeded or Failed"
May 27 05:26:56.368: INFO: Pod "busybox-readonly-false-531e10bb-d984-4b76-9362-d735ab0a9f67": Phase="Pending", Reason="", readiness=false. Elapsed: 14.625358ms
May 27 05:26:58.381: INFO: Pod "busybox-readonly-false-531e10bb-d984-4b76-9362-d735ab0a9f67": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028328065s
May 27 05:27:00.391: INFO: Pod "busybox-readonly-false-531e10bb-d984-4b76-9362-d735ab0a9f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038070483s
May 27 05:27:00.391: INFO: Pod "busybox-readonly-false-531e10bb-d984-4b76-9362-d735ab0a9f67" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
May 27 05:27:00.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9678" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":356,"completed":26,"skipped":477,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:27:00.418: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pod templates
May 27 05:27:00.484: INFO: created test-podtemplate-1
May 27 05:27:00.498: INFO: created test-podtemplate-2
May 27 05:27:00.508: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
May 27 05:27:00.514: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
May 27 05:27:00.539: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
May 27 05:27:00.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6014" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":356,"completed":27,"skipped":496,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:27:00.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 05:27:00.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42914af5-e1aa-447e-aa96-4eb852ba05df" in namespace "downward-api-1549" to be "Succeeded or Failed"
May 27 05:27:00.640: INFO: Pod "downwardapi-volume-42914af5-e1aa-447e-aa96-4eb852ba05df": Phase="Pending", Reason="", readiness=false. Elapsed: 8.705095ms
May 27 05:27:02.682: INFO: Pod "downwardapi-volume-42914af5-e1aa-447e-aa96-4eb852ba05df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050636515s
May 27 05:27:04.699: INFO: Pod "downwardapi-volume-42914af5-e1aa-447e-aa96-4eb852ba05df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067426529s
STEP: Saw pod success
May 27 05:27:04.699: INFO: Pod "downwardapi-volume-42914af5-e1aa-447e-aa96-4eb852ba05df" satisfied condition "Succeeded or Failed"
May 27 05:27:04.710: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-42914af5-e1aa-447e-aa96-4eb852ba05df container client-container: <nil>
STEP: delete the pod
May 27 05:27:04.764: INFO: Waiting for pod downwardapi-volume-42914af5-e1aa-447e-aa96-4eb852ba05df to disappear
May 27 05:27:04.770: INFO: Pod downwardapi-volume-42914af5-e1aa-447e-aa96-4eb852ba05df no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
May 27 05:27:04.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1549" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":28,"skipped":521,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context 
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:27:04.791: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
May 27 05:27:04.851: INFO: Waiting up to 5m0s for pod "security-context-fecf91b6-8e0a-4dbb-9bd0-0de3ecb59088" in namespace "security-context-8778" to be "Succeeded or Failed"
May 27 05:27:04.860: INFO: Pod "security-context-fecf91b6-8e0a-4dbb-9bd0-0de3ecb59088": Phase="Pending", Reason="", readiness=false. Elapsed: 8.774107ms
May 27 05:27:06.879: INFO: Pod "security-context-fecf91b6-8e0a-4dbb-9bd0-0de3ecb59088": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027621461s
May 27 05:27:08.895: INFO: Pod "security-context-fecf91b6-8e0a-4dbb-9bd0-0de3ecb59088": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043161813s
STEP: Saw pod success
May 27 05:27:08.895: INFO: Pod "security-context-fecf91b6-8e0a-4dbb-9bd0-0de3ecb59088" satisfied condition "Succeeded or Failed"
May 27 05:27:08.902: INFO: Trying to get logs from node bohc9zohd7ee-3 pod security-context-fecf91b6-8e0a-4dbb-9bd0-0de3ecb59088 container test-container: <nil>
STEP: delete the pod
May 27 05:27:08.942: INFO: Waiting for pod security-context-fecf91b6-8e0a-4dbb-9bd0-0de3ecb59088 to disappear
May 27 05:27:08.949: INFO: Pod security-context-fecf91b6-8e0a-4dbb-9bd0-0de3ecb59088 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
May 27 05:27:08.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-8778" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":29,"skipped":541,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease 
  lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:27:08.976: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:188
May 27 05:27:09.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-8534" for this suite.
•{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","total":356,"completed":30,"skipped":583,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:27:09.147: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 05:27:09.200: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b8a13e8e-af5b-4d8d-ae05-5cf160b08355" in namespace "projected-2488" to be "Succeeded or Failed"
May 27 05:27:09.212: INFO: Pod "downwardapi-volume-b8a13e8e-af5b-4d8d-ae05-5cf160b08355": Phase="Pending", Reason="", readiness=false. Elapsed: 12.04217ms
May 27 05:27:11.226: INFO: Pod "downwardapi-volume-b8a13e8e-af5b-4d8d-ae05-5cf160b08355": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025531635s
May 27 05:27:13.239: INFO: Pod "downwardapi-volume-b8a13e8e-af5b-4d8d-ae05-5cf160b08355": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039203978s
STEP: Saw pod success
May 27 05:27:13.240: INFO: Pod "downwardapi-volume-b8a13e8e-af5b-4d8d-ae05-5cf160b08355" satisfied condition "Succeeded or Failed"
May 27 05:27:13.247: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-b8a13e8e-af5b-4d8d-ae05-5cf160b08355 container client-container: <nil>
STEP: delete the pod
May 27 05:27:13.300: INFO: Waiting for pod downwardapi-volume-b8a13e8e-af5b-4d8d-ae05-5cf160b08355 to disappear
May 27 05:27:13.308: INFO: Pod downwardapi-volume-b8a13e8e-af5b-4d8d-ae05-5cf160b08355 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
May 27 05:27:13.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2488" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":31,"skipped":597,"failed":0}
SSSSSS
------------------------------
[sig-node] Security Context 
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:27:13.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
May 27 05:27:13.393: INFO: Waiting up to 5m0s for pod "security-context-ff5d3dcf-4636-41b9-a2a4-1c6bf06475a1" in namespace "security-context-6198" to be "Succeeded or Failed"
May 27 05:27:13.406: INFO: Pod "security-context-ff5d3dcf-4636-41b9-a2a4-1c6bf06475a1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.927838ms
May 27 05:27:15.421: INFO: Pod "security-context-ff5d3dcf-4636-41b9-a2a4-1c6bf06475a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028300399s
May 27 05:27:17.438: INFO: Pod "security-context-ff5d3dcf-4636-41b9-a2a4-1c6bf06475a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044790499s
STEP: Saw pod success
May 27 05:27:17.438: INFO: Pod "security-context-ff5d3dcf-4636-41b9-a2a4-1c6bf06475a1" satisfied condition "Succeeded or Failed"
May 27 05:27:17.446: INFO: Trying to get logs from node bohc9zohd7ee-3 pod security-context-ff5d3dcf-4636-41b9-a2a4-1c6bf06475a1 container test-container: <nil>
STEP: delete the pod
May 27 05:27:17.488: INFO: Waiting for pod security-context-ff5d3dcf-4636-41b9-a2a4-1c6bf06475a1 to disappear
May 27 05:27:17.501: INFO: Pod security-context-ff5d3dcf-4636-41b9-a2a4-1c6bf06475a1 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
May 27 05:27:17.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-6198" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":32,"skipped":603,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:27:17.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
May 27 05:27:18.781: INFO: The status of Pod kube-controller-manager-bohc9zohd7ee-2 is Running (Ready = true)
May 27 05:27:18.929: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
May 27 05:27:18.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2046" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":356,"completed":33,"skipped":617,"failed":0}
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:27:18.955: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5405
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-5405
I0527 05:27:19.099079      15 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5405, replica count: 2
May 27 05:27:22.150: INFO: Creating new exec pod
I0527 05:27:22.150507      15 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 27 05:27:25.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-5405 exec execpod5ppkk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May 27 05:27:25.527: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May 27 05:27:25.527: INFO: stdout: "externalname-service-slzrs"
May 27 05:27:25.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-5405 exec execpod5ppkk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.0.194 80'
May 27 05:27:25.730: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.0.194 80\nConnection to 10.233.0.194 80 port [tcp/http] succeeded!\n"
May 27 05:27:25.731: INFO: stdout: "externalname-service-hh5r6"
May 27 05:27:25.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-5405 exec execpod5ppkk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.180 30961'
May 27 05:27:25.944: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.180 30961\nConnection to 192.168.121.180 30961 port [tcp/*] succeeded!\n"
May 27 05:27:25.944: INFO: stdout: ""
May 27 05:27:26.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-5405 exec execpod5ppkk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.180 30961'
May 27 05:27:27.177: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.180 30961\nConnection to 192.168.121.180 30961 port [tcp/*] succeeded!\n"
May 27 05:27:27.177: INFO: stdout: ""
May 27 05:27:27.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-5405 exec execpod5ppkk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.180 30961'
May 27 05:27:28.242: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.180 30961\nConnection to 192.168.121.180 30961 port [tcp/*] succeeded!\n"
May 27 05:27:28.242: INFO: stdout: "externalname-service-hh5r6"
May 27 05:27:28.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-5405 exec execpod5ppkk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.16 30961'
May 27 05:27:28.541: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.16 30961\nConnection to 192.168.121.16 30961 port [tcp/*] succeeded!\n"
May 27 05:27:28.541: INFO: stdout: "externalname-service-slzrs"
May 27 05:27:28.541: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 05:27:28.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5405" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:9.668 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":356,"completed":34,"skipped":623,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:27:28.624: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:27:28.759: INFO: Create a RollingUpdate DaemonSet
May 27 05:27:28.772: INFO: Check that daemon pods launch on every node of the cluster
May 27 05:27:28.791: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:27:28.791: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:27:29.841: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:27:29.841: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:27:30.811: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
May 27 05:27:30.812: INFO: Node bohc9zohd7ee-2 is running 0 daemon pod, expected 1
May 27 05:27:31.814: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:27:31.814: INFO: Node bohc9zohd7ee-2 is running 0 daemon pod, expected 1
May 27 05:27:32.811: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:27:32.811: INFO: Node bohc9zohd7ee-2 is running 0 daemon pod, expected 1
May 27 05:27:33.811: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:27:33.811: INFO: Node bohc9zohd7ee-2 is running 0 daemon pod, expected 1
May 27 05:27:34.820: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:27:34.821: INFO: Node bohc9zohd7ee-2 is running 0 daemon pod, expected 1
May 27 05:27:35.811: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:27:35.811: INFO: Node bohc9zohd7ee-2 is running 0 daemon pod, expected 1
May 27 05:27:36.818: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:27:36.818: INFO: Node bohc9zohd7ee-2 is running 0 daemon pod, expected 1
May 27 05:27:37.814: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:27:37.814: INFO: Node bohc9zohd7ee-2 is running 0 daemon pod, expected 1
May 27 05:27:38.853: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May 27 05:27:38.853: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
May 27 05:27:38.853: INFO: Update the DaemonSet to trigger a rollout
May 27 05:27:38.876: INFO: Updating DaemonSet daemon-set
May 27 05:27:41.926: INFO: Roll back the DaemonSet before rollout is complete
May 27 05:27:41.977: INFO: Updating DaemonSet daemon-set
May 27 05:27:41.977: INFO: Make sure DaemonSet rollback is complete
May 27 05:27:41.987: INFO: Wrong image for pod: daemon-set-9zjtp. Expected: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
May 27 05:27:41.987: INFO: Pod daemon-set-9zjtp is not available
May 27 05:27:48.008: INFO: Pod daemon-set-5fkf2 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5911, will wait for the garbage collector to delete the pods
May 27 05:27:48.146: INFO: Deleting DaemonSet.extensions daemon-set took: 58.482185ms
May 27 05:27:48.347: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.990079ms
May 27 05:27:50.957: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:27:50.957: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May 27 05:27:50.968: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"6913"},"items":null}

May 27 05:27:50.975: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"6913"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
May 27 05:27:51.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5911" for this suite.

• [SLOW TEST:22.407 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":356,"completed":35,"skipped":665,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:27:51.033: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-2493
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 27 05:27:51.085: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May 27 05:27:51.147: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:27:53.163: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:27:55.161: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:27:57.164: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:27:59.161: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:28:01.159: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:28:03.160: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:28:05.160: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:28:07.164: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:28:09.161: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:28:11.158: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:28:13.164: INFO: The status of Pod netserver-0 is Running (Ready = true)
May 27 05:28:13.176: INFO: The status of Pod netserver-1 is Running (Ready = true)
May 27 05:28:13.186: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
May 27 05:28:15.262: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
May 27 05:28:15.262: INFO: Breadth first check of 10.233.66.164 on host 192.168.121.180...
May 27 05:28:15.275: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.11:9080/dial?request=hostname&protocol=udp&host=10.233.66.164&port=8081&tries=1'] Namespace:pod-network-test-2493 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 05:28:15.275: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:28:15.278: INFO: ExecWithOptions: Clientset creation
May 27 05:28:15.278: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2493/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.65.11%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.164%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May 27 05:28:15.454: INFO: Waiting for responses: map[]
May 27 05:28:15.454: INFO: reached 10.233.66.164 after 0/1 tries
May 27 05:28:15.454: INFO: Breadth first check of 10.233.64.43 on host 192.168.121.117...
May 27 05:28:15.461: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.11:9080/dial?request=hostname&protocol=udp&host=10.233.64.43&port=8081&tries=1'] Namespace:pod-network-test-2493 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 05:28:15.461: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:28:15.462: INFO: ExecWithOptions: Clientset creation
May 27 05:28:15.462: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2493/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.65.11%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.43%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May 27 05:28:15.598: INFO: Waiting for responses: map[]
May 27 05:28:15.598: INFO: reached 10.233.64.43 after 0/1 tries
May 27 05:28:15.598: INFO: Breadth first check of 10.233.65.166 on host 192.168.121.16...
May 27 05:28:15.611: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.11:9080/dial?request=hostname&protocol=udp&host=10.233.65.166&port=8081&tries=1'] Namespace:pod-network-test-2493 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 05:28:15.611: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:28:15.613: INFO: ExecWithOptions: Clientset creation
May 27 05:28:15.613: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2493/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.65.11%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.166%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May 27 05:28:15.718: INFO: Waiting for responses: map[]
May 27 05:28:15.718: INFO: reached 10.233.65.166 after 0/1 tries
May 27 05:28:15.718: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
May 27 05:28:15.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2493" for this suite.

• [SLOW TEST:24.714 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":356,"completed":36,"skipped":682,"failed":0}
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:28:15.749: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-6deaf30d-c523-44bb-a5c4-e2ccdcf691f4
STEP: Creating a pod to test consume configMaps
May 27 05:28:15.838: INFO: Waiting up to 5m0s for pod "pod-configmaps-74423373-8918-4471-bbe9-2a174ed83acc" in namespace "configmap-4062" to be "Succeeded or Failed"
May 27 05:28:15.848: INFO: Pod "pod-configmaps-74423373-8918-4471-bbe9-2a174ed83acc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.4506ms
May 27 05:28:17.864: INFO: Pod "pod-configmaps-74423373-8918-4471-bbe9-2a174ed83acc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025911632s
May 27 05:28:19.880: INFO: Pod "pod-configmaps-74423373-8918-4471-bbe9-2a174ed83acc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04162801s
STEP: Saw pod success
May 27 05:28:19.880: INFO: Pod "pod-configmaps-74423373-8918-4471-bbe9-2a174ed83acc" satisfied condition "Succeeded or Failed"
May 27 05:28:19.890: INFO: Trying to get logs from node bohc9zohd7ee-1 pod pod-configmaps-74423373-8918-4471-bbe9-2a174ed83acc container agnhost-container: <nil>
STEP: delete the pod
May 27 05:28:19.947: INFO: Waiting for pod pod-configmaps-74423373-8918-4471-bbe9-2a174ed83acc to disappear
May 27 05:28:19.952: INFO: Pod pod-configmaps-74423373-8918-4471-bbe9-2a174ed83acc no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
May 27 05:28:19.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4062" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":37,"skipped":685,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:28:19.973: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
May 27 05:28:31.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9504" for this suite.

• [SLOW TEST:11.187 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":356,"completed":38,"skipped":689,"failed":0}
S
------------------------------
[sig-apps] DisruptionController 
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:28:31.165: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pdb that targets all three pods in a test replica set
STEP: Waiting for the pdb to be processed
STEP: First trying to evict a pod which shouldn't be evictable
STEP: Waiting for all pods to be running
May 27 05:28:33.318: INFO: pods: 0 < 3
May 27 05:28:35.336: INFO: running pods: 2 < 3
STEP: locating a running pod
STEP: Updating the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
STEP: Waiting for the pdb to observed all healthy pods
STEP: Patching the pdb to disallow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
May 27 05:28:39.602: INFO: running pods: 2 < 3
STEP: locating a running pod
STEP: Deleting the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be deleted
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
May 27 05:28:41.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2631" for this suite.

• [SLOW TEST:10.599 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","total":356,"completed":39,"skipped":690,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:28:41.764: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-0c54af66-ee2d-4e9b-bc9d-88031838cbbe
STEP: Creating a pod to test consume configMaps
May 27 05:28:41.860: INFO: Waiting up to 5m0s for pod "pod-configmaps-7a4fe852-257d-47bd-9eb3-7c0b6aa49a68" in namespace "configmap-7990" to be "Succeeded or Failed"
May 27 05:28:41.887: INFO: Pod "pod-configmaps-7a4fe852-257d-47bd-9eb3-7c0b6aa49a68": Phase="Pending", Reason="", readiness=false. Elapsed: 26.509411ms
May 27 05:28:43.901: INFO: Pod "pod-configmaps-7a4fe852-257d-47bd-9eb3-7c0b6aa49a68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04076739s
May 27 05:28:45.916: INFO: Pod "pod-configmaps-7a4fe852-257d-47bd-9eb3-7c0b6aa49a68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055154412s
STEP: Saw pod success
May 27 05:28:45.916: INFO: Pod "pod-configmaps-7a4fe852-257d-47bd-9eb3-7c0b6aa49a68" satisfied condition "Succeeded or Failed"
May 27 05:28:45.922: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-configmaps-7a4fe852-257d-47bd-9eb3-7c0b6aa49a68 container agnhost-container: <nil>
STEP: delete the pod
May 27 05:28:45.954: INFO: Waiting for pod pod-configmaps-7a4fe852-257d-47bd-9eb3-7c0b6aa49a68 to disappear
May 27 05:28:45.960: INFO: Pod pod-configmaps-7a4fe852-257d-47bd-9eb3-7c0b6aa49a68 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
May 27 05:28:45.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7990" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":40,"skipped":698,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:28:45.983: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-3b80aace-3dba-4142-b93d-c6aed757ff2f
STEP: Creating a pod to test consume configMaps
May 27 05:28:46.089: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-566ca798-f78d-47d5-89c9-4f9357926125" in namespace "projected-1253" to be "Succeeded or Failed"
May 27 05:28:46.100: INFO: Pod "pod-projected-configmaps-566ca798-f78d-47d5-89c9-4f9357926125": Phase="Pending", Reason="", readiness=false. Elapsed: 11.462477ms
May 27 05:28:48.173: INFO: Pod "pod-projected-configmaps-566ca798-f78d-47d5-89c9-4f9357926125": Phase="Running", Reason="", readiness=true. Elapsed: 2.084873797s
May 27 05:28:50.193: INFO: Pod "pod-projected-configmaps-566ca798-f78d-47d5-89c9-4f9357926125": Phase="Running", Reason="", readiness=false. Elapsed: 4.104779242s
May 27 05:28:52.207: INFO: Pod "pod-projected-configmaps-566ca798-f78d-47d5-89c9-4f9357926125": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.118144112s
STEP: Saw pod success
May 27 05:28:52.207: INFO: Pod "pod-projected-configmaps-566ca798-f78d-47d5-89c9-4f9357926125" satisfied condition "Succeeded or Failed"
May 27 05:28:52.213: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-configmaps-566ca798-f78d-47d5-89c9-4f9357926125 container agnhost-container: <nil>
STEP: delete the pod
May 27 05:28:52.257: INFO: Waiting for pod pod-projected-configmaps-566ca798-f78d-47d5-89c9-4f9357926125 to disappear
May 27 05:28:52.263: INFO: Pod pod-projected-configmaps-566ca798-f78d-47d5-89c9-4f9357926125 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
May 27 05:28:52.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1253" for this suite.

• [SLOW TEST:6.303 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":41,"skipped":714,"failed":0}
SSSSSS
------------------------------
[sig-apps] Deployment 
  should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:28:52.291: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
May 27 05:28:52.346: INFO: Creating simple deployment test-deployment-xxsht
May 27 05:28:52.373: INFO: deployment "test-deployment-xxsht" doesn't have the required revision set
STEP: Getting /status
May 27 05:28:54.422: INFO: Deployment test-deployment-xxsht has Conditions: [{Available True 2022-05-27 05:28:54 +0000 UTC 2022-05-27 05:28:54 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-05-27 05:28:54 +0000 UTC 2022-05-27 05:28:52 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-xxsht-688c4d6789" has successfully progressed.}]
STEP: updating Deployment Status
May 27 05:28:54.450: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 28, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 28, 54, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 28, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 28, 52, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-xxsht-688c4d6789\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated
May 27 05:28:54.456: INFO: Observed &Deployment event: ADDED
May 27 05:28:54.456: INFO: Observed Deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-27 05:28:52 +0000 UTC 2022-05-27 05:28:52 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-xxsht-688c4d6789"}
May 27 05:28:54.457: INFO: Observed &Deployment event: MODIFIED
May 27 05:28:54.458: INFO: Observed Deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-27 05:28:52 +0000 UTC 2022-05-27 05:28:52 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-xxsht-688c4d6789"}
May 27 05:28:54.458: INFO: Observed Deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-05-27 05:28:52 +0000 UTC 2022-05-27 05:28:52 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May 27 05:28:54.459: INFO: Observed &Deployment event: MODIFIED
May 27 05:28:54.459: INFO: Observed Deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-05-27 05:28:52 +0000 UTC 2022-05-27 05:28:52 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May 27 05:28:54.459: INFO: Observed Deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-27 05:28:52 +0000 UTC 2022-05-27 05:28:52 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-xxsht-688c4d6789" is progressing.}
May 27 05:28:54.459: INFO: Observed &Deployment event: MODIFIED
May 27 05:28:54.459: INFO: Observed Deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-05-27 05:28:54 +0000 UTC 2022-05-27 05:28:54 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May 27 05:28:54.459: INFO: Observed Deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-27 05:28:54 +0000 UTC 2022-05-27 05:28:52 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-xxsht-688c4d6789" has successfully progressed.}
May 27 05:28:54.460: INFO: Observed &Deployment event: MODIFIED
May 27 05:28:54.460: INFO: Observed Deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-05-27 05:28:54 +0000 UTC 2022-05-27 05:28:54 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May 27 05:28:54.460: INFO: Observed Deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-27 05:28:54 +0000 UTC 2022-05-27 05:28:52 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-xxsht-688c4d6789" has successfully progressed.}
May 27 05:28:54.460: INFO: Found Deployment test-deployment-xxsht in namespace deployment-4104 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May 27 05:28:54.460: INFO: Deployment test-deployment-xxsht has an updated status
STEP: patching the Statefulset Status
May 27 05:28:54.460: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
May 27 05:28:54.477: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched
May 27 05:28:54.480: INFO: Observed &Deployment event: ADDED
May 27 05:28:54.480: INFO: Observed deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-27 05:28:52 +0000 UTC 2022-05-27 05:28:52 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-xxsht-688c4d6789"}
May 27 05:28:54.480: INFO: Observed &Deployment event: MODIFIED
May 27 05:28:54.481: INFO: Observed deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-27 05:28:52 +0000 UTC 2022-05-27 05:28:52 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-xxsht-688c4d6789"}
May 27 05:28:54.481: INFO: Observed deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-05-27 05:28:52 +0000 UTC 2022-05-27 05:28:52 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May 27 05:28:54.481: INFO: Observed &Deployment event: MODIFIED
May 27 05:28:54.481: INFO: Observed deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-05-27 05:28:52 +0000 UTC 2022-05-27 05:28:52 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May 27 05:28:54.481: INFO: Observed deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-27 05:28:52 +0000 UTC 2022-05-27 05:28:52 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-xxsht-688c4d6789" is progressing.}
May 27 05:28:54.482: INFO: Observed &Deployment event: MODIFIED
May 27 05:28:54.482: INFO: Observed deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-05-27 05:28:54 +0000 UTC 2022-05-27 05:28:54 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May 27 05:28:54.482: INFO: Observed deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-27 05:28:54 +0000 UTC 2022-05-27 05:28:52 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-xxsht-688c4d6789" has successfully progressed.}
May 27 05:28:54.483: INFO: Observed &Deployment event: MODIFIED
May 27 05:28:54.483: INFO: Observed deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-05-27 05:28:54 +0000 UTC 2022-05-27 05:28:54 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May 27 05:28:54.483: INFO: Observed deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-05-27 05:28:54 +0000 UTC 2022-05-27 05:28:52 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-xxsht-688c4d6789" has successfully progressed.}
May 27 05:28:54.483: INFO: Observed deployment test-deployment-xxsht in namespace deployment-4104 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May 27 05:28:54.483: INFO: Observed &Deployment event: MODIFIED
May 27 05:28:54.483: INFO: Found deployment test-deployment-xxsht in namespace deployment-4104 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
May 27 05:28:54.483: INFO: Deployment test-deployment-xxsht has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May 27 05:28:54.491: INFO: Deployment "test-deployment-xxsht":
&Deployment{ObjectMeta:{test-deployment-xxsht  deployment-4104  caefc033-f35b-4360-ab13-fe0e4d6997cd 7421 1 2022-05-27 05:28:52 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-05-27 05:28:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-05-27 05:28:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-05-27 05:28:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0026c2078 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May 27 05:28:54.502: INFO: New ReplicaSet "test-deployment-xxsht-688c4d6789" of Deployment "test-deployment-xxsht":
&ReplicaSet{ObjectMeta:{test-deployment-xxsht-688c4d6789  deployment-4104  bd575a90-dccb-49c0-a647-b6c743651604 7418 1 2022-05-27 05:28:52 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-xxsht caefc033-f35b-4360-ab13-fe0e4d6997cd 0xc001fffa70 0xc001fffa71}] []  [{kube-controller-manager Update apps/v1 2022-05-27 05:28:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"caefc033-f35b-4360-ab13-fe0e4d6997cd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:28:54 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 688c4d6789,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001fffb18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May 27 05:28:54.514: INFO: Pod "test-deployment-xxsht-688c4d6789-rgcsc" is available:
&Pod{ObjectMeta:{test-deployment-xxsht-688c4d6789-rgcsc test-deployment-xxsht-688c4d6789- deployment-4104  5b7f6688-ad39-44c6-8c62-d0d54b2803ab 7417 0 2022-05-27 05:28:52 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[] [{apps/v1 ReplicaSet test-deployment-xxsht-688c4d6789 bd575a90-dccb-49c0-a647-b6c743651604 0xc001fffeb7 0xc001fffeb8}] []  [{kube-controller-manager Update v1 2022-05-27 05:28:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bd575a90-dccb-49c0-a647-b6c743651604\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:28:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.63\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xks59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xks59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:28:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:28:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:28:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.117,PodIP:10.233.64.63,StartTime:2022-05-27 05:28:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 05:28:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://7a2758f64a0952b9016375098e5b6b48a802b79f26d1eab7009d56cbafe35ef3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
May 27 05:28:54.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4104" for this suite.
•{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","total":356,"completed":42,"skipped":720,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:28:54.544: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
May 27 05:28:54.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8632" for this suite.
•{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","total":356,"completed":43,"skipped":752,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:28:54.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 27 05:28:54.812: INFO: Waiting up to 5m0s for pod "pod-2b723010-3a59-4254-8a97-ca04f88bd2fc" in namespace "emptydir-7993" to be "Succeeded or Failed"
May 27 05:28:54.818: INFO: Pod "pod-2b723010-3a59-4254-8a97-ca04f88bd2fc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.310739ms
May 27 05:28:56.835: INFO: Pod "pod-2b723010-3a59-4254-8a97-ca04f88bd2fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023622612s
May 27 05:28:58.853: INFO: Pod "pod-2b723010-3a59-4254-8a97-ca04f88bd2fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040846822s
STEP: Saw pod success
May 27 05:28:58.853: INFO: Pod "pod-2b723010-3a59-4254-8a97-ca04f88bd2fc" satisfied condition "Succeeded or Failed"
May 27 05:28:58.860: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-2b723010-3a59-4254-8a97-ca04f88bd2fc container test-container: <nil>
STEP: delete the pod
May 27 05:28:58.899: INFO: Waiting for pod pod-2b723010-3a59-4254-8a97-ca04f88bd2fc to disappear
May 27 05:28:58.905: INFO: Pod pod-2b723010-3a59-4254-8a97-ca04f88bd2fc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 05:28:58.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7993" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":44,"skipped":755,"failed":0}
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:28:58.935: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: reading a file in the container
May 27 05:29:01.050: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4980 pod-service-account-89f0b2e5-bc6a-4c16-a209-9504effbfbe1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
May 27 05:29:01.388: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4980 pod-service-account-89f0b2e5-bc6a-4c16-a209-9504effbfbe1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
May 27 05:29:01.603: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4980 pod-service-account-89f0b2e5-bc6a-4c16-a209-9504effbfbe1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
May 27 05:29:01.815: INFO: Got root ca configmap in namespace "svcaccounts-4980"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
May 27 05:29:01.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4980" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":356,"completed":45,"skipped":759,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:29:01.896: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Pod with a static label
STEP: watching for Pod to be ready
May 27 05:29:02.008: INFO: observed Pod pod-test in namespace pods-1812 in phase Pending with labels: map[test-pod-static:true] & conditions []
May 27 05:29:02.021: INFO: observed Pod pod-test in namespace pods-1812 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:29:02 +0000 UTC  }]
May 27 05:29:02.096: INFO: observed Pod pod-test in namespace pods-1812 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:29:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:29:02 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:29:02 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:29:02 +0000 UTC  }]
May 27 05:29:03.159: INFO: Found Pod pod-test in namespace pods-1812 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:29:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:29:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:29:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:29:02 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data
STEP: getting the Pod and ensuring that it's patched
STEP: replacing the Pod's status Ready condition to False
STEP: check the Pod again to ensure its Ready conditions are False
STEP: deleting the Pod via a Collection with a LabelSelector
STEP: watching for the Pod to be deleted
May 27 05:29:03.277: INFO: observed event type MODIFIED
May 27 05:29:05.205: INFO: observed event type MODIFIED
May 27 05:29:06.190: INFO: observed event type MODIFIED
May 27 05:29:06.209: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
May 27 05:29:06.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1812" for this suite.
•{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","total":356,"completed":46,"skipped":775,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:29:06.277: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:29:06.371: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 27 05:29:06.402: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:29:06.402: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:29:07.542: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:29:07.542: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:29:08.431: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:29:08.431: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:29:09.429: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May 27 05:29:09.429: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 27 05:29:09.512: INFO: Wrong image for pod: daemon-set-b9hpv. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:09.512: INFO: Wrong image for pod: daemon-set-db28l. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:09.512: INFO: Wrong image for pod: daemon-set-zddtx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:10.531: INFO: Wrong image for pod: daemon-set-db28l. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:10.531: INFO: Wrong image for pod: daemon-set-zddtx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:11.532: INFO: Wrong image for pod: daemon-set-db28l. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:11.532: INFO: Wrong image for pod: daemon-set-zddtx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:12.532: INFO: Pod daemon-set-7mvgv is not available
May 27 05:29:12.532: INFO: Wrong image for pod: daemon-set-db28l. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:12.532: INFO: Wrong image for pod: daemon-set-zddtx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:13.531: INFO: Pod daemon-set-7mvgv is not available
May 27 05:29:13.531: INFO: Wrong image for pod: daemon-set-db28l. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:13.531: INFO: Wrong image for pod: daemon-set-zddtx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:14.535: INFO: Wrong image for pod: daemon-set-db28l. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:15.533: INFO: Wrong image for pod: daemon-set-db28l. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.36, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
May 27 05:29:15.533: INFO: Pod daemon-set-gg7bf is not available
May 27 05:29:17.535: INFO: Pod daemon-set-rwmcz is not available
STEP: Check that daemon pods are still running on every node of the cluster.
May 27 05:29:17.571: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:29:17.571: INFO: Node bohc9zohd7ee-3 is running 0 daemon pod, expected 1
May 27 05:29:18.595: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:29:18.595: INFO: Node bohc9zohd7ee-3 is running 0 daemon pod, expected 1
May 27 05:29:19.589: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May 27 05:29:19.589: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3381, will wait for the garbage collector to delete the pods
May 27 05:29:19.695: INFO: Deleting DaemonSet.extensions daemon-set took: 17.020846ms
May 27 05:29:19.796: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.478606ms
May 27 05:29:22.609: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:29:22.609: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May 27 05:29:22.616: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7736"},"items":null}

May 27 05:29:22.622: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7736"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
May 27 05:29:22.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3381" for this suite.

• [SLOW TEST:16.393 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":356,"completed":47,"skipped":822,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:29:22.672: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
May 27 05:29:23.722: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 05:29:26.776: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:29:26.789: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:29:30.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8972" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

• [SLOW TEST:7.989 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":356,"completed":48,"skipped":845,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:29:30.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 05:29:31.660: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 05:29:34.711: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:29:34.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7367" for this suite.
STEP: Destroying namespace "webhook-7367-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":356,"completed":49,"skipped":859,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:29:35.003: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:188
May 27 05:29:35.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1142" for this suite.
•{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":356,"completed":50,"skipped":872,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:29:35.150: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
May 27 05:30:16.802: INFO: The status of Pod kube-controller-manager-bohc9zohd7ee-2 is Running (Ready = true)
May 27 05:30:16.926: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

May 27 05:30:16.926: INFO: Deleting pod "simpletest.rc-27fbz" in namespace "gc-1157"
May 27 05:30:16.944: INFO: Deleting pod "simpletest.rc-296pg" in namespace "gc-1157"
May 27 05:30:16.967: INFO: Deleting pod "simpletest.rc-2klmg" in namespace "gc-1157"
May 27 05:30:17.009: INFO: Deleting pod "simpletest.rc-44vqz" in namespace "gc-1157"
May 27 05:30:17.106: INFO: Deleting pod "simpletest.rc-4hj2j" in namespace "gc-1157"
May 27 05:30:17.193: INFO: Deleting pod "simpletest.rc-4jvvr" in namespace "gc-1157"
May 27 05:30:17.275: INFO: Deleting pod "simpletest.rc-52rqk" in namespace "gc-1157"
May 27 05:30:17.372: INFO: Deleting pod "simpletest.rc-57x47" in namespace "gc-1157"
May 27 05:30:17.531: INFO: Deleting pod "simpletest.rc-5chth" in namespace "gc-1157"
May 27 05:30:17.662: INFO: Deleting pod "simpletest.rc-5cspr" in namespace "gc-1157"
May 27 05:30:17.708: INFO: Deleting pod "simpletest.rc-5rx56" in namespace "gc-1157"
May 27 05:30:17.813: INFO: Deleting pod "simpletest.rc-6mlwg" in namespace "gc-1157"
May 27 05:30:17.895: INFO: Deleting pod "simpletest.rc-6qvsm" in namespace "gc-1157"
May 27 05:30:17.994: INFO: Deleting pod "simpletest.rc-6wp5p" in namespace "gc-1157"
May 27 05:30:18.183: INFO: Deleting pod "simpletest.rc-758wm" in namespace "gc-1157"
May 27 05:30:18.318: INFO: Deleting pod "simpletest.rc-76wbx" in namespace "gc-1157"
May 27 05:30:18.407: INFO: Deleting pod "simpletest.rc-77h4h" in namespace "gc-1157"
May 27 05:30:18.517: INFO: Deleting pod "simpletest.rc-79rgs" in namespace "gc-1157"
May 27 05:30:18.631: INFO: Deleting pod "simpletest.rc-7x66h" in namespace "gc-1157"
May 27 05:30:18.675: INFO: Deleting pod "simpletest.rc-8t24d" in namespace "gc-1157"
May 27 05:30:18.774: INFO: Deleting pod "simpletest.rc-8z9nf" in namespace "gc-1157"
May 27 05:30:18.834: INFO: Deleting pod "simpletest.rc-97xnz" in namespace "gc-1157"
May 27 05:30:18.911: INFO: Deleting pod "simpletest.rc-98q5q" in namespace "gc-1157"
May 27 05:30:19.001: INFO: Deleting pod "simpletest.rc-9ttv8" in namespace "gc-1157"
May 27 05:30:19.209: INFO: Deleting pod "simpletest.rc-bf4zw" in namespace "gc-1157"
May 27 05:30:19.493: INFO: Deleting pod "simpletest.rc-btqfr" in namespace "gc-1157"
May 27 05:30:19.611: INFO: Deleting pod "simpletest.rc-cbd6w" in namespace "gc-1157"
May 27 05:30:19.735: INFO: Deleting pod "simpletest.rc-cg6hg" in namespace "gc-1157"
May 27 05:30:19.787: INFO: Deleting pod "simpletest.rc-ch94g" in namespace "gc-1157"
May 27 05:30:19.859: INFO: Deleting pod "simpletest.rc-cjnn6" in namespace "gc-1157"
May 27 05:30:19.910: INFO: Deleting pod "simpletest.rc-cn8nr" in namespace "gc-1157"
May 27 05:30:20.028: INFO: Deleting pod "simpletest.rc-cpm6x" in namespace "gc-1157"
May 27 05:30:20.363: INFO: Deleting pod "simpletest.rc-cxlhv" in namespace "gc-1157"
May 27 05:30:20.741: INFO: Deleting pod "simpletest.rc-d4hnj" in namespace "gc-1157"
May 27 05:30:20.893: INFO: Deleting pod "simpletest.rc-dg56m" in namespace "gc-1157"
May 27 05:30:21.072: INFO: Deleting pod "simpletest.rc-dkg5j" in namespace "gc-1157"
May 27 05:30:21.215: INFO: Deleting pod "simpletest.rc-dm6ts" in namespace "gc-1157"
May 27 05:30:21.276: INFO: Deleting pod "simpletest.rc-dtlmm" in namespace "gc-1157"
May 27 05:30:21.336: INFO: Deleting pod "simpletest.rc-f5ct2" in namespace "gc-1157"
May 27 05:30:21.442: INFO: Deleting pod "simpletest.rc-fbqx2" in namespace "gc-1157"
May 27 05:30:21.547: INFO: Deleting pod "simpletest.rc-fl55t" in namespace "gc-1157"
May 27 05:30:21.707: INFO: Deleting pod "simpletest.rc-fw4rw" in namespace "gc-1157"
May 27 05:30:21.817: INFO: Deleting pod "simpletest.rc-fwt5c" in namespace "gc-1157"
May 27 05:30:21.886: INFO: Deleting pod "simpletest.rc-fwwcz" in namespace "gc-1157"
May 27 05:30:22.003: INFO: Deleting pod "simpletest.rc-g28zm" in namespace "gc-1157"
May 27 05:30:22.191: INFO: Deleting pod "simpletest.rc-g2rxs" in namespace "gc-1157"
May 27 05:30:22.406: INFO: Deleting pod "simpletest.rc-gf7qk" in namespace "gc-1157"
May 27 05:30:22.615: INFO: Deleting pod "simpletest.rc-gff82" in namespace "gc-1157"
May 27 05:30:22.685: INFO: Deleting pod "simpletest.rc-gnhhr" in namespace "gc-1157"
May 27 05:30:22.750: INFO: Deleting pod "simpletest.rc-h8sc8" in namespace "gc-1157"
May 27 05:30:22.849: INFO: Deleting pod "simpletest.rc-hfzr7" in namespace "gc-1157"
May 27 05:30:22.980: INFO: Deleting pod "simpletest.rc-hhxz7" in namespace "gc-1157"
May 27 05:30:23.140: INFO: Deleting pod "simpletest.rc-hrk27" in namespace "gc-1157"
May 27 05:30:23.237: INFO: Deleting pod "simpletest.rc-hwfbq" in namespace "gc-1157"
May 27 05:30:23.405: INFO: Deleting pod "simpletest.rc-jlssq" in namespace "gc-1157"
May 27 05:30:23.580: INFO: Deleting pod "simpletest.rc-jlznj" in namespace "gc-1157"
May 27 05:30:23.722: INFO: Deleting pod "simpletest.rc-jqgtm" in namespace "gc-1157"
May 27 05:30:23.836: INFO: Deleting pod "simpletest.rc-k2cbh" in namespace "gc-1157"
May 27 05:30:23.946: INFO: Deleting pod "simpletest.rc-kcvq6" in namespace "gc-1157"
May 27 05:30:24.014: INFO: Deleting pod "simpletest.rc-kzmbg" in namespace "gc-1157"
May 27 05:30:24.553: INFO: Deleting pod "simpletest.rc-ljdqd" in namespace "gc-1157"
May 27 05:30:24.680: INFO: Deleting pod "simpletest.rc-llsfg" in namespace "gc-1157"
May 27 05:30:24.797: INFO: Deleting pod "simpletest.rc-lmvck" in namespace "gc-1157"
May 27 05:30:24.971: INFO: Deleting pod "simpletest.rc-lsglv" in namespace "gc-1157"
May 27 05:30:25.063: INFO: Deleting pod "simpletest.rc-m7r9j" in namespace "gc-1157"
May 27 05:30:25.156: INFO: Deleting pod "simpletest.rc-mdldl" in namespace "gc-1157"
May 27 05:30:25.286: INFO: Deleting pod "simpletest.rc-mjd7q" in namespace "gc-1157"
May 27 05:30:25.366: INFO: Deleting pod "simpletest.rc-mjzk2" in namespace "gc-1157"
May 27 05:30:25.503: INFO: Deleting pod "simpletest.rc-mxrfb" in namespace "gc-1157"
May 27 05:30:25.587: INFO: Deleting pod "simpletest.rc-n6hz4" in namespace "gc-1157"
May 27 05:30:25.663: INFO: Deleting pod "simpletest.rc-ntpjl" in namespace "gc-1157"
May 27 05:30:25.777: INFO: Deleting pod "simpletest.rc-p26xc" in namespace "gc-1157"
May 27 05:30:25.850: INFO: Deleting pod "simpletest.rc-p55wx" in namespace "gc-1157"
May 27 05:30:25.917: INFO: Deleting pod "simpletest.rc-p5jbb" in namespace "gc-1157"
May 27 05:30:25.974: INFO: Deleting pod "simpletest.rc-p7lkm" in namespace "gc-1157"
May 27 05:30:26.143: INFO: Deleting pod "simpletest.rc-pw9sl" in namespace "gc-1157"
May 27 05:30:26.347: INFO: Deleting pod "simpletest.rc-q2h86" in namespace "gc-1157"
May 27 05:30:26.569: INFO: Deleting pod "simpletest.rc-q746f" in namespace "gc-1157"
May 27 05:30:26.669: INFO: Deleting pod "simpletest.rc-q9j72" in namespace "gc-1157"
May 27 05:30:26.728: INFO: Deleting pod "simpletest.rc-qvfdr" in namespace "gc-1157"
May 27 05:30:26.857: INFO: Deleting pod "simpletest.rc-rr8m7" in namespace "gc-1157"
May 27 05:30:26.963: INFO: Deleting pod "simpletest.rc-rt226" in namespace "gc-1157"
May 27 05:30:27.036: INFO: Deleting pod "simpletest.rc-schsc" in namespace "gc-1157"
May 27 05:30:27.165: INFO: Deleting pod "simpletest.rc-sk72m" in namespace "gc-1157"
May 27 05:30:27.233: INFO: Deleting pod "simpletest.rc-sm9r5" in namespace "gc-1157"
May 27 05:30:27.397: INFO: Deleting pod "simpletest.rc-ssv9f" in namespace "gc-1157"
May 27 05:30:27.560: INFO: Deleting pod "simpletest.rc-sxmnj" in namespace "gc-1157"
May 27 05:30:27.688: INFO: Deleting pod "simpletest.rc-sztbp" in namespace "gc-1157"
May 27 05:30:27.860: INFO: Deleting pod "simpletest.rc-t4g9z" in namespace "gc-1157"
May 27 05:30:28.019: INFO: Deleting pod "simpletest.rc-th446" in namespace "gc-1157"
May 27 05:30:28.120: INFO: Deleting pod "simpletest.rc-trtbw" in namespace "gc-1157"
May 27 05:30:28.563: INFO: Deleting pod "simpletest.rc-v5bmt" in namespace "gc-1157"
May 27 05:30:28.678: INFO: Deleting pod "simpletest.rc-v9lzc" in namespace "gc-1157"
May 27 05:30:28.727: INFO: Deleting pod "simpletest.rc-vxxw5" in namespace "gc-1157"
May 27 05:30:28.813: INFO: Deleting pod "simpletest.rc-wfpg4" in namespace "gc-1157"
May 27 05:30:28.911: INFO: Deleting pod "simpletest.rc-whqzr" in namespace "gc-1157"
May 27 05:30:29.083: INFO: Deleting pod "simpletest.rc-xmqnl" in namespace "gc-1157"
May 27 05:30:29.201: INFO: Deleting pod "simpletest.rc-xwvch" in namespace "gc-1157"
May 27 05:30:29.333: INFO: Deleting pod "simpletest.rc-zj2jj" in namespace "gc-1157"
May 27 05:30:29.419: INFO: Deleting pod "simpletest.rc-znqxs" in namespace "gc-1157"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
May 27 05:30:29.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1157" for this suite.

• [SLOW TEST:54.453 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":356,"completed":51,"skipped":873,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:30:29.604: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:188
May 27 05:30:29.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4172" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":356,"completed":52,"skipped":894,"failed":0}
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:30:29.769: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5274
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating stateful set ss in namespace statefulset-5274
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5274
May 27 05:30:29.923: INFO: Found 0 stateful pods, waiting for 1
May 27 05:30:39.974: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 27 05:30:39.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-5274 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 27 05:30:40.376: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 27 05:30:40.376: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 27 05:30:40.376: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 27 05:30:40.398: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 27 05:30:50.433: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 27 05:30:50.433: INFO: Waiting for statefulset status.replicas updated to 0
May 27 05:30:50.479: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 27 05:30:50.480: INFO: ss-0  bohc9zohd7ee-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:30 +0000 UTC  }]
May 27 05:30:50.480: INFO: 
May 27 05:30:50.480: INFO: StatefulSet ss has not reached scale 3, at 1
May 27 05:30:51.496: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985712319s
May 27 05:30:52.506: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.96944574s
May 27 05:30:53.525: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.959313691s
May 27 05:30:54.540: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.940532065s
May 27 05:30:55.554: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.924301604s
May 27 05:30:56.566: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.911424946s
May 27 05:30:57.580: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.899105816s
May 27 05:30:58.594: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.8857632s
May 27 05:30:59.605: INFO: Verifying statefulset ss doesn't scale past 3 for another 871.787781ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5274
May 27 05:31:00.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-5274 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 27 05:31:00.890: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 27 05:31:00.890: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 27 05:31:00.890: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 27 05:31:00.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-5274 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 27 05:31:01.171: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 27 05:31:01.171: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 27 05:31:01.171: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 27 05:31:01.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-5274 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 27 05:31:01.539: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 27 05:31:01.539: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 27 05:31:01.539: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 27 05:31:01.547: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 27 05:31:01.547: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 27 05:31:01.548: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 27 05:31:01.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-5274 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 27 05:31:01.811: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 27 05:31:01.811: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 27 05:31:01.811: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 27 05:31:01.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-5274 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 27 05:31:02.057: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 27 05:31:02.057: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 27 05:31:02.057: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 27 05:31:02.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-5274 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 27 05:31:02.322: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 27 05:31:02.322: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 27 05:31:02.322: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 27 05:31:02.322: INFO: Waiting for statefulset status.replicas updated to 0
May 27 05:31:02.331: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May 27 05:31:12.383: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 27 05:31:12.384: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 27 05:31:12.384: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 27 05:31:12.412: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 27 05:31:12.412: INFO: ss-0  bohc9zohd7ee-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:31:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:31:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:30 +0000 UTC  }]
May 27 05:31:12.413: INFO: ss-1  bohc9zohd7ee-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:31:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:31:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:50 +0000 UTC  }]
May 27 05:31:12.413: INFO: ss-2  bohc9zohd7ee-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:31:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:31:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:50 +0000 UTC  }]
May 27 05:31:12.413: INFO: 
May 27 05:31:12.413: INFO: StatefulSet ss has not reached scale 0, at 3
May 27 05:31:13.426: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 27 05:31:13.426: INFO: ss-0  bohc9zohd7ee-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:31:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:31:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:30 +0000 UTC  }]
May 27 05:31:13.426: INFO: ss-2  bohc9zohd7ee-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:31:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:31:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 05:30:50 +0000 UTC  }]
May 27 05:31:13.426: INFO: 
May 27 05:31:13.426: INFO: StatefulSet ss has not reached scale 0, at 2
May 27 05:31:14.447: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.97909477s
May 27 05:31:15.462: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.957410031s
May 27 05:31:16.474: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.942985618s
May 27 05:31:17.494: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.930836188s
May 27 05:31:18.511: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.911097065s
May 27 05:31:19.526: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.893375239s
May 27 05:31:20.545: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.879057559s
May 27 05:31:21.557: INFO: Verifying statefulset ss doesn't scale past 0 for another 859.216948ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5274
May 27 05:31:22.567: INFO: Scaling statefulset ss to 0
May 27 05:31:22.605: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May 27 05:31:22.611: INFO: Deleting all statefulset in ns statefulset-5274
May 27 05:31:22.619: INFO: Scaling statefulset ss to 0
May 27 05:31:22.643: INFO: Waiting for statefulset status.replicas updated to 0
May 27 05:31:22.649: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
May 27 05:31:22.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5274" for this suite.

• [SLOW TEST:52.938 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":356,"completed":53,"skipped":897,"failed":0}
SSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] 
  should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:31:22.710: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename certificates
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
May 27 05:31:23.921: INFO: starting watch
STEP: patching
STEP: updating
May 27 05:31:23.946: INFO: waiting for watch events with expected annotations
May 27 05:31:23.946: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:31:24.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-4452" for this suite.
•{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":356,"completed":54,"skipped":907,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:31:24.123: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
May 27 05:31:25.194: INFO: The status of Pod kube-controller-manager-bohc9zohd7ee-2 is Running (Ready = true)
May 27 05:31:25.370: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
May 27 05:31:25.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8701" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":356,"completed":55,"skipped":932,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:31:25.407: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:31:25.547: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 27 05:31:25.587: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:31:25.587: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched.
May 27 05:31:25.709: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:31:25.709: INFO: Node bohc9zohd7ee-3 is running 0 daemon pod, expected 1
May 27 05:31:26.735: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:31:26.735: INFO: Node bohc9zohd7ee-3 is running 0 daemon pod, expected 1
May 27 05:31:27.724: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
May 27 05:31:27.725: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 27 05:31:27.799: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
May 27 05:31:27.799: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
May 27 05:31:28.815: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:31:28.815: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 27 05:31:28.851: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:31:28.851: INFO: Node bohc9zohd7ee-3 is running 0 daemon pod, expected 1
May 27 05:31:29.863: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:31:29.864: INFO: Node bohc9zohd7ee-3 is running 0 daemon pod, expected 1
May 27 05:31:30.879: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:31:30.879: INFO: Node bohc9zohd7ee-3 is running 0 daemon pod, expected 1
May 27 05:31:31.864: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:31:31.864: INFO: Node bohc9zohd7ee-3 is running 0 daemon pod, expected 1
May 27 05:31:32.860: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
May 27 05:31:32.860: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7768, will wait for the garbage collector to delete the pods
May 27 05:31:32.946: INFO: Deleting DaemonSet.extensions daemon-set took: 18.39483ms
May 27 05:31:33.048: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.750186ms
May 27 05:31:35.763: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:31:35.764: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May 27 05:31:35.770: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"10520"},"items":null}

May 27 05:31:35.777: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"10520"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
May 27 05:31:35.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7768" for this suite.

• [SLOW TEST:10.458 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":356,"completed":56,"skipped":968,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:31:35.866: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:31:35.916: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
May 27 05:31:43.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-1120 --namespace=crd-publish-openapi-1120 create -f -'
May 27 05:31:44.806: INFO: stderr: ""
May 27 05:31:44.806: INFO: stdout: "e2e-test-crd-publish-openapi-7386-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May 27 05:31:44.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-1120 --namespace=crd-publish-openapi-1120 delete e2e-test-crd-publish-openapi-7386-crds test-cr'
May 27 05:31:45.053: INFO: stderr: ""
May 27 05:31:45.053: INFO: stdout: "e2e-test-crd-publish-openapi-7386-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
May 27 05:31:45.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-1120 --namespace=crd-publish-openapi-1120 apply -f -'
May 27 05:31:45.581: INFO: stderr: ""
May 27 05:31:45.581: INFO: stdout: "e2e-test-crd-publish-openapi-7386-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May 27 05:31:45.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-1120 --namespace=crd-publish-openapi-1120 delete e2e-test-crd-publish-openapi-7386-crds test-cr'
May 27 05:31:45.739: INFO: stderr: ""
May 27 05:31:45.739: INFO: stdout: "e2e-test-crd-publish-openapi-7386-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
May 27 05:31:45.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-1120 explain e2e-test-crd-publish-openapi-7386-crds'
May 27 05:31:46.070: INFO: stderr: ""
May 27 05:31:46.070: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7386-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:31:50.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1120" for this suite.

• [SLOW TEST:14.390 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":356,"completed":57,"skipped":995,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:31:50.273: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 05:31:50.987: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 05:31:54.039: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:32:06.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5668" for this suite.
STEP: Destroying namespace "webhook-5668-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:16.253 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":356,"completed":58,"skipped":1053,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:32:06.527: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 05:32:06.643: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6bdff6f3-0876-4c77-ab99-229783875622" in namespace "downward-api-7071" to be "Succeeded or Failed"
May 27 05:32:06.653: INFO: Pod "downwardapi-volume-6bdff6f3-0876-4c77-ab99-229783875622": Phase="Pending", Reason="", readiness=false. Elapsed: 9.819405ms
May 27 05:32:08.667: INFO: Pod "downwardapi-volume-6bdff6f3-0876-4c77-ab99-229783875622": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023801351s
May 27 05:32:10.685: INFO: Pod "downwardapi-volume-6bdff6f3-0876-4c77-ab99-229783875622": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041811075s
STEP: Saw pod success
May 27 05:32:10.685: INFO: Pod "downwardapi-volume-6bdff6f3-0876-4c77-ab99-229783875622" satisfied condition "Succeeded or Failed"
May 27 05:32:10.696: INFO: Trying to get logs from node bohc9zohd7ee-2 pod downwardapi-volume-6bdff6f3-0876-4c77-ab99-229783875622 container client-container: <nil>
STEP: delete the pod
May 27 05:32:10.743: INFO: Waiting for pod downwardapi-volume-6bdff6f3-0876-4c77-ab99-229783875622 to disappear
May 27 05:32:10.749: INFO: Pod downwardapi-volume-6bdff6f3-0876-4c77-ab99-229783875622 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
May 27 05:32:10.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7071" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":59,"skipped":1063,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:32:10.781: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 27 05:32:14.906: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
May 27 05:32:14.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-670" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":356,"completed":60,"skipped":1092,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:32:14.984: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:32:15.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-3374 create -f -'
May 27 05:32:16.502: INFO: stderr: ""
May 27 05:32:16.502: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
May 27 05:32:16.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-3374 create -f -'
May 27 05:32:16.900: INFO: stderr: ""
May 27 05:32:16.900: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
May 27 05:32:17.913: INFO: Selector matched 1 pods for map[app:agnhost]
May 27 05:32:17.913: INFO: Found 1 / 1
May 27 05:32:17.913: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 27 05:32:17.922: INFO: Selector matched 1 pods for map[app:agnhost]
May 27 05:32:17.922: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 27 05:32:17.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-3374 describe pod agnhost-primary-g9tnq'
May 27 05:32:18.117: INFO: stderr: ""
May 27 05:32:18.117: INFO: stdout: "Name:         agnhost-primary-g9tnq\nNamespace:    kubectl-3374\nPriority:     0\nNode:         bohc9zohd7ee-3/192.168.121.16\nStart Time:   Fri, 27 May 2022 05:32:16 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nStatus:       Running\nIP:           10.233.65.244\nIPs:\n  IP:           10.233.65.244\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://60ab5669558cb8d77cc8ef8853ab2ae885f252bb6301274a424dc42b7d31a922\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.36\n    Image ID:       k8s.gcr.io/e2e-test-images/agnhost@sha256:c8cf9027e6db0e7de9b172400b209da8fe7aac863d19352723d2457847457403\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 27 May 2022 05:32:17 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-8cz5p (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-8cz5p:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-3374/agnhost-primary-g9tnq to bohc9zohd7ee-3\n  Normal  Pulled     1s    kubelet            Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.36\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
May 27 05:32:18.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-3374 describe rc agnhost-primary'
May 27 05:32:18.261: INFO: stderr: ""
May 27 05:32:18.261: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-3374\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.36\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-g9tnq\n"
May 27 05:32:18.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-3374 describe service agnhost-primary'
May 27 05:32:18.429: INFO: stderr: ""
May 27 05:32:18.429: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-3374\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.24.10\nIPs:               10.233.24.10\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.65.244:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 27 05:32:18.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-3374 describe node bohc9zohd7ee-1'
May 27 05:32:18.621: INFO: stderr: ""
May 27 05:32:18.621: INFO: stdout: "Name:               bohc9zohd7ee-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=bohc9zohd7ee-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        io.cilium.network.ipv4-cilium-host: 10.233.66.49\n                    io.cilium.network.ipv4-health-ip: 10.233.66.6\n                    io.cilium.network.ipv4-pod-cidr: 10.233.66.0/24\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 27 May 2022 04:56:54 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  bohc9zohd7ee-1\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 27 May 2022 05:32:10 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 27 May 2022 05:11:10 +0000   Fri, 27 May 2022 05:11:10 +0000   CiliumIsUp                   Cilium is running on this node\n  MemoryPressure       False   Fri, 27 May 2022 05:30:27 +0000   Fri, 27 May 2022 04:56:44 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 27 May 2022 05:30:27 +0000   Fri, 27 May 2022 04:56:44 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 27 May 2022 05:30:27 +0000   Fri, 27 May 2022 04:56:44 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 27 May 2022 05:30:27 +0000   Fri, 27 May 2022 05:08:20 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.121.180\n  Hostname:    bohc9zohd7ee-1\nCapacity:\n  cpu:                    2\n  ephemeral-storage:      122749536Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 8142488Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    1600m\n  ephemeral-storage:      119410748528\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 3292824Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 a50ee89a928e4a78af6029861450cdfb\n  System UUID:                a50ee89a-928e-4a78-af60-29861450cdfb\n  Boot ID:                    62963425-c09a-4fd2-a413-eb931fc722c8\n  Kernel Version:             5.15.0-33-generic\n  OS Image:                   Ubuntu 22.04 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.24.0\n  Kubelet Version:            v1.24.1\n  Kube-Proxy Version:         v1.24.1\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  cilium-test                 echo-other-node-6cd597cddc-nc274                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         20m\n  kube-system                 cilium-5bg94                                               100m (6%)     0 (0%)      100Mi (3%)       0 (0%)         22m\n  kube-system                 cilium-node-init-b2j7g                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         22m\n  kube-system                 kube-addon-manager-bohc9zohd7ee-1                          5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         22m\n  kube-system                 kube-apiserver-bohc9zohd7ee-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         35m\n  kube-system                 kube-controller-manager-bohc9zohd7ee-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         35m\n  kube-system                 kube-proxy-lfbdj                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         35m\n  kube-system                 kube-scheduler-bohc9zohd7ee-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         35m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-wh4kx    0 (0%)        0 (0%)      0 (0%)           0 (0%)         16m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    655m (40%)  0 (0%)\n  memory                 150Mi (4%)  0 (0%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-1Gi          0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  scheduling.k8s.io/foo  0           0\nEvents:\n  Type    Reason                   Age                From             Message\n  ----    ------                   ----               ----             -------\n  Normal  Starting                 35m                kube-proxy       \n  Normal  NodeHasSufficientMemory  35m (x6 over 35m)  kubelet          Node bohc9zohd7ee-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    35m (x6 over 35m)  kubelet          Node bohc9zohd7ee-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     35m (x6 over 35m)  kubelet          Node bohc9zohd7ee-1 status is now: NodeHasSufficientPID\n  Normal  Starting                 35m                kubelet          Starting kubelet.\n  Normal  NodeHasSufficientMemory  35m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    35m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     35m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  35m                kubelet          Updated Node Allocatable limit across pods\n  Normal  NodeReady                35m                kubelet          Node bohc9zohd7ee-1 status is now: NodeReady\n  Normal  RegisteredNode           35m                node-controller  Node bohc9zohd7ee-1 event: Registered Node bohc9zohd7ee-1 in Controller\n  Normal  Starting                 34m                kubelet          Starting kubelet.\n  Normal  NodeHasSufficientMemory  34m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    34m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     34m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasSufficientPID\n  Normal  NodeNotReady             34m                kubelet          Node bohc9zohd7ee-1 status is now: NodeNotReady\n  Normal  NodeReady                34m                kubelet          Node bohc9zohd7ee-1 status is now: NodeReady\n  Normal  NodeAllocatableEnforced  34m                kubelet          Updated Node Allocatable limit across pods\n  Normal  Starting                 24m                kubelet          Starting kubelet.\n  Normal  NodeHasSufficientMemory  24m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    24m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     24m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasSufficientPID\n  Normal  NodeNotReady             24m                kubelet          Node bohc9zohd7ee-1 status is now: NodeNotReady\n  Normal  NodeReady                24m                kubelet          Node bohc9zohd7ee-1 status is now: NodeReady\n  Normal  NodeAllocatableEnforced  24m                kubelet          Updated Node Allocatable limit across pods\n  Normal  Starting                 23m                kubelet          Starting kubelet.\n  Normal  NodeHasSufficientMemory  23m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    23m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     23m                kubelet          Node bohc9zohd7ee-1 status is now: NodeHasSufficientPID\n  Normal  NodeNotReady             23m                kubelet          Node bohc9zohd7ee-1 status is now: NodeNotReady\n  Normal  NodeAllocatableEnforced  23m                kubelet          Updated Node Allocatable limit across pods\n  Normal  NodeReady                23m                kubelet          Node bohc9zohd7ee-1 status is now: NodeReady\n"
May 27 05:32:18.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-3374 describe namespace kubectl-3374'
May 27 05:32:18.738: INFO: stderr: ""
May 27 05:32:18.738: INFO: stdout: "Name:         kubectl-3374\nLabels:       e2e-framework=kubectl\n              e2e-run=aec79d35-0b81-4f72-859e-66637ea7da42\n              kubernetes.io/metadata.name=kubectl-3374\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 05:32:18.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3374" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":356,"completed":61,"skipped":1159,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:32:18.762: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:32:18.837: INFO: Waiting up to 5m0s for pod "busybox-user-65534-29b8c325-a2ef-457a-a68b-dd6e67258377" in namespace "security-context-test-3332" to be "Succeeded or Failed"
May 27 05:32:18.846: INFO: Pod "busybox-user-65534-29b8c325-a2ef-457a-a68b-dd6e67258377": Phase="Pending", Reason="", readiness=false. Elapsed: 9.377054ms
May 27 05:32:20.863: INFO: Pod "busybox-user-65534-29b8c325-a2ef-457a-a68b-dd6e67258377": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025893886s
May 27 05:32:22.876: INFO: Pod "busybox-user-65534-29b8c325-a2ef-457a-a68b-dd6e67258377": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039215837s
May 27 05:32:22.876: INFO: Pod "busybox-user-65534-29b8c325-a2ef-457a-a68b-dd6e67258377" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
May 27 05:32:22.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3332" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":62,"skipped":1181,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:32:22.916: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 05:32:22.978: INFO: Waiting up to 5m0s for pod "downwardapi-volume-194bce1c-8777-40ed-8639-f33d978e1b3e" in namespace "projected-4435" to be "Succeeded or Failed"
May 27 05:32:22.985: INFO: Pod "downwardapi-volume-194bce1c-8777-40ed-8639-f33d978e1b3e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.125946ms
May 27 05:32:25.000: INFO: Pod "downwardapi-volume-194bce1c-8777-40ed-8639-f33d978e1b3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022078975s
May 27 05:32:27.017: INFO: Pod "downwardapi-volume-194bce1c-8777-40ed-8639-f33d978e1b3e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038843687s
May 27 05:32:29.032: INFO: Pod "downwardapi-volume-194bce1c-8777-40ed-8639-f33d978e1b3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.053969723s
STEP: Saw pod success
May 27 05:32:29.032: INFO: Pod "downwardapi-volume-194bce1c-8777-40ed-8639-f33d978e1b3e" satisfied condition "Succeeded or Failed"
May 27 05:32:29.039: INFO: Trying to get logs from node bohc9zohd7ee-2 pod downwardapi-volume-194bce1c-8777-40ed-8639-f33d978e1b3e container client-container: <nil>
STEP: delete the pod
May 27 05:32:29.083: INFO: Waiting for pod downwardapi-volume-194bce1c-8777-40ed-8639-f33d978e1b3e to disappear
May 27 05:32:29.090: INFO: Pod downwardapi-volume-194bce1c-8777-40ed-8639-f33d978e1b3e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
May 27 05:32:29.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4435" for this suite.

• [SLOW TEST:6.197 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":63,"skipped":1264,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:32:29.122: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 27 05:32:29.198: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3833  892236f7-db75-4443-9aac-2e3f1b1df1bd 10894 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 05:32:29.204: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3833  892236f7-db75-4443-9aac-2e3f1b1df1bd 10894 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 27 05:32:29.234: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3833  892236f7-db75-4443-9aac-2e3f1b1df1bd 10895 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 05:32:29.234: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3833  892236f7-db75-4443-9aac-2e3f1b1df1bd 10895 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 27 05:32:29.258: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3833  892236f7-db75-4443-9aac-2e3f1b1df1bd 10896 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 05:32:29.259: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3833  892236f7-db75-4443-9aac-2e3f1b1df1bd 10896 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 27 05:32:29.290: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3833  892236f7-db75-4443-9aac-2e3f1b1df1bd 10897 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 05:32:29.290: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3833  892236f7-db75-4443-9aac-2e3f1b1df1bd 10897 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 27 05:32:29.300: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3833  9cafbaba-7c7b-4edd-8073-0c64516ed237 10898 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 05:32:29.300: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3833  9cafbaba-7c7b-4edd-8073-0c64516ed237 10898 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 27 05:32:39.343: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3833  9cafbaba-7c7b-4edd-8073-0c64516ed237 10930 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 05:32:39.344: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3833  9cafbaba-7c7b-4edd-8073-0c64516ed237 10930 0 2022-05-27 05:32:29 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-05-27 05:32:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
May 27 05:32:49.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3833" for this suite.

• [SLOW TEST:20.292 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":356,"completed":64,"skipped":1284,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:32:49.415: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:32:49.500: INFO: Creating deployment "webserver-deployment"
May 27 05:32:49.512: INFO: Waiting for observed generation 1
May 27 05:32:51.690: INFO: Waiting for all required pods to come up
May 27 05:32:51.713: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
May 27 05:32:55.789: INFO: Waiting for deployment "webserver-deployment" to complete
May 27 05:32:55.800: INFO: Updating deployment "webserver-deployment" with a non-existent image
May 27 05:32:55.824: INFO: Updating deployment webserver-deployment
May 27 05:32:55.824: INFO: Waiting for observed generation 2
May 27 05:32:57.845: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 27 05:32:57.850: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 27 05:32:57.856: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May 27 05:32:57.874: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 27 05:32:57.874: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 27 05:32:57.879: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May 27 05:32:57.893: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
May 27 05:32:57.894: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
May 27 05:32:57.911: INFO: Updating deployment webserver-deployment
May 27 05:32:57.912: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
May 27 05:32:57.934: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 27 05:32:57.940: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May 27 05:32:57.967: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-6569  fc12d5ab-c98a-4d46-91bc-8e259bbe09ff 11176 3 2022-05-27 05:32:49 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-05-27 05:32:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:32:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000ad5828 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-57ccb67bb8" is progressing.,LastUpdateTime:2022-05-27 05:32:56 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-05-27 05:32:57 +0000 UTC,LastTransitionTime:2022-05-27 05:32:57 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

May 27 05:32:57.977: INFO: New ReplicaSet "webserver-deployment-57ccb67bb8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-57ccb67bb8  deployment-6569  5ed831c8-4cc7-4592-a498-34e786129c38 11173 3 2022-05-27 05:32:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment fc12d5ab-c98a-4d46-91bc-8e259bbe09ff 0xc000ad5f77 0xc000ad5f78}] []  [{kube-controller-manager Update apps/v1 2022-05-27 05:32:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fc12d5ab-c98a-4d46-91bc-8e259bbe09ff\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:32:55 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 57ccb67bb8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041440d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 27 05:32:57.978: INFO: All old ReplicaSets of Deployment "webserver-deployment":
May 27 05:32:57.978: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-55df494869  deployment-6569  78b1d1d7-476a-4a83-ae5f-e7add9e9a156 11172 3 2022-05-27 05:32:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment fc12d5ab-c98a-4d46-91bc-8e259bbe09ff 0xc000ad5cd7 0xc000ad5cd8}] []  [{kube-controller-manager Update apps/v1 2022-05-27 05:32:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fc12d5ab-c98a-4d46-91bc-8e259bbe09ff\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:32:52 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000ad5dc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
May 27 05:32:58.003: INFO: Pod "webserver-deployment-55df494869-4n8pq" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-4n8pq webserver-deployment-55df494869- deployment-6569  d50ccbdc-b0ac-4e71-be6c-d7bdee64f6c9 11044 0 2022-05-27 05:32:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 78b1d1d7-476a-4a83-ae5f-e7add9e9a156 0xc004145057 0xc004145058}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78b1d1d7-476a-4a83-ae5f-e7add9e9a156\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.159\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z7tdz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z7tdz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.16,PodIP:10.233.65.159,StartTime:2022-05-27 05:32:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 05:32:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://f662721909294eb602c400cbf513dde632d29b236f7047d9ef14b5d7176cdea6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.159,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.003: INFO: Pod "webserver-deployment-55df494869-6gf7p" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-6gf7p webserver-deployment-55df494869- deployment-6569  12c3166c-5ff3-4f64-924e-5145af8627b8 11175 0 2022-05-27 05:32:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 78b1d1d7-476a-4a83-ae5f-e7add9e9a156 0xc004145367 0xc004145368}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78b1d1d7-476a-4a83-ae5f-e7add9e9a156\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z9qhx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z9qhx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.005: INFO: Pod "webserver-deployment-55df494869-chq87" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-chq87 webserver-deployment-55df494869- deployment-6569  43526a8c-11f8-40fc-b83c-33f6f14d754b 11058 0 2022-05-27 05:32:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 78b1d1d7-476a-4a83-ae5f-e7add9e9a156 0xc0041454e7 0xc0041454e8}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78b1d1d7-476a-4a83-ae5f-e7add9e9a156\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.213\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mgtg4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mgtg4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.117,PodIP:10.233.64.213,StartTime:2022-05-27 05:32:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 05:32:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://02a7f8a64455b434806d31810c83a413005550265e61ea2e80d2a31a47c2565c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.213,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.011: INFO: Pod "webserver-deployment-55df494869-l7pz9" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-l7pz9 webserver-deployment-55df494869- deployment-6569  6a2c7aa4-ee6b-4e7e-8190-35e98b8c43a5 11086 0 2022-05-27 05:32:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 78b1d1d7-476a-4a83-ae5f-e7add9e9a156 0xc0041456d7 0xc0041456d8}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78b1d1d7-476a-4a83-ae5f-e7add9e9a156\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.197\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sj4ph,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sj4ph,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.180,PodIP:10.233.66.197,StartTime:2022-05-27 05:32:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 05:32:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://0d6b89c1ef0fe3249ef5025ab50bb676350d3ed99f4c081dfce03d5794fc2385,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.197,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.012: INFO: Pod "webserver-deployment-55df494869-qdmwl" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-qdmwl webserver-deployment-55df494869- deployment-6569  230de412-34c8-44d3-a7b6-91b706817f0a 11087 0 2022-05-27 05:32:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 78b1d1d7-476a-4a83-ae5f-e7add9e9a156 0xc0041458c7 0xc0041458c8}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78b1d1d7-476a-4a83-ae5f-e7add9e9a156\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.164\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ld4vl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ld4vl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.180,PodIP:10.233.66.164,StartTime:2022-05-27 05:32:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 05:32:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://defa624fcab63643bfeb11807dedac20c57d53ba14ec8cd5dcf4668b241155e0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.164,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.012: INFO: Pod "webserver-deployment-55df494869-rvcwq" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-rvcwq webserver-deployment-55df494869- deployment-6569  b3f010dd-ef94-4f4c-8fea-9df03355a1fb 11180 0 2022-05-27 05:32:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 78b1d1d7-476a-4a83-ae5f-e7add9e9a156 0xc004145ab7 0xc004145ab8}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78b1d1d7-476a-4a83-ae5f-e7add9e9a156\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g25nf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g25nf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.013: INFO: Pod "webserver-deployment-55df494869-t7pxr" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-t7pxr webserver-deployment-55df494869- deployment-6569  cc476fde-2a7e-4d7e-948d-ec3e284ba1cc 11090 0 2022-05-27 05:32:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 78b1d1d7-476a-4a83-ae5f-e7add9e9a156 0xc004145bf7 0xc004145bf8}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78b1d1d7-476a-4a83-ae5f-e7add9e9a156\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.115\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j95wn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j95wn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.180,PodIP:10.233.66.115,StartTime:2022-05-27 05:32:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 05:32:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://38c1c1782592e2d976f22baaa025f68be97dee4b020e70fcaec1f53a3f563d04,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.115,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.014: INFO: Pod "webserver-deployment-55df494869-tn8jh" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-tn8jh webserver-deployment-55df494869- deployment-6569  22fbe2a2-06fd-4d0f-83df-ea009f1b8174 11179 0 2022-05-27 05:32:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 78b1d1d7-476a-4a83-ae5f-e7add9e9a156 0xc004145de7 0xc004145de8}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78b1d1d7-476a-4a83-ae5f-e7add9e9a156\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-whzp9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-whzp9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.014: INFO: Pod "webserver-deployment-55df494869-v5xqw" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-v5xqw webserver-deployment-55df494869- deployment-6569  b1dcef95-a085-483b-a1c6-c030cbe9021d 11077 0 2022-05-27 05:32:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 78b1d1d7-476a-4a83-ae5f-e7add9e9a156 0xc004145f27 0xc004145f28}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78b1d1d7-476a-4a83-ae5f-e7add9e9a156\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.176\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jr5q9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jr5q9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.16,PodIP:10.233.65.176,StartTime:2022-05-27 05:32:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 05:32:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://45ced2833c4a6a87949f5b8f751f6f41d3ee17c544010178fed9c5ed147e450c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.176,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.016: INFO: Pod "webserver-deployment-55df494869-vzdh5" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-vzdh5 webserver-deployment-55df494869- deployment-6569  0d656cd8-e5e1-438a-b1ae-65513e92a5d3 11064 0 2022-05-27 05:32:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 78b1d1d7-476a-4a83-ae5f-e7add9e9a156 0xc000d6c337 0xc000d6c338}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78b1d1d7-476a-4a83-ae5f-e7add9e9a156\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.33\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kbd9l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kbd9l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.117,PodIP:10.233.64.33,StartTime:2022-05-27 05:32:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 05:32:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://70327d628ecb7252b185c50cf6fc91e9cd831954c558520f460446d07d529529,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.33,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.017: INFO: Pod "webserver-deployment-55df494869-z72wq" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-z72wq webserver-deployment-55df494869- deployment-6569  b2b9e9b7-0ac4-4c9e-a437-d15e34755fa0 11068 0 2022-05-27 05:32:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 78b1d1d7-476a-4a83-ae5f-e7add9e9a156 0xc000d6cad7 0xc000d6cad8}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78b1d1d7-476a-4a83-ae5f-e7add9e9a156\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.85\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pl6nk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pl6nk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.117,PodIP:10.233.64.85,StartTime:2022-05-27 05:32:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 05:32:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://032b4ad67301a0d32907793425eff7a49095accf7814911af67c448799b0b79e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.017: INFO: Pod "webserver-deployment-57ccb67bb8-774wd" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-774wd webserver-deployment-57ccb67bb8- deployment-6569  d9110b0b-bbc9-434d-84e7-8c5b2d6979ce 11149 0 2022-05-27 05:32:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 5ed831c8-4cc7-4592-a498-34e786129c38 0xc000d6d1a7 0xc000d6d1a8}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ed831c8-4cc7-4592-a498-34e786129c38\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mzqxh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mzqxh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.16,PodIP:,StartTime:2022-05-27 05:32:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.018: INFO: Pod "webserver-deployment-57ccb67bb8-bpl88" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-bpl88 webserver-deployment-57ccb67bb8- deployment-6569  94f60ecf-b413-456c-ba97-b0954a24ab8f 11153 0 2022-05-27 05:32:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 5ed831c8-4cc7-4592-a498-34e786129c38 0xc000d6d8b7 0xc000d6d8b8}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ed831c8-4cc7-4592-a498-34e786129c38\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dpmsb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dpmsb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.180,PodIP:,StartTime:2022-05-27 05:32:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.020: INFO: Pod "webserver-deployment-57ccb67bb8-cf4vf" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-cf4vf webserver-deployment-57ccb67bb8- deployment-6569  add0c73b-95ac-43f4-813a-0e6abe093f54 11126 0 2022-05-27 05:32:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 5ed831c8-4cc7-4592-a498-34e786129c38 0xc000d6df87 0xc000d6df88}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ed831c8-4cc7-4592-a498-34e786129c38\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mcj6k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mcj6k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.180,PodIP:,StartTime:2022-05-27 05:32:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.020: INFO: Pod "webserver-deployment-57ccb67bb8-kk7qd" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-kk7qd webserver-deployment-57ccb67bb8- deployment-6569  8e6a9506-baa7-4990-b665-c85dc23c52e8 11130 0 2022-05-27 05:32:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 5ed831c8-4cc7-4592-a498-34e786129c38 0xc0004824d7 0xc0004824d8}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ed831c8-4cc7-4592-a498-34e786129c38\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2mbj2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2mbj2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.117,PodIP:,StartTime:2022-05-27 05:32:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.021: INFO: Pod "webserver-deployment-57ccb67bb8-qwqhv" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-qwqhv webserver-deployment-57ccb67bb8- deployment-6569  d94669af-c302-491b-8580-14253add49fb 11116 0 2022-05-27 05:32:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 5ed831c8-4cc7-4592-a498-34e786129c38 0xc000483177 0xc000483178}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ed831c8-4cc7-4592-a498-34e786129c38\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:32:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zk628,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zk628,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:32:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.16,PodIP:,StartTime:2022-05-27 05:32:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 05:32:58.021: INFO: Pod "webserver-deployment-57ccb67bb8-vbph5" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-vbph5 webserver-deployment-57ccb67bb8- deployment-6569  e673ff3c-4bd4-4f45-9f53-4d9db8264374 11177 0 2022-05-27 05:32:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 5ed831c8-4cc7-4592-a498-34e786129c38 0xc0004838c7 0xc0004838c8}] []  [{kube-controller-manager Update v1 2022-05-27 05:32:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5ed831c8-4cc7-4592-a498-34e786129c38\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g7cpr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g7cpr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
May 27 05:32:58.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6569" for this suite.

• [SLOW TEST:8.712 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":356,"completed":65,"skipped":1300,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:32:58.129: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:32:58.281: INFO: Pod name sample-pod: Found 0 pods out of 1
May 27 05:33:03.316: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Scaling up "test-rs" replicaset 
May 27 05:33:03.348: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet
May 27 05:33:03.401: INFO: observed ReplicaSet test-rs in namespace replicaset-7756 with ReadyReplicas 1, AvailableReplicas 1
May 27 05:33:03.642: INFO: observed ReplicaSet test-rs in namespace replicaset-7756 with ReadyReplicas 1, AvailableReplicas 1
May 27 05:33:03.752: INFO: observed ReplicaSet test-rs in namespace replicaset-7756 with ReadyReplicas 1, AvailableReplicas 1
May 27 05:33:04.000: INFO: observed ReplicaSet test-rs in namespace replicaset-7756 with ReadyReplicas 1, AvailableReplicas 1
May 27 05:33:06.784: INFO: observed ReplicaSet test-rs in namespace replicaset-7756 with ReadyReplicas 2, AvailableReplicas 2
May 27 05:33:07.048: INFO: observed Replicaset test-rs in namespace replicaset-7756 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
May 27 05:33:07.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7756" for this suite.

• [SLOW TEST:8.954 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","total":356,"completed":66,"skipped":1313,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:33:07.085: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Indexed job
STEP: Ensuring job reaches completions
STEP: Ensuring pods with index for job exist
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
May 27 05:33:19.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-205" for this suite.

• [SLOW TEST:12.109 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","total":356,"completed":67,"skipped":1345,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath 
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:33:19.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
May 27 05:33:19.319: INFO: Waiting up to 1m0s for all nodes to be ready
May 27 05:34:19.403: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:34:19.412: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
May 27 05:34:23.573: INFO: found a healthy node: bohc9zohd7ee-3
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:34:37.764: INFO: pods created so far: [1 1 1]
May 27 05:34:37.765: INFO: length of pods created so far: 3
May 27 05:34:39.803: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:188
May 27 05:34:46.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-8905" for this suite.
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
May 27 05:34:46.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3609" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:87.843 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","total":356,"completed":68,"skipped":1454,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:34:47.050: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
May 27 05:34:47.173: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
May 27 05:34:47.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2781" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":356,"completed":69,"skipped":1485,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:34:47.288: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-secret-95ww
STEP: Creating a pod to test atomic-volume-subpath
May 27 05:34:47.382: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-95ww" in namespace "subpath-6707" to be "Succeeded or Failed"
May 27 05:34:47.389: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Pending", Reason="", readiness=false. Elapsed: 7.133247ms
May 27 05:34:49.403: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021319008s
May 27 05:34:51.424: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Running", Reason="", readiness=true. Elapsed: 4.042448383s
May 27 05:34:53.460: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Running", Reason="", readiness=true. Elapsed: 6.078437066s
May 27 05:34:55.472: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Running", Reason="", readiness=true. Elapsed: 8.090028419s
May 27 05:34:57.486: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Running", Reason="", readiness=true. Elapsed: 10.103778709s
May 27 05:34:59.502: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Running", Reason="", readiness=true. Elapsed: 12.119917829s
May 27 05:35:01.517: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Running", Reason="", readiness=true. Elapsed: 14.135430628s
May 27 05:35:03.536: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Running", Reason="", readiness=true. Elapsed: 16.154402452s
May 27 05:35:05.544: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Running", Reason="", readiness=true. Elapsed: 18.162561611s
May 27 05:35:07.559: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Running", Reason="", readiness=true. Elapsed: 20.176975165s
May 27 05:35:09.577: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Running", Reason="", readiness=true. Elapsed: 22.195077553s
May 27 05:35:11.598: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Running", Reason="", readiness=false. Elapsed: 24.216176065s
May 27 05:35:13.614: INFO: Pod "pod-subpath-test-secret-95ww": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.231939435s
STEP: Saw pod success
May 27 05:35:13.614: INFO: Pod "pod-subpath-test-secret-95ww" satisfied condition "Succeeded or Failed"
May 27 05:35:13.620: INFO: Trying to get logs from node bohc9zohd7ee-1 pod pod-subpath-test-secret-95ww container test-container-subpath-secret-95ww: <nil>
STEP: delete the pod
May 27 05:35:13.703: INFO: Waiting for pod pod-subpath-test-secret-95ww to disappear
May 27 05:35:13.712: INFO: Pod pod-subpath-test-secret-95ww no longer exists
STEP: Deleting pod pod-subpath-test-secret-95ww
May 27 05:35:13.713: INFO: Deleting pod "pod-subpath-test-secret-95ww" in namespace "subpath-6707"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
May 27 05:35:13.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6707" for this suite.

• [SLOW TEST:26.454 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","total":356,"completed":70,"skipped":1527,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:35:13.748: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-4931448b-3882-445b-957d-835fad393681
STEP: Creating a pod to test consume secrets
May 27 05:35:13.840: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e75915cd-21cb-4c81-b91b-8d466065fe83" in namespace "projected-7581" to be "Succeeded or Failed"
May 27 05:35:13.849: INFO: Pod "pod-projected-secrets-e75915cd-21cb-4c81-b91b-8d466065fe83": Phase="Pending", Reason="", readiness=false. Elapsed: 9.201696ms
May 27 05:35:15.859: INFO: Pod "pod-projected-secrets-e75915cd-21cb-4c81-b91b-8d466065fe83": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019318776s
May 27 05:35:17.881: INFO: Pod "pod-projected-secrets-e75915cd-21cb-4c81-b91b-8d466065fe83": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041322742s
May 27 05:35:19.895: INFO: Pod "pod-projected-secrets-e75915cd-21cb-4c81-b91b-8d466065fe83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.055621138s
STEP: Saw pod success
May 27 05:35:19.895: INFO: Pod "pod-projected-secrets-e75915cd-21cb-4c81-b91b-8d466065fe83" satisfied condition "Succeeded or Failed"
May 27 05:35:19.902: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-secrets-e75915cd-21cb-4c81-b91b-8d466065fe83 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 27 05:35:19.956: INFO: Waiting for pod pod-projected-secrets-e75915cd-21cb-4c81-b91b-8d466065fe83 to disappear
May 27 05:35:19.962: INFO: Pod pod-projected-secrets-e75915cd-21cb-4c81-b91b-8d466065fe83 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
May 27 05:35:19.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7581" for this suite.

• [SLOW TEST:6.235 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":71,"skipped":1544,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:35:19.983: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
May 27 05:35:20.112: INFO: The status of Pod labelsupdate57e72968-7a17-4a52-8ffc-4fc038680f16 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:35:22.131: INFO: The status of Pod labelsupdate57e72968-7a17-4a52-8ffc-4fc038680f16 is Running (Ready = true)
May 27 05:35:22.687: INFO: Successfully updated pod "labelsupdate57e72968-7a17-4a52-8ffc-4fc038680f16"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
May 27 05:35:24.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6951" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":72,"skipped":1548,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:35:24.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:35:24.815: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:35:25.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5961" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":356,"completed":73,"skipped":1560,"failed":0}

------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:35:25.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:35:25.732: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-ba132b79-fa64-4433-8809-27d4f3e42930" in namespace "security-context-test-3151" to be "Succeeded or Failed"
May 27 05:35:25.738: INFO: Pod "alpine-nnp-false-ba132b79-fa64-4433-8809-27d4f3e42930": Phase="Pending", Reason="", readiness=false. Elapsed: 6.316598ms
May 27 05:35:27.754: INFO: Pod "alpine-nnp-false-ba132b79-fa64-4433-8809-27d4f3e42930": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022268536s
May 27 05:35:29.768: INFO: Pod "alpine-nnp-false-ba132b79-fa64-4433-8809-27d4f3e42930": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03589697s
May 27 05:35:31.783: INFO: Pod "alpine-nnp-false-ba132b79-fa64-4433-8809-27d4f3e42930": Phase="Pending", Reason="", readiness=false. Elapsed: 6.050758587s
May 27 05:35:33.802: INFO: Pod "alpine-nnp-false-ba132b79-fa64-4433-8809-27d4f3e42930": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.069954258s
May 27 05:35:33.802: INFO: Pod "alpine-nnp-false-ba132b79-fa64-4433-8809-27d4f3e42930" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
May 27 05:35:33.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3151" for this suite.

• [SLOW TEST:8.311 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:298
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":74,"skipped":1560,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:35:33.836: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:35:33.882: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
May 27 05:35:35.965: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
May 27 05:35:36.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4582" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":356,"completed":75,"skipped":1571,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:35:37.011: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 05:35:37.079: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5db364e7-11d2-4fb3-b209-7cff25a5a56e" in namespace "downward-api-5753" to be "Succeeded or Failed"
May 27 05:35:37.085: INFO: Pod "downwardapi-volume-5db364e7-11d2-4fb3-b209-7cff25a5a56e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.09352ms
May 27 05:35:39.100: INFO: Pod "downwardapi-volume-5db364e7-11d2-4fb3-b209-7cff25a5a56e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020388029s
May 27 05:35:41.115: INFO: Pod "downwardapi-volume-5db364e7-11d2-4fb3-b209-7cff25a5a56e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035424505s
STEP: Saw pod success
May 27 05:35:41.115: INFO: Pod "downwardapi-volume-5db364e7-11d2-4fb3-b209-7cff25a5a56e" satisfied condition "Succeeded or Failed"
May 27 05:35:41.119: INFO: Trying to get logs from node bohc9zohd7ee-1 pod downwardapi-volume-5db364e7-11d2-4fb3-b209-7cff25a5a56e container client-container: <nil>
STEP: delete the pod
May 27 05:35:41.151: INFO: Waiting for pod downwardapi-volume-5db364e7-11d2-4fb3-b209-7cff25a5a56e to disappear
May 27 05:35:41.156: INFO: Pod downwardapi-volume-5db364e7-11d2-4fb3-b209-7cff25a5a56e no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
May 27 05:35:41.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5753" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":76,"skipped":1588,"failed":0}
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:35:41.175: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-c332fe37-efe5-4460-83a4-5dc1d3667855
STEP: Creating secret with name s-test-opt-upd-0ec6bafb-8a47-42b9-82dd-239ef4b5bf9e
STEP: Creating the pod
May 27 05:35:41.314: INFO: The status of Pod pod-secrets-c1e9e76c-d979-4329-b38a-a2dc20e7dbd8 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:35:43.338: INFO: The status of Pod pod-secrets-c1e9e76c-d979-4329-b38a-a2dc20e7dbd8 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:35:45.330: INFO: The status of Pod pod-secrets-c1e9e76c-d979-4329-b38a-a2dc20e7dbd8 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-c332fe37-efe5-4460-83a4-5dc1d3667855
STEP: Updating secret s-test-opt-upd-0ec6bafb-8a47-42b9-82dd-239ef4b5bf9e
STEP: Creating secret with name s-test-opt-create-5f707216-66b9-4361-98ef-12eb102c88a2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
May 27 05:37:10.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3267" for this suite.

• [SLOW TEST:89.153 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":77,"skipped":1592,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:37:10.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-befc2f72-348a-4217-86e1-9ae8845976be
STEP: Creating a pod to test consume configMaps
May 27 05:37:10.410: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-65afd8c4-1478-4e5c-8744-f90554dc2cd2" in namespace "projected-5615" to be "Succeeded or Failed"
May 27 05:37:10.417: INFO: Pod "pod-projected-configmaps-65afd8c4-1478-4e5c-8744-f90554dc2cd2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.884109ms
May 27 05:37:12.430: INFO: Pod "pod-projected-configmaps-65afd8c4-1478-4e5c-8744-f90554dc2cd2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020085208s
May 27 05:37:14.444: INFO: Pod "pod-projected-configmaps-65afd8c4-1478-4e5c-8744-f90554dc2cd2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033705682s
May 27 05:37:16.466: INFO: Pod "pod-projected-configmaps-65afd8c4-1478-4e5c-8744-f90554dc2cd2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.055897857s
STEP: Saw pod success
May 27 05:37:16.467: INFO: Pod "pod-projected-configmaps-65afd8c4-1478-4e5c-8744-f90554dc2cd2" satisfied condition "Succeeded or Failed"
May 27 05:37:16.479: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-configmaps-65afd8c4-1478-4e5c-8744-f90554dc2cd2 container agnhost-container: <nil>
STEP: delete the pod
May 27 05:37:16.566: INFO: Waiting for pod pod-projected-configmaps-65afd8c4-1478-4e5c-8744-f90554dc2cd2 to disappear
May 27 05:37:16.576: INFO: Pod pod-projected-configmaps-65afd8c4-1478-4e5c-8744-f90554dc2cd2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
May 27 05:37:16.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5615" for this suite.

• [SLOW TEST:6.277 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":78,"skipped":1633,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:37:16.612: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replication controller my-hostname-basic-c140cad4-e82f-45d4-a734-c04c708c8a00
May 27 05:37:16.682: INFO: Pod name my-hostname-basic-c140cad4-e82f-45d4-a734-c04c708c8a00: Found 0 pods out of 1
May 27 05:37:21.703: INFO: Pod name my-hostname-basic-c140cad4-e82f-45d4-a734-c04c708c8a00: Found 1 pods out of 1
May 27 05:37:21.703: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c140cad4-e82f-45d4-a734-c04c708c8a00" are running
May 27 05:37:21.710: INFO: Pod "my-hostname-basic-c140cad4-e82f-45d4-a734-c04c708c8a00-brfhz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-27 05:37:16 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-27 05:37:18 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-27 05:37:18 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-27 05:37:16 +0000 UTC Reason: Message:}])
May 27 05:37:21.710: INFO: Trying to dial the pod
May 27 05:37:26.750: INFO: Controller my-hostname-basic-c140cad4-e82f-45d4-a734-c04c708c8a00: Got expected result from replica 1 [my-hostname-basic-c140cad4-e82f-45d4-a734-c04c708c8a00-brfhz]: "my-hostname-basic-c140cad4-e82f-45d4-a734-c04c708c8a00-brfhz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
May 27 05:37:26.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2892" for this suite.

• [SLOW TEST:10.161 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":79,"skipped":1652,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:37:26.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
May 27 05:37:26.826: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:37:31.246: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:37:55.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4242" for this suite.

• [SLOW TEST:28.682 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":356,"completed":80,"skipped":1707,"failed":0}
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:37:55.461: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-9590/configmap-test-a93b882d-da9f-47dc-ad72-7beb6860ede2
STEP: Creating a pod to test consume configMaps
May 27 05:37:55.582: INFO: Waiting up to 5m0s for pod "pod-configmaps-b5135c92-0924-42b4-9240-99f9c80dd571" in namespace "configmap-9590" to be "Succeeded or Failed"
May 27 05:37:55.594: INFO: Pod "pod-configmaps-b5135c92-0924-42b4-9240-99f9c80dd571": Phase="Pending", Reason="", readiness=false. Elapsed: 12.087719ms
May 27 05:37:57.607: INFO: Pod "pod-configmaps-b5135c92-0924-42b4-9240-99f9c80dd571": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024538581s
May 27 05:37:59.618: INFO: Pod "pod-configmaps-b5135c92-0924-42b4-9240-99f9c80dd571": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03533329s
May 27 05:38:01.629: INFO: Pod "pod-configmaps-b5135c92-0924-42b4-9240-99f9c80dd571": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.046219672s
STEP: Saw pod success
May 27 05:38:01.629: INFO: Pod "pod-configmaps-b5135c92-0924-42b4-9240-99f9c80dd571" satisfied condition "Succeeded or Failed"
May 27 05:38:01.634: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-configmaps-b5135c92-0924-42b4-9240-99f9c80dd571 container env-test: <nil>
STEP: delete the pod
May 27 05:38:01.686: INFO: Waiting for pod pod-configmaps-b5135c92-0924-42b4-9240-99f9c80dd571 to disappear
May 27 05:38:01.704: INFO: Pod pod-configmaps-b5135c92-0924-42b4-9240-99f9c80dd571 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
May 27 05:38:01.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9590" for this suite.

• [SLOW TEST:6.262 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":356,"completed":81,"skipped":1707,"failed":0}
S
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:38:01.725: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
May 27 05:38:01.767: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
May 27 05:38:07.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1844" for this suite.

• [SLOW TEST:6.082 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":356,"completed":82,"skipped":1708,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:38:07.812: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
May 27 05:38:09.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9948" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","total":356,"completed":83,"skipped":1747,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:38:09.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-4318
STEP: creating service affinity-nodeport-transition in namespace services-4318
STEP: creating replication controller affinity-nodeport-transition in namespace services-4318
I0527 05:38:10.059471      15 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-4318, replica count: 3
I0527 05:38:13.110629      15 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 27 05:38:13.146: INFO: Creating new exec pod
May 27 05:38:16.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-4318 exec execpod-affinityhhkhb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
May 27 05:38:16.599: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
May 27 05:38:16.600: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:38:16.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-4318 exec execpod-affinityhhkhb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.46.189 80'
May 27 05:38:16.801: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.46.189 80\nConnection to 10.233.46.189 80 port [tcp/http] succeeded!\n"
May 27 05:38:16.801: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:38:16.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-4318 exec execpod-affinityhhkhb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.117 32343'
May 27 05:38:17.035: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.117 32343\nConnection to 192.168.121.117 32343 port [tcp/*] succeeded!\n"
May 27 05:38:17.035: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:38:17.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-4318 exec execpod-affinityhhkhb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.180 32343'
May 27 05:38:17.233: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.180 32343\nConnection to 192.168.121.180 32343 port [tcp/*] succeeded!\n"
May 27 05:38:17.234: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:38:17.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-4318 exec execpod-affinityhhkhb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.180:32343/ ; done'
May 27 05:38:18.193: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n"
May 27 05:38:18.193: INFO: stdout: "\naffinity-nodeport-transition-qvttx\naffinity-nodeport-transition-qvttx\naffinity-nodeport-transition-qvttx\naffinity-nodeport-transition-qvttx\naffinity-nodeport-transition-qvttx\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-lgjd8\naffinity-nodeport-transition-qvttx\naffinity-nodeport-transition-qvttx\naffinity-nodeport-transition-lgjd8\naffinity-nodeport-transition-qvttx\naffinity-nodeport-transition-lgjd8\naffinity-nodeport-transition-lgjd8\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-qvttx"
May 27 05:38:18.193: INFO: Received response from host: affinity-nodeport-transition-qvttx
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-qvttx
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-qvttx
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-qvttx
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-qvttx
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-lgjd8
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-qvttx
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-qvttx
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-lgjd8
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-qvttx
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-lgjd8
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-lgjd8
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.194: INFO: Received response from host: affinity-nodeport-transition-qvttx
May 27 05:38:18.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-4318 exec execpod-affinityhhkhb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.180:32343/ ; done'
May 27 05:38:18.770: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.180:32343/\n"
May 27 05:38:18.771: INFO: stdout: "\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b\naffinity-nodeport-transition-hxv2b"
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Received response from host: affinity-nodeport-transition-hxv2b
May 27 05:38:18.771: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4318, will wait for the garbage collector to delete the pods
May 27 05:38:18.927: INFO: Deleting ReplicationController affinity-nodeport-transition took: 11.303451ms
May 27 05:38:19.049: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 122.062567ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 05:38:21.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4318" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:11.423 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":84,"skipped":1769,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:38:21.371: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-4dbf191d-d46f-4536-aecc-bd1137d6ea57
STEP: Creating configMap with name cm-test-opt-upd-216c1a12-c4be-4a43-8dc9-cf63581abc14
STEP: Creating the pod
May 27 05:38:21.498: INFO: The status of Pod pod-projected-configmaps-4b9d166f-4a8f-489c-b5bb-dfb2913f0676 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:38:23.516: INFO: The status of Pod pod-projected-configmaps-4b9d166f-4a8f-489c-b5bb-dfb2913f0676 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:38:25.508: INFO: The status of Pod pod-projected-configmaps-4b9d166f-4a8f-489c-b5bb-dfb2913f0676 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-4dbf191d-d46f-4536-aecc-bd1137d6ea57
STEP: Updating configmap cm-test-opt-upd-216c1a12-c4be-4a43-8dc9-cf63581abc14
STEP: Creating configMap with name cm-test-opt-create-c48808ab-c548-4362-a081-d0186b29ef6d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
May 27 05:39:34.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9414" for this suite.

• [SLOW TEST:72.992 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":85,"skipped":1791,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:39:34.365: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
May 27 05:39:45.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5034" for this suite.

• [SLOW TEST:11.157 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":356,"completed":86,"skipped":1793,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:39:45.528: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-9435
STEP: creating service affinity-clusterip-transition in namespace services-9435
STEP: creating replication controller affinity-clusterip-transition in namespace services-9435
I0527 05:39:45.623522      15 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-9435, replica count: 3
I0527 05:39:48.675384      15 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 27 05:39:48.689: INFO: Creating new exec pod
May 27 05:39:51.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-9435 exec execpod-affinityghmnj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
May 27 05:39:51.982: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
May 27 05:39:51.982: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:39:51.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-9435 exec execpod-affinityghmnj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.22.10 80'
May 27 05:39:52.392: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.22.10 80\nConnection to 10.233.22.10 80 port [tcp/http] succeeded!\n"
May 27 05:39:52.392: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:39:52.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-9435 exec execpod-affinityghmnj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.22.10:80/ ; done'
May 27 05:39:52.805: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n"
May 27 05:39:52.806: INFO: stdout: "\naffinity-clusterip-transition-wlcz6\naffinity-clusterip-transition-wlcz6\naffinity-clusterip-transition-wlcz6\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-wlcz6\naffinity-clusterip-transition-lzgkr\naffinity-clusterip-transition-lzgkr\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-wlcz6\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-lzgkr\naffinity-clusterip-transition-wlcz6\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-lzgkr\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n"
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-wlcz6
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-wlcz6
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-wlcz6
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-wlcz6
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-lzgkr
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-lzgkr
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-wlcz6
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-lzgkr
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-wlcz6
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-lzgkr
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:52.806: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:52.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-9435 exec execpod-affinityghmnj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.22.10:80/ ; done'
May 27 05:39:53.339: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.22.10:80/\n"
May 27 05:39:53.339: INFO: stdout: "\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n\naffinity-clusterip-transition-6mb5n"
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Received response from host: affinity-clusterip-transition-6mb5n
May 27 05:39:53.339: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-9435, will wait for the garbage collector to delete the pods
May 27 05:39:53.443: INFO: Deleting ReplicationController affinity-clusterip-transition took: 23.037351ms
May 27 05:39:53.644: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 200.854741ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 05:39:56.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9435" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:10.792 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":87,"skipped":1868,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:39:56.327: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 27 05:39:56.403: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5199  437fb1bc-59a5-4ff3-8a17-304e5c358448 13384 0 2022-05-27 05:39:56 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-05-27 05:39:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 05:39:56.404: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5199  437fb1bc-59a5-4ff3-8a17-304e5c358448 13385 0 2022-05-27 05:39:56 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-05-27 05:39:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 27 05:39:56.443: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5199  437fb1bc-59a5-4ff3-8a17-304e5c358448 13386 0 2022-05-27 05:39:56 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-05-27 05:39:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 05:39:56.444: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5199  437fb1bc-59a5-4ff3-8a17-304e5c358448 13387 0 2022-05-27 05:39:56 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-05-27 05:39:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
May 27 05:39:56.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5199" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":356,"completed":88,"skipped":1930,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:39:56.476: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 05:39:58.217: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 27 05:40:00.266: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 5, 39, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 39, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 39, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 39, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 05:40:03.334: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:40:13.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3957" for this suite.
STEP: Destroying namespace "webhook-3957-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:17.282 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":356,"completed":89,"skipped":1937,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:40:13.761: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-9485
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 27 05:40:13.831: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May 27 05:40:13.943: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:40:15.952: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:40:17.959: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:40:19.954: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:40:21.961: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:40:23.956: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:40:25.950: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:40:27.958: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:40:29.953: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:40:31.956: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:40:33.969: INFO: The status of Pod netserver-0 is Running (Ready = true)
May 27 05:40:33.980: INFO: The status of Pod netserver-1 is Running (Ready = true)
May 27 05:40:33.992: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
May 27 05:40:36.262: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
May 27 05:40:36.262: INFO: Going to poll 10.233.66.244 on port 8081 at least 0 times, with a maximum of 39 tries before failing
May 27 05:40:36.274: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.244 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9485 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 05:40:36.274: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:40:36.275: INFO: ExecWithOptions: Clientset creation
May 27 05:40:36.276: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9485/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.244+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May 27 05:40:37.497: INFO: Found all 1 expected endpoints: [netserver-0]
May 27 05:40:37.497: INFO: Going to poll 10.233.64.182 on port 8081 at least 0 times, with a maximum of 39 tries before failing
May 27 05:40:37.513: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.182 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9485 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 05:40:37.513: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:40:37.515: INFO: ExecWithOptions: Clientset creation
May 27 05:40:37.515: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9485/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.182+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May 27 05:40:38.633: INFO: Found all 1 expected endpoints: [netserver-1]
May 27 05:40:38.633: INFO: Going to poll 10.233.65.72 on port 8081 at least 0 times, with a maximum of 39 tries before failing
May 27 05:40:38.644: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.72 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9485 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 05:40:38.644: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:40:38.645: INFO: ExecWithOptions: Clientset creation
May 27 05:40:38.645: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9485/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.72+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May 27 05:40:39.768: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
May 27 05:40:39.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9485" for this suite.

• [SLOW TEST:26.032 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":90,"skipped":1948,"failed":0}
SSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:40:39.795: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
May 27 05:40:39.853: INFO: Waiting up to 1m0s for all nodes to be ready
May 27 05:41:39.914: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
May 27 05:41:39.995: INFO: Created pod: pod0-0-sched-preemption-low-priority
May 27 05:41:40.008: INFO: Created pod: pod0-1-sched-preemption-medium-priority
May 27 05:41:40.075: INFO: Created pod: pod1-0-sched-preemption-medium-priority
May 27 05:41:40.178: INFO: Created pod: pod1-1-sched-preemption-medium-priority
May 27 05:41:40.272: INFO: Created pod: pod2-0-sched-preemption-medium-priority
May 27 05:41:40.294: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a high priority pod that has same requirements as that of lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
May 27 05:41:52.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-6375" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:72.809 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","total":356,"completed":91,"skipped":1954,"failed":0}
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:41:52.608: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:41:52.682: INFO: Creating deployment "test-recreate-deployment"
May 27 05:41:52.696: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 27 05:41:52.723: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
May 27 05:41:54.742: INFO: Waiting deployment "test-recreate-deployment" to complete
May 27 05:41:54.748: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 5, 41, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 41, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 41, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 41, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-848969dbcd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 05:41:56.766: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 27 05:41:56.800: INFO: Updating deployment test-recreate-deployment
May 27 05:41:56.801: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May 27 05:41:57.087: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5593  2ebebf66-8115-478f-8389-77c750b9daef 13988 2 2022-05-27 05:41:52 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-05-27 05:41:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:41:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002d61558 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-05-27 05:41:57 +0000 UTC,LastTransitionTime:2022-05-27 05:41:57 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-cd8586fc7" is progressing.,LastUpdateTime:2022-05-27 05:41:57 +0000 UTC,LastTransitionTime:2022-05-27 05:41:52 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

May 27 05:41:57.097: INFO: New ReplicaSet "test-recreate-deployment-cd8586fc7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-cd8586fc7  deployment-5593  df97c519-562b-42ed-b79a-c0613e604856 13985 1 2022-05-27 05:41:56 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 2ebebf66-8115-478f-8389-77c750b9daef 0xc0026c2280 0xc0026c2281}] []  [{kube-controller-manager Update apps/v1 2022-05-27 05:41:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2ebebf66-8115-478f-8389-77c750b9daef\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:41:56 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: cd8586fc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0026c2318 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 27 05:41:57.097: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 27 05:41:57.098: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-848969dbcd  deployment-5593  64bc033d-79b4-4e7d-8656-bbb2739f99d1 13975 2 2022-05-27 05:41:52 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:848969dbcd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 2ebebf66-8115-478f-8389-77c750b9daef 0xc0026c2167 0xc0026c2168}] []  [{kube-controller-manager Update apps/v1 2022-05-27 05:41:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2ebebf66-8115-478f-8389-77c750b9daef\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:41:56 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 848969dbcd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:848969dbcd] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.36 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0026c2218 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 27 05:41:57.103: INFO: Pod "test-recreate-deployment-cd8586fc7-wknjs" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-cd8586fc7-wknjs test-recreate-deployment-cd8586fc7- deployment-5593  a8953e9b-a506-43de-ac5d-df24cffbc25d 13987 0 2022-05-27 05:41:56 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-cd8586fc7 df97c519-562b-42ed-b79a-c0613e604856 0xc0026c2780 0xc0026c2781}] []  [{kube-controller-manager Update v1 2022-05-27 05:41:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"df97c519-562b-42ed-b79a-c0613e604856\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:41:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p2nw2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p2nw2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:41:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:41:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:41:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:41:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.16,PodIP:,StartTime:2022-05-27 05:41:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
May 27 05:41:57.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5593" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":92,"skipped":1957,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:41:57.139: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
May 27 05:41:57.185: INFO: Waiting up to 1m0s for all nodes to be ready
May 27 05:42:57.306: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:42:57.319: INFO: Starting informer...
STEP: Starting pods...
May 27 05:42:57.564: INFO: Pod1 is running on bohc9zohd7ee-3. Tainting Node
May 27 05:42:59.818: INFO: Pod2 is running on bohc9zohd7ee-3. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
May 27 05:43:05.740: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
May 27 05:43:25.733: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:188
May 27 05:43:25.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-762" for this suite.

• [SLOW TEST:88.659 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":356,"completed":93,"skipped":2029,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:43:25.800: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 05:43:27.088: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 05:43:30.149: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
May 27 05:43:34.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=webhook-5299 attach --namespace=webhook-5299 to-be-attached-pod -i -c=container1'
May 27 05:43:34.434: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:43:34.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5299" for this suite.
STEP: Destroying namespace "webhook-5299-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:8.791 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":356,"completed":94,"skipped":2041,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:43:34.602: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:43:36.730: INFO: Deleting pod "var-expansion-355c45fc-d97f-4395-8e0b-e99379409fbc" in namespace "var-expansion-2364"
May 27 05:43:36.750: INFO: Wait up to 5m0s for pod "var-expansion-355c45fc-d97f-4395-8e0b-e99379409fbc" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
May 27 05:43:38.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2364" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","total":356,"completed":95,"skipped":2099,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:43:38.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:43:38.840: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
May 27 05:43:43.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-7419 --namespace=crd-publish-openapi-7419 create -f -'
May 27 05:43:45.201: INFO: stderr: ""
May 27 05:43:45.201: INFO: stdout: "e2e-test-crd-publish-openapi-1905-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May 27 05:43:45.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-7419 --namespace=crd-publish-openapi-7419 delete e2e-test-crd-publish-openapi-1905-crds test-cr'
May 27 05:43:45.399: INFO: stderr: ""
May 27 05:43:45.399: INFO: stdout: "e2e-test-crd-publish-openapi-1905-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
May 27 05:43:45.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-7419 --namespace=crd-publish-openapi-7419 apply -f -'
May 27 05:43:45.894: INFO: stderr: ""
May 27 05:43:45.897: INFO: stdout: "e2e-test-crd-publish-openapi-1905-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May 27 05:43:45.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-7419 --namespace=crd-publish-openapi-7419 delete e2e-test-crd-publish-openapi-1905-crds test-cr'
May 27 05:43:46.090: INFO: stderr: ""
May 27 05:43:46.090: INFO: stdout: "e2e-test-crd-publish-openapi-1905-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
May 27 05:43:46.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-7419 explain e2e-test-crd-publish-openapi-1905-crds'
May 27 05:43:46.387: INFO: stderr: ""
May 27 05:43:46.387: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1905-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:43:50.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7419" for this suite.

• [SLOW TEST:11.679 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":356,"completed":96,"skipped":2121,"failed":0}
SS
------------------------------
[sig-node] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:43:50.480: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:43:50.549: INFO: The status of Pod busybox-host-aliasesacb23a8b-cb1c-45b4-8d31-d5b294b0c44c is Pending, waiting for it to be Running (with Ready = true)
May 27 05:43:52.563: INFO: The status of Pod busybox-host-aliasesacb23a8b-cb1c-45b4-8d31-d5b294b0c44c is Pending, waiting for it to be Running (with Ready = true)
May 27 05:43:54.564: INFO: The status of Pod busybox-host-aliasesacb23a8b-cb1c-45b4-8d31-d5b294b0c44c is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
May 27 05:43:54.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3411" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":97,"skipped":2123,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:43:54.630: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service endpoint-test2 in namespace services-2716
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2716 to expose endpoints map[]
May 27 05:43:54.768: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
May 27 05:43:55.793: INFO: successfully validated that service endpoint-test2 in namespace services-2716 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2716
May 27 05:43:55.834: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:43:57.852: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2716 to expose endpoints map[pod1:[80]]
May 27 05:43:57.874: INFO: successfully validated that service endpoint-test2 in namespace services-2716 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1
May 27 05:43:57.874: INFO: Creating new exec pod
May 27 05:44:00.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-2716 exec execpod8kbxz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
May 27 05:44:01.186: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
May 27 05:44:01.187: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:44:01.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-2716 exec execpod8kbxz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.17.111 80'
May 27 05:44:01.549: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.17.111 80\nConnection to 10.233.17.111 80 port [tcp/http] succeeded!\n"
May 27 05:44:01.549: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-2716
May 27 05:44:01.570: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:44:03.583: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2716 to expose endpoints map[pod1:[80] pod2:[80]]
May 27 05:44:03.608: INFO: successfully validated that service endpoint-test2 in namespace services-2716 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2
May 27 05:44:04.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-2716 exec execpod8kbxz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
May 27 05:44:04.881: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
May 27 05:44:04.881: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:44:04.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-2716 exec execpod8kbxz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.17.111 80'
May 27 05:44:05.104: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.17.111 80\nConnection to 10.233.17.111 80 port [tcp/http] succeeded!\n"
May 27 05:44:05.104: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2716
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2716 to expose endpoints map[pod2:[80]]
May 27 05:44:05.246: INFO: successfully validated that service endpoint-test2 in namespace services-2716 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2
May 27 05:44:06.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-2716 exec execpod8kbxz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
May 27 05:44:06.480: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
May 27 05:44:06.480: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:44:06.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-2716 exec execpod8kbxz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.17.111 80'
May 27 05:44:06.682: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.17.111 80\nConnection to 10.233.17.111 80 port [tcp/http] succeeded!\n"
May 27 05:44:06.682: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-2716
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2716 to expose endpoints map[]
May 27 05:44:07.806: INFO: successfully validated that service endpoint-test2 in namespace services-2716 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 05:44:07.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2716" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:13.244 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":356,"completed":98,"skipped":2154,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:44:07.880: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:44:07.948: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 27 05:44:12.961: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 27 05:44:12.961: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 27 05:44:14.971: INFO: Creating deployment "test-rollover-deployment"
May 27 05:44:14.994: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 27 05:44:17.007: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 27 05:44:17.022: INFO: Ensure that both replica sets have 1 created replica
May 27 05:44:17.035: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 27 05:44:17.057: INFO: Updating deployment test-rollover-deployment
May 27 05:44:17.057: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 27 05:44:19.083: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 27 05:44:19.099: INFO: Make sure deployment "test-rollover-deployment" is complete
May 27 05:44:19.116: INFO: all replica sets need to contain the pod-template-hash label
May 27 05:44:19.116: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 44, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-77745f886c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 05:44:21.139: INFO: all replica sets need to contain the pod-template-hash label
May 27 05:44:21.140: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 44, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-77745f886c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 05:44:23.143: INFO: all replica sets need to contain the pod-template-hash label
May 27 05:44:23.144: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 44, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-77745f886c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 05:44:25.133: INFO: all replica sets need to contain the pod-template-hash label
May 27 05:44:25.134: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 44, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-77745f886c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 05:44:27.140: INFO: all replica sets need to contain the pod-template-hash label
May 27 05:44:27.141: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 44, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 44, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-77745f886c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 05:44:29.137: INFO: 
May 27 05:44:29.137: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May 27 05:44:29.161: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-8032  31a04823-c244-4d21-aded-dc5c58e9b24e 14875 2 2022-05-27 05:44:14 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-05-27 05:44:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:44:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.36 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004ceb248 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-05-27 05:44:15 +0000 UTC,LastTransitionTime:2022-05-27 05:44:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-77745f886c" has successfully progressed.,LastUpdateTime:2022-05-27 05:44:28 +0000 UTC,LastTransitionTime:2022-05-27 05:44:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May 27 05:44:29.170: INFO: New ReplicaSet "test-rollover-deployment-77745f886c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-77745f886c  deployment-8032  70b3e47a-bcc1-44b1-bc58-cfced208f422 14865 2 2022-05-27 05:44:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:77745f886c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 31a04823-c244-4d21-aded-dc5c58e9b24e 0xc004ceb787 0xc004ceb788}] []  [{kube-controller-manager Update apps/v1 2022-05-27 05:44:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"31a04823-c244-4d21-aded-dc5c58e9b24e\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:44:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 77745f886c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:77745f886c] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.36 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004ceb858 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May 27 05:44:29.170: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 27 05:44:29.170: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-8032  c28ce618-0e86-4420-bc0a-ef029a47635e 14874 2 2022-05-27 05:44:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 31a04823-c244-4d21-aded-dc5c58e9b24e 0xc004ceb607 0xc004ceb608}] []  [{e2e.test Update apps/v1 2022-05-27 05:44:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:44:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"31a04823-c244-4d21-aded-dc5c58e9b24e\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:44:28 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004ceb6f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 27 05:44:29.170: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-87f8f6dcf  deployment-8032  46f0ef7d-4f97-43b5-839c-0af62960eb51 14820 2 2022-05-27 05:44:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 31a04823-c244-4d21-aded-dc5c58e9b24e 0xc004ceb8c0 0xc004ceb8c1}] []  [{kube-controller-manager Update apps/v1 2022-05-27 05:44:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"31a04823-c244-4d21-aded-dc5c58e9b24e\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 05:44:17 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 87f8f6dcf,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004ceb968 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 27 05:44:29.179: INFO: Pod "test-rollover-deployment-77745f886c-gcgnx" is available:
&Pod{ObjectMeta:{test-rollover-deployment-77745f886c-gcgnx test-rollover-deployment-77745f886c- deployment-8032  08d9aba9-7631-4938-a250-a733baa8f399 14842 0 2022-05-27 05:44:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:77745f886c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-77745f886c 70b3e47a-bcc1-44b1-bc58-cfced208f422 0xc004cebea7 0xc004cebea8}] []  [{kube-controller-manager Update v1 2022-05-27 05:44:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"70b3e47a-bcc1-44b1-bc58-cfced208f422\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 05:44:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.159\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2mv9f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.36,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2mv9f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:44:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:44:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:44:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 05:44:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.16,PodIP:10.233.65.159,StartTime:2022-05-27 05:44:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 05:44:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.36,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:c8cf9027e6db0e7de9b172400b209da8fe7aac863d19352723d2457847457403,ContainerID:cri-o://5131fe8f10491deac9aaa7bab667aec6ea69b3fd8f688b0912950004d3cb18de,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.159,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
May 27 05:44:29.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8032" for this suite.

• [SLOW TEST:21.333 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":356,"completed":99,"skipped":2192,"failed":0}
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:44:29.214: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-99197b32-bf3b-4f16-869e-60ba4d222468
STEP: Creating a pod to test consume secrets
May 27 05:44:29.308: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4a43edb2-3f16-43eb-9f6b-d17efa07182d" in namespace "projected-9818" to be "Succeeded or Failed"
May 27 05:44:29.316: INFO: Pod "pod-projected-secrets-4a43edb2-3f16-43eb-9f6b-d17efa07182d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.037847ms
May 27 05:44:31.335: INFO: Pod "pod-projected-secrets-4a43edb2-3f16-43eb-9f6b-d17efa07182d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027372043s
May 27 05:44:33.350: INFO: Pod "pod-projected-secrets-4a43edb2-3f16-43eb-9f6b-d17efa07182d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042638179s
STEP: Saw pod success
May 27 05:44:33.351: INFO: Pod "pod-projected-secrets-4a43edb2-3f16-43eb-9f6b-d17efa07182d" satisfied condition "Succeeded or Failed"
May 27 05:44:33.359: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-secrets-4a43edb2-3f16-43eb-9f6b-d17efa07182d container projected-secret-volume-test: <nil>
STEP: delete the pod
May 27 05:44:33.402: INFO: Waiting for pod pod-projected-secrets-4a43edb2-3f16-43eb-9f6b-d17efa07182d to disappear
May 27 05:44:33.409: INFO: Pod pod-projected-secrets-4a43edb2-3f16-43eb-9f6b-d17efa07182d no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
May 27 05:44:33.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9818" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":100,"skipped":2196,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:44:33.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:44:33.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6008 version'
May 27 05:44:33.646: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
May 27 05:44:33.646: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.1\", GitCommit:\"3ddd0f45aa91e2f30c70734b175631bec5b5825a\", GitTreeState:\"clean\", BuildDate:\"2022-05-24T12:26:19Z\", GoVersion:\"go1.18.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.4\nServer Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.1\", GitCommit:\"3ddd0f45aa91e2f30c70734b175631bec5b5825a\", GitTreeState:\"clean\", BuildDate:\"2022-05-24T12:18:48Z\", GoVersion:\"go1.18.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 05:44:33.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6008" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":356,"completed":101,"skipped":2198,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:44:33.671: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
May 27 05:44:33.744: INFO: Waiting up to 5m0s for pod "downward-api-348c73a9-f5f1-44f9-8526-e0ed1ac4d915" in namespace "downward-api-8923" to be "Succeeded or Failed"
May 27 05:44:33.755: INFO: Pod "downward-api-348c73a9-f5f1-44f9-8526-e0ed1ac4d915": Phase="Pending", Reason="", readiness=false. Elapsed: 10.762185ms
May 27 05:44:35.766: INFO: Pod "downward-api-348c73a9-f5f1-44f9-8526-e0ed1ac4d915": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021813955s
May 27 05:44:37.799: INFO: Pod "downward-api-348c73a9-f5f1-44f9-8526-e0ed1ac4d915": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054893679s
May 27 05:44:39.806: INFO: Pod "downward-api-348c73a9-f5f1-44f9-8526-e0ed1ac4d915": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.062269964s
STEP: Saw pod success
May 27 05:44:39.806: INFO: Pod "downward-api-348c73a9-f5f1-44f9-8526-e0ed1ac4d915" satisfied condition "Succeeded or Failed"
May 27 05:44:39.813: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downward-api-348c73a9-f5f1-44f9-8526-e0ed1ac4d915 container dapi-container: <nil>
STEP: delete the pod
May 27 05:44:39.851: INFO: Waiting for pod downward-api-348c73a9-f5f1-44f9-8526-e0ed1ac4d915 to disappear
May 27 05:44:39.857: INFO: Pod downward-api-348c73a9-f5f1-44f9-8526-e0ed1ac4d915 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
May 27 05:44:39.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8923" for this suite.

• [SLOW TEST:6.207 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":356,"completed":102,"skipped":2216,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:44:39.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-sqqm
STEP: Creating a pod to test atomic-volume-subpath
May 27 05:44:39.976: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-sqqm" in namespace "subpath-9746" to be "Succeeded or Failed"
May 27 05:44:39.984: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Pending", Reason="", readiness=false. Elapsed: 8.04342ms
May 27 05:44:42.001: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Running", Reason="", readiness=true. Elapsed: 2.024737268s
May 27 05:44:44.018: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Running", Reason="", readiness=true. Elapsed: 4.041777107s
May 27 05:44:46.057: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Running", Reason="", readiness=true. Elapsed: 6.081092114s
May 27 05:44:48.080: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Running", Reason="", readiness=true. Elapsed: 8.104109471s
May 27 05:44:50.101: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Running", Reason="", readiness=true. Elapsed: 10.124860318s
May 27 05:44:52.151: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Running", Reason="", readiness=true. Elapsed: 12.174660825s
May 27 05:44:54.165: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Running", Reason="", readiness=true. Elapsed: 14.18931104s
May 27 05:44:56.186: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Running", Reason="", readiness=true. Elapsed: 16.210192399s
May 27 05:44:58.203: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Running", Reason="", readiness=true. Elapsed: 18.226994187s
May 27 05:45:00.242: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Running", Reason="", readiness=true. Elapsed: 20.265934891s
May 27 05:45:02.255: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Running", Reason="", readiness=false. Elapsed: 22.278765026s
May 27 05:45:04.268: INFO: Pod "pod-subpath-test-configmap-sqqm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.291903956s
STEP: Saw pod success
May 27 05:45:04.268: INFO: Pod "pod-subpath-test-configmap-sqqm" satisfied condition "Succeeded or Failed"
May 27 05:45:04.273: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-subpath-test-configmap-sqqm container test-container-subpath-configmap-sqqm: <nil>
STEP: delete the pod
May 27 05:45:04.323: INFO: Waiting for pod pod-subpath-test-configmap-sqqm to disappear
May 27 05:45:04.335: INFO: Pod pod-subpath-test-configmap-sqqm no longer exists
STEP: Deleting pod pod-subpath-test-configmap-sqqm
May 27 05:45:04.335: INFO: Deleting pod "pod-subpath-test-configmap-sqqm" in namespace "subpath-9746"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
May 27 05:45:04.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9746" for this suite.

• [SLOW TEST:24.494 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","total":356,"completed":103,"skipped":2223,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:45:04.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
May 27 05:45:04.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-707" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":356,"completed":104,"skipped":2284,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:45:04.535: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:45:04.582: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-050805c7-c500-494f-b7f5-3e79cbd87bba" in namespace "security-context-test-5784" to be "Succeeded or Failed"
May 27 05:45:04.589: INFO: Pod "busybox-privileged-false-050805c7-c500-494f-b7f5-3e79cbd87bba": Phase="Pending", Reason="", readiness=false. Elapsed: 7.446848ms
May 27 05:45:06.602: INFO: Pod "busybox-privileged-false-050805c7-c500-494f-b7f5-3e79cbd87bba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020230503s
May 27 05:45:08.619: INFO: Pod "busybox-privileged-false-050805c7-c500-494f-b7f5-3e79cbd87bba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037251167s
May 27 05:45:08.619: INFO: Pod "busybox-privileged-false-050805c7-c500-494f-b7f5-3e79cbd87bba" satisfied condition "Succeeded or Failed"
May 27 05:45:08.631: INFO: Got logs for pod "busybox-privileged-false-050805c7-c500-494f-b7f5-3e79cbd87bba": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
May 27 05:45:08.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5784" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":105,"skipped":2312,"failed":0}
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:45:08.656: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 05:45:08.730: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98e3a054-3fbe-43bc-be51-9703c9ea3742" in namespace "downward-api-6832" to be "Succeeded or Failed"
May 27 05:45:08.738: INFO: Pod "downwardapi-volume-98e3a054-3fbe-43bc-be51-9703c9ea3742": Phase="Pending", Reason="", readiness=false. Elapsed: 7.399895ms
May 27 05:45:10.749: INFO: Pod "downwardapi-volume-98e3a054-3fbe-43bc-be51-9703c9ea3742": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019195238s
May 27 05:45:12.760: INFO: Pod "downwardapi-volume-98e3a054-3fbe-43bc-be51-9703c9ea3742": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029677505s
May 27 05:45:14.768: INFO: Pod "downwardapi-volume-98e3a054-3fbe-43bc-be51-9703c9ea3742": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037736642s
STEP: Saw pod success
May 27 05:45:14.768: INFO: Pod "downwardapi-volume-98e3a054-3fbe-43bc-be51-9703c9ea3742" satisfied condition "Succeeded or Failed"
May 27 05:45:14.773: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-98e3a054-3fbe-43bc-be51-9703c9ea3742 container client-container: <nil>
STEP: delete the pod
May 27 05:45:14.807: INFO: Waiting for pod downwardapi-volume-98e3a054-3fbe-43bc-be51-9703c9ea3742 to disappear
May 27 05:45:14.811: INFO: Pod downwardapi-volume-98e3a054-3fbe-43bc-be51-9703c9ea3742 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
May 27 05:45:14.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6832" for this suite.

• [SLOW TEST:6.181 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":106,"skipped":2318,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:45:14.838: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
May 27 05:45:15.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4966" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":107,"skipped":2334,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:45:15.056: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
May 27 05:45:15.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 create -f -'
May 27 05:45:15.691: INFO: stderr: ""
May 27 05:45:15.691: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 27 05:45:15.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May 27 05:45:15.968: INFO: stderr: ""
May 27 05:45:15.968: INFO: stdout: "update-demo-nautilus-5cvj8 update-demo-nautilus-k4fct "
May 27 05:45:15.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-5cvj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 05:45:16.201: INFO: stderr: ""
May 27 05:45:16.201: INFO: stdout: ""
May 27 05:45:16.202: INFO: update-demo-nautilus-5cvj8 is created but not running
May 27 05:45:21.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May 27 05:45:21.426: INFO: stderr: ""
May 27 05:45:21.427: INFO: stdout: "update-demo-nautilus-5cvj8 update-demo-nautilus-k4fct "
May 27 05:45:21.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-5cvj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 05:45:21.686: INFO: stderr: ""
May 27 05:45:21.686: INFO: stdout: ""
May 27 05:45:21.686: INFO: update-demo-nautilus-5cvj8 is created but not running
May 27 05:45:26.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May 27 05:45:26.839: INFO: stderr: ""
May 27 05:45:26.839: INFO: stdout: "update-demo-nautilus-5cvj8 update-demo-nautilus-k4fct "
May 27 05:45:26.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-5cvj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 05:45:26.970: INFO: stderr: ""
May 27 05:45:26.970: INFO: stdout: "true"
May 27 05:45:26.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-5cvj8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May 27 05:45:27.091: INFO: stderr: ""
May 27 05:45:27.091: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
May 27 05:45:27.091: INFO: validating pod update-demo-nautilus-5cvj8
May 27 05:45:27.105: INFO: got data: {
  "image": "nautilus.jpg"
}

May 27 05:45:27.106: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 27 05:45:27.106: INFO: update-demo-nautilus-5cvj8 is verified up and running
May 27 05:45:27.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-k4fct -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 05:45:27.247: INFO: stderr: ""
May 27 05:45:27.247: INFO: stdout: "true"
May 27 05:45:27.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-k4fct -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May 27 05:45:27.402: INFO: stderr: ""
May 27 05:45:27.402: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
May 27 05:45:27.402: INFO: validating pod update-demo-nautilus-k4fct
May 27 05:45:27.425: INFO: got data: {
  "image": "nautilus.jpg"
}

May 27 05:45:27.425: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 27 05:45:27.425: INFO: update-demo-nautilus-k4fct is verified up and running
STEP: scaling down the replication controller
May 27 05:45:27.456: INFO: scanned /root for discovery docs: <nil>
May 27 05:45:27.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
May 27 05:45:28.668: INFO: stderr: ""
May 27 05:45:28.669: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 27 05:45:28.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May 27 05:45:28.782: INFO: stderr: ""
May 27 05:45:28.782: INFO: stdout: "update-demo-nautilus-5cvj8 update-demo-nautilus-k4fct "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 27 05:45:33.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May 27 05:45:33.914: INFO: stderr: ""
May 27 05:45:33.914: INFO: stdout: "update-demo-nautilus-5cvj8 "
May 27 05:45:33.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-5cvj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 05:45:34.028: INFO: stderr: ""
May 27 05:45:34.028: INFO: stdout: "true"
May 27 05:45:34.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-5cvj8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May 27 05:45:34.146: INFO: stderr: ""
May 27 05:45:34.146: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
May 27 05:45:34.146: INFO: validating pod update-demo-nautilus-5cvj8
May 27 05:45:34.154: INFO: got data: {
  "image": "nautilus.jpg"
}

May 27 05:45:34.154: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 27 05:45:34.154: INFO: update-demo-nautilus-5cvj8 is verified up and running
STEP: scaling up the replication controller
May 27 05:45:34.163: INFO: scanned /root for discovery docs: <nil>
May 27 05:45:34.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
May 27 05:45:35.349: INFO: stderr: ""
May 27 05:45:35.349: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 27 05:45:35.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May 27 05:45:35.601: INFO: stderr: ""
May 27 05:45:35.601: INFO: stdout: "update-demo-nautilus-5cvj8 update-demo-nautilus-svtcr "
May 27 05:45:35.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-5cvj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 05:45:35.822: INFO: stderr: ""
May 27 05:45:35.822: INFO: stdout: "true"
May 27 05:45:35.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-5cvj8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May 27 05:45:35.959: INFO: stderr: ""
May 27 05:45:35.959: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
May 27 05:45:35.959: INFO: validating pod update-demo-nautilus-5cvj8
May 27 05:45:35.966: INFO: got data: {
  "image": "nautilus.jpg"
}

May 27 05:45:35.966: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 27 05:45:35.966: INFO: update-demo-nautilus-5cvj8 is verified up and running
May 27 05:45:35.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-svtcr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 05:45:36.122: INFO: stderr: ""
May 27 05:45:36.122: INFO: stdout: ""
May 27 05:45:36.122: INFO: update-demo-nautilus-svtcr is created but not running
May 27 05:45:41.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May 27 05:45:41.274: INFO: stderr: ""
May 27 05:45:41.274: INFO: stdout: "update-demo-nautilus-5cvj8 update-demo-nautilus-svtcr "
May 27 05:45:41.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-5cvj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 05:45:41.455: INFO: stderr: ""
May 27 05:45:41.455: INFO: stdout: "true"
May 27 05:45:41.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-5cvj8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May 27 05:45:41.653: INFO: stderr: ""
May 27 05:45:41.653: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
May 27 05:45:41.653: INFO: validating pod update-demo-nautilus-5cvj8
May 27 05:45:41.660: INFO: got data: {
  "image": "nautilus.jpg"
}

May 27 05:45:41.660: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 27 05:45:41.660: INFO: update-demo-nautilus-5cvj8 is verified up and running
May 27 05:45:41.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-svtcr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 05:45:41.820: INFO: stderr: ""
May 27 05:45:41.820: INFO: stdout: "true"
May 27 05:45:41.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods update-demo-nautilus-svtcr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May 27 05:45:41.952: INFO: stderr: ""
May 27 05:45:41.952: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
May 27 05:45:41.952: INFO: validating pod update-demo-nautilus-svtcr
May 27 05:45:41.962: INFO: got data: {
  "image": "nautilus.jpg"
}

May 27 05:45:41.962: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 27 05:45:41.962: INFO: update-demo-nautilus-svtcr is verified up and running
STEP: using delete to clean up resources
May 27 05:45:41.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 delete --grace-period=0 --force -f -'
May 27 05:45:42.116: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 27 05:45:42.117: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 27 05:45:42.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get rc,svc -l name=update-demo --no-headers'
May 27 05:45:42.314: INFO: stderr: "No resources found in kubectl-9037 namespace.\n"
May 27 05:45:42.315: INFO: stdout: ""
May 27 05:45:42.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-9037 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 27 05:45:42.506: INFO: stderr: ""
May 27 05:45:42.506: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 05:45:42.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9037" for this suite.

• [SLOW TEST:27.482 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should scale a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":356,"completed":108,"skipped":2344,"failed":0}
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:45:42.538: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 27 05:45:46.669: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
May 27 05:45:46.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7533" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":109,"skipped":2350,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:45:46.724: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service multi-endpoint-test in namespace services-3302
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3302 to expose endpoints map[]
May 27 05:45:46.793: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
May 27 05:45:47.812: INFO: successfully validated that service multi-endpoint-test in namespace services-3302 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-3302
May 27 05:45:47.844: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:45:49.850: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3302 to expose endpoints map[pod1:[100]]
May 27 05:45:49.871: INFO: successfully validated that service multi-endpoint-test in namespace services-3302 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-3302
May 27 05:45:49.886: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:45:51.904: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3302 to expose endpoints map[pod1:[100] pod2:[101]]
May 27 05:45:51.937: INFO: successfully validated that service multi-endpoint-test in namespace services-3302 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods
May 27 05:45:51.937: INFO: Creating new exec pod
May 27 05:45:54.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-3302 exec execpodqmd6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
May 27 05:45:55.380: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
May 27 05:45:55.380: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:45:55.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-3302 exec execpodqmd6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.29.245 80'
May 27 05:45:55.704: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.29.245 80\nConnection to 10.233.29.245 80 port [tcp/http] succeeded!\n"
May 27 05:45:55.704: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:45:55.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-3302 exec execpodqmd6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
May 27 05:45:55.969: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
May 27 05:45:55.969: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 05:45:55.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-3302 exec execpodqmd6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.29.245 81'
May 27 05:45:56.246: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.29.245 81\nConnection to 10.233.29.245 81 port [tcp/*] succeeded!\n"
May 27 05:45:56.246: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-3302
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3302 to expose endpoints map[pod2:[101]]
May 27 05:45:57.343: INFO: successfully validated that service multi-endpoint-test in namespace services-3302 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-3302
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3302 to expose endpoints map[]
May 27 05:45:57.435: INFO: successfully validated that service multi-endpoint-test in namespace services-3302 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 05:45:57.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3302" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:10.849 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":356,"completed":110,"skipped":2372,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:45:57.580: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 05:45:58.694: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 27 05:46:00.720: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 5, 45, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 45, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 45, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 45, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 05:46:03.775: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
May 27 05:46:03.816: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:46:03.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3703" for this suite.
STEP: Destroying namespace "webhook-3703-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.407 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":356,"completed":111,"skipped":2388,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:46:03.990: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
May 27 05:46:04.278: INFO: The status of Pod pod-update-7ef5e2d0-d8a9-48ed-a172-b52de6562897 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:46:06.300: INFO: The status of Pod pod-update-7ef5e2d0-d8a9-48ed-a172-b52de6562897 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 27 05:46:06.847: INFO: Successfully updated pod "pod-update-7ef5e2d0-d8a9-48ed-a172-b52de6562897"
STEP: verifying the updated pod is in kubernetes
May 27 05:46:06.879: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
May 27 05:46:06.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7780" for this suite.
•{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","total":356,"completed":112,"skipped":2398,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:46:06.905: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
May 27 05:46:23.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6441" for this suite.

• [SLOW TEST:16.195 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":356,"completed":113,"skipped":2406,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:46:23.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-5504
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 27 05:46:23.153: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May 27 05:46:23.257: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:46:25.266: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 27 05:46:27.277: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:46:29.273: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:46:31.275: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:46:33.270: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:46:35.268: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:46:37.284: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:46:39.267: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:46:41.280: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 05:46:43.265: INFO: The status of Pod netserver-0 is Running (Ready = true)
May 27 05:46:43.276: INFO: The status of Pod netserver-1 is Running (Ready = false)
May 27 05:46:45.286: INFO: The status of Pod netserver-1 is Running (Ready = true)
May 27 05:46:45.300: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
May 27 05:46:47.383: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
May 27 05:46:47.383: INFO: Going to poll 10.233.66.132 on port 8083 at least 0 times, with a maximum of 39 tries before failing
May 27 05:46:47.389: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.132:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5504 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 05:46:47.389: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:46:47.390: INFO: ExecWithOptions: Clientset creation
May 27 05:46:47.390: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5504/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.132%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May 27 05:46:47.569: INFO: Found all 1 expected endpoints: [netserver-0]
May 27 05:46:47.569: INFO: Going to poll 10.233.64.95 on port 8083 at least 0 times, with a maximum of 39 tries before failing
May 27 05:46:47.578: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.95:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5504 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 05:46:47.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:46:47.579: INFO: ExecWithOptions: Clientset creation
May 27 05:46:47.579: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5504/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.95%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May 27 05:46:47.726: INFO: Found all 1 expected endpoints: [netserver-1]
May 27 05:46:47.726: INFO: Going to poll 10.233.65.198 on port 8083 at least 0 times, with a maximum of 39 tries before failing
May 27 05:46:47.735: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.198:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5504 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 05:46:47.735: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:46:47.737: INFO: ExecWithOptions: Clientset creation
May 27 05:46:47.737: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-5504/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.198%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May 27 05:46:47.866: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
May 27 05:46:47.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5504" for this suite.

• [SLOW TEST:24.788 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":114,"skipped":2419,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:46:47.893: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:58
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-161b53d9-796e-4425-a606-f05f428c1618 in namespace container-probe-2762
May 27 05:46:49.985: INFO: Started pod liveness-161b53d9-796e-4425-a606-f05f428c1618 in namespace container-probe-2762
STEP: checking the pod's current state and verifying that restartCount is present
May 27 05:46:49.991: INFO: Initial restart count of pod liveness-161b53d9-796e-4425-a606-f05f428c1618 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
May 27 05:50:51.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2762" for this suite.

• [SLOW TEST:244.021 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":356,"completed":115,"skipped":2444,"failed":0}
SSSSSS
------------------------------
[sig-apps] Job 
  should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:50:51.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensure pods equal to paralellism count is attached to the job
STEP: patching /status
STEP: updating /status
STEP: get /status
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
May 27 05:50:54.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2048" for this suite.
•{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","total":356,"completed":116,"skipped":2450,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:50:54.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
May 27 05:50:54.270: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
May 27 05:51:13.964: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 05:51:20.223: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:51:41.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1425" for this suite.

• [SLOW TEST:47.063 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":356,"completed":117,"skipped":2454,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:51:41.282: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:51:41.335: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:51:48.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8262" for this suite.

• [SLOW TEST:7.117 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":356,"completed":118,"skipped":2483,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:51:48.401: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 05:51:48.592: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf21a423-be85-48b4-97a8-b0d926e08350" in namespace "downward-api-9364" to be "Succeeded or Failed"
May 27 05:51:48.607: INFO: Pod "downwardapi-volume-cf21a423-be85-48b4-97a8-b0d926e08350": Phase="Pending", Reason="", readiness=false. Elapsed: 15.295778ms
May 27 05:51:50.617: INFO: Pod "downwardapi-volume-cf21a423-be85-48b4-97a8-b0d926e08350": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025283647s
May 27 05:51:52.631: INFO: Pod "downwardapi-volume-cf21a423-be85-48b4-97a8-b0d926e08350": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038970909s
STEP: Saw pod success
May 27 05:51:52.631: INFO: Pod "downwardapi-volume-cf21a423-be85-48b4-97a8-b0d926e08350" satisfied condition "Succeeded or Failed"
May 27 05:51:52.637: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-cf21a423-be85-48b4-97a8-b0d926e08350 container client-container: <nil>
STEP: delete the pod
May 27 05:51:52.697: INFO: Waiting for pod downwardapi-volume-cf21a423-be85-48b4-97a8-b0d926e08350 to disappear
May 27 05:51:52.703: INFO: Pod downwardapi-volume-cf21a423-be85-48b4-97a8-b0d926e08350 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
May 27 05:51:52.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9364" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":119,"skipped":2486,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API 
   should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:51:52.727: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename ingressclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:188
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
May 27 05:51:52.832: INFO: starting watch
STEP: patching
STEP: updating
May 27 05:51:52.857: INFO: waiting for watch events with expected annotations
May 27 05:51:52.857: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:188
May 27 05:51:52.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-4161" for this suite.
•{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":356,"completed":120,"skipped":2509,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Discovery 
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:51:52.944: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename discovery
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:51:53.717: INFO: Checking APIGroup: apiregistration.k8s.io
May 27 05:51:53.721: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
May 27 05:51:53.722: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
May 27 05:51:53.722: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
May 27 05:51:53.722: INFO: Checking APIGroup: apps
May 27 05:51:53.727: INFO: PreferredVersion.GroupVersion: apps/v1
May 27 05:51:53.728: INFO: Versions found [{apps/v1 v1}]
May 27 05:51:53.728: INFO: apps/v1 matches apps/v1
May 27 05:51:53.728: INFO: Checking APIGroup: events.k8s.io
May 27 05:51:53.740: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
May 27 05:51:53.740: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
May 27 05:51:53.740: INFO: events.k8s.io/v1 matches events.k8s.io/v1
May 27 05:51:53.740: INFO: Checking APIGroup: authentication.k8s.io
May 27 05:51:53.757: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
May 27 05:51:53.757: INFO: Versions found [{authentication.k8s.io/v1 v1}]
May 27 05:51:53.757: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
May 27 05:51:53.757: INFO: Checking APIGroup: authorization.k8s.io
May 27 05:51:53.762: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
May 27 05:51:53.762: INFO: Versions found [{authorization.k8s.io/v1 v1}]
May 27 05:51:53.762: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
May 27 05:51:53.762: INFO: Checking APIGroup: autoscaling
May 27 05:51:53.769: INFO: PreferredVersion.GroupVersion: autoscaling/v2
May 27 05:51:53.770: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
May 27 05:51:53.770: INFO: autoscaling/v2 matches autoscaling/v2
May 27 05:51:53.770: INFO: Checking APIGroup: batch
May 27 05:51:53.775: INFO: PreferredVersion.GroupVersion: batch/v1
May 27 05:51:53.775: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
May 27 05:51:53.775: INFO: batch/v1 matches batch/v1
May 27 05:51:53.775: INFO: Checking APIGroup: certificates.k8s.io
May 27 05:51:53.778: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
May 27 05:51:53.778: INFO: Versions found [{certificates.k8s.io/v1 v1}]
May 27 05:51:53.778: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
May 27 05:51:53.778: INFO: Checking APIGroup: networking.k8s.io
May 27 05:51:53.783: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
May 27 05:51:53.783: INFO: Versions found [{networking.k8s.io/v1 v1}]
May 27 05:51:53.783: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
May 27 05:51:53.783: INFO: Checking APIGroup: policy
May 27 05:51:53.795: INFO: PreferredVersion.GroupVersion: policy/v1
May 27 05:51:53.798: INFO: Versions found [{policy/v1 v1} {policy/v1beta1 v1beta1}]
May 27 05:51:53.798: INFO: policy/v1 matches policy/v1
May 27 05:51:53.798: INFO: Checking APIGroup: rbac.authorization.k8s.io
May 27 05:51:53.806: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
May 27 05:51:53.806: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
May 27 05:51:53.806: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
May 27 05:51:53.806: INFO: Checking APIGroup: storage.k8s.io
May 27 05:51:53.811: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
May 27 05:51:53.812: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
May 27 05:51:53.812: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
May 27 05:51:53.812: INFO: Checking APIGroup: admissionregistration.k8s.io
May 27 05:51:53.814: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
May 27 05:51:53.814: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
May 27 05:51:53.814: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
May 27 05:51:53.814: INFO: Checking APIGroup: apiextensions.k8s.io
May 27 05:51:53.816: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
May 27 05:51:53.816: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
May 27 05:51:53.816: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
May 27 05:51:53.816: INFO: Checking APIGroup: scheduling.k8s.io
May 27 05:51:53.818: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
May 27 05:51:53.819: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
May 27 05:51:53.819: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
May 27 05:51:53.819: INFO: Checking APIGroup: coordination.k8s.io
May 27 05:51:53.821: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
May 27 05:51:53.821: INFO: Versions found [{coordination.k8s.io/v1 v1}]
May 27 05:51:53.821: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
May 27 05:51:53.821: INFO: Checking APIGroup: node.k8s.io
May 27 05:51:53.823: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
May 27 05:51:53.823: INFO: Versions found [{node.k8s.io/v1 v1} {node.k8s.io/v1beta1 v1beta1}]
May 27 05:51:53.823: INFO: node.k8s.io/v1 matches node.k8s.io/v1
May 27 05:51:53.823: INFO: Checking APIGroup: discovery.k8s.io
May 27 05:51:53.825: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
May 27 05:51:53.825: INFO: Versions found [{discovery.k8s.io/v1 v1} {discovery.k8s.io/v1beta1 v1beta1}]
May 27 05:51:53.825: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
May 27 05:51:53.825: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
May 27 05:51:53.827: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
May 27 05:51:53.827: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
May 27 05:51:53.828: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
May 27 05:51:53.828: INFO: Checking APIGroup: cilium.io
May 27 05:51:53.831: INFO: PreferredVersion.GroupVersion: cilium.io/v2
May 27 05:51:53.831: INFO: Versions found [{cilium.io/v2 v2}]
May 27 05:51:53.831: INFO: cilium.io/v2 matches cilium.io/v2
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:188
May 27 05:51:53.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-1343" for this suite.
•{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":356,"completed":121,"skipped":2514,"failed":0}
SS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:51:53.883: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in volume subpath
May 27 05:51:53.994: INFO: Waiting up to 5m0s for pod "var-expansion-17fca0c3-e0a4-4966-aae7-ae5e791d80c7" in namespace "var-expansion-5418" to be "Succeeded or Failed"
May 27 05:51:54.019: INFO: Pod "var-expansion-17fca0c3-e0a4-4966-aae7-ae5e791d80c7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.095454ms
May 27 05:51:56.103: INFO: Pod "var-expansion-17fca0c3-e0a4-4966-aae7-ae5e791d80c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.108365441s
May 27 05:51:58.135: INFO: Pod "var-expansion-17fca0c3-e0a4-4966-aae7-ae5e791d80c7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.140658369s
May 27 05:52:00.169: INFO: Pod "var-expansion-17fca0c3-e0a4-4966-aae7-ae5e791d80c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.174291936s
STEP: Saw pod success
May 27 05:52:00.169: INFO: Pod "var-expansion-17fca0c3-e0a4-4966-aae7-ae5e791d80c7" satisfied condition "Succeeded or Failed"
May 27 05:52:00.175: INFO: Trying to get logs from node bohc9zohd7ee-3 pod var-expansion-17fca0c3-e0a4-4966-aae7-ae5e791d80c7 container dapi-container: <nil>
STEP: delete the pod
May 27 05:52:00.213: INFO: Waiting for pod var-expansion-17fca0c3-e0a4-4966-aae7-ae5e791d80c7 to disappear
May 27 05:52:00.220: INFO: Pod var-expansion-17fca0c3-e0a4-4966-aae7-ae5e791d80c7 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
May 27 05:52:00.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5418" for this suite.

• [SLOW TEST:6.355 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","total":356,"completed":122,"skipped":2516,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:52:00.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 27 05:52:00.400: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:52:00.400: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:52:01.440: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:52:01.440: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:52:02.421: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May 27 05:52:02.422: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 27 05:52:02.460: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:52:02.460: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:52:03.485: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:52:03.485: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:52:04.490: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:52:04.490: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:52:05.504: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:52:05.505: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:52:06.506: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 05:52:06.506: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 05:52:07.484: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May 27 05:52:07.484: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3681, will wait for the garbage collector to delete the pods
May 27 05:52:07.566: INFO: Deleting DaemonSet.extensions daemon-set took: 14.454109ms
May 27 05:52:07.667: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.870122ms
May 27 05:52:10.073: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 05:52:10.073: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May 27 05:52:10.092: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"16764"},"items":null}

May 27 05:52:10.101: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"16764"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
May 27 05:52:10.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3681" for this suite.

• [SLOW TEST:9.910 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":356,"completed":123,"skipped":2550,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:52:10.163: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 05:52:11.205: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 27 05:52:13.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 5, 52, 11, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 52, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 5, 52, 11, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 5, 52, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 05:52:16.301: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:52:16.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3854" for this suite.
STEP: Destroying namespace "webhook-3854-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.509 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":356,"completed":124,"skipped":2562,"failed":0}
SSSSS
------------------------------
[sig-node] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:52:16.673: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:52:16.754: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: creating the pod
STEP: submitting the pod to kubernetes
May 27 05:52:16.790: INFO: The status of Pod pod-logs-websocket-23a7f1a1-aebd-48ad-8329-3e6a7499cb5f is Pending, waiting for it to be Running (with Ready = true)
May 27 05:52:18.808: INFO: The status of Pod pod-logs-websocket-23a7f1a1-aebd-48ad-8329-3e6a7499cb5f is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
May 27 05:52:18.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7533" for this suite.
•{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":356,"completed":125,"skipped":2567,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:52:18.861: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1679.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1679.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1679.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1679.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1679.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1679.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1679.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1679.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1679.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1679.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 1.54.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.54.1_udp@PTR;check="$$(dig +tcp +noall +answer +search 1.54.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.54.1_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1679.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1679.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1679.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1679.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1679.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1679.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1679.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1679.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1679.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1679.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 1.54.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.54.1_udp@PTR;check="$$(dig +tcp +noall +answer +search 1.54.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.54.1_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 27 05:52:37.048: INFO: Unable to read wheezy_udp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:37.054: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:37.061: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:37.067: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:37.099: INFO: Unable to read jessie_udp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:37.108: INFO: Unable to read jessie_tcp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:37.114: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:37.119: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:37.147: INFO: Lookups using dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18 failed for: [wheezy_udp@dns-test-service.dns-1679.svc.cluster.local wheezy_tcp@dns-test-service.dns-1679.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local jessie_udp@dns-test-service.dns-1679.svc.cluster.local jessie_tcp@dns-test-service.dns-1679.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local]

May 27 05:52:42.158: INFO: Unable to read wheezy_udp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:42.166: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:42.173: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:42.183: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:42.220: INFO: Unable to read jessie_udp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:42.226: INFO: Unable to read jessie_tcp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:42.238: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:42.247: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:42.282: INFO: Lookups using dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18 failed for: [wheezy_udp@dns-test-service.dns-1679.svc.cluster.local wheezy_tcp@dns-test-service.dns-1679.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local jessie_udp@dns-test-service.dns-1679.svc.cluster.local jessie_tcp@dns-test-service.dns-1679.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local]

May 27 05:52:47.159: INFO: Unable to read wheezy_udp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:47.166: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:47.173: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:47.179: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:47.220: INFO: Unable to read jessie_udp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:47.228: INFO: Unable to read jessie_tcp@dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:47.233: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:47.240: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local from pod dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18: the server could not find the requested resource (get pods dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18)
May 27 05:52:47.267: INFO: Lookups using dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18 failed for: [wheezy_udp@dns-test-service.dns-1679.svc.cluster.local wheezy_tcp@dns-test-service.dns-1679.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local jessie_udp@dns-test-service.dns-1679.svc.cluster.local jessie_tcp@dns-test-service.dns-1679.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1679.svc.cluster.local]

May 27 05:52:52.315: INFO: DNS probes using dns-1679/dns-test-1ad18008-63b5-458b-93f5-7d3e17dd7c18 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
May 27 05:52:52.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1679" for this suite.

• [SLOW TEST:33.827 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":356,"completed":126,"skipped":2580,"failed":0}
[sig-node] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:52:52.688: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
May 27 05:52:52.759: INFO: The status of Pod pod-update-activedeadlineseconds-6f74a7e0-7b29-4f34-aa77-eda1261c3daa is Pending, waiting for it to be Running (with Ready = true)
May 27 05:52:54.769: INFO: The status of Pod pod-update-activedeadlineseconds-6f74a7e0-7b29-4f34-aa77-eda1261c3daa is Pending, waiting for it to be Running (with Ready = true)
May 27 05:52:56.773: INFO: The status of Pod pod-update-activedeadlineseconds-6f74a7e0-7b29-4f34-aa77-eda1261c3daa is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 27 05:52:57.315: INFO: Successfully updated pod "pod-update-activedeadlineseconds-6f74a7e0-7b29-4f34-aa77-eda1261c3daa"
May 27 05:52:57.316: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-6f74a7e0-7b29-4f34-aa77-eda1261c3daa" in namespace "pods-2327" to be "terminated due to deadline exceeded"
May 27 05:52:57.323: INFO: Pod "pod-update-activedeadlineseconds-6f74a7e0-7b29-4f34-aa77-eda1261c3daa": Phase="Running", Reason="", readiness=true. Elapsed: 7.915975ms
May 27 05:52:59.339: INFO: Pod "pod-update-activedeadlineseconds-6f74a7e0-7b29-4f34-aa77-eda1261c3daa": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.02371505s
May 27 05:52:59.339: INFO: Pod "pod-update-activedeadlineseconds-6f74a7e0-7b29-4f34-aa77-eda1261c3daa" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
May 27 05:52:59.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2327" for this suite.

• [SLOW TEST:6.672 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":356,"completed":127,"skipped":2580,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:52:59.361: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5563
[It] should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-5563
May 27 05:52:59.447: INFO: Found 0 stateful pods, waiting for 1
May 27 05:53:09.464: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
STEP: Patch a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May 27 05:53:09.564: INFO: Deleting all statefulset in ns statefulset-5563
May 27 05:53:09.584: INFO: Scaling statefulset ss to 0
May 27 05:53:19.669: INFO: Waiting for statefulset status.replicas updated to 0
May 27 05:53:19.676: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
May 27 05:53:19.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5563" for this suite.

• [SLOW TEST:20.392 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":356,"completed":128,"skipped":2595,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:53:19.754: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating api versions
May 27 05:53:19.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-816 api-versions'
May 27 05:53:19.917: INFO: stderr: ""
May 27 05:53:19.917: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncilium.io/v2\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\nnode.k8s.io/v1beta1\npolicy/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 05:53:19.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-816" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":356,"completed":129,"skipped":2604,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version 
  should find the server version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:53:19.964: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename server-version
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should find the server version [Conformance]
  test/e2e/framework/framework.go:652
STEP: Request ServerVersion
STEP: Confirm major version
May 27 05:53:20.028: INFO: Major version: 1
STEP: Confirm minor version
May 27 05:53:20.028: INFO: cleanMinorVersion: 24
May 27 05:53:20.028: INFO: Minor version: 24
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:188
May 27 05:53:20.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-1388" for this suite.
•{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":356,"completed":130,"skipped":2631,"failed":0}

------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:53:20.063: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
May 27 05:53:20.171: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 05:53:21.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4618" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":356,"completed":131,"skipped":2631,"failed":0}
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:53:21.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3282.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3282.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 27 05:53:25.417: INFO: DNS probes using dns-test-6c413448-197c-409c-bd47-b3ee1c3757ee succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3282.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3282.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 27 05:53:29.588: INFO: File wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local from pod  dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 contains 'foo.example.com.
' instead of 'bar.example.com.'
May 27 05:53:29.597: INFO: File jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local from pod  dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 contains 'foo.example.com.
' instead of 'bar.example.com.'
May 27 05:53:29.597: INFO: Lookups using dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 failed for: [wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local]

May 27 05:53:34.606: INFO: File wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local from pod  dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 contains 'foo.example.com.
' instead of 'bar.example.com.'
May 27 05:53:34.612: INFO: File jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local from pod  dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 contains 'foo.example.com.
' instead of 'bar.example.com.'
May 27 05:53:34.612: INFO: Lookups using dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 failed for: [wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local]

May 27 05:53:39.610: INFO: File wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local from pod  dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 contains 'foo.example.com.
' instead of 'bar.example.com.'
May 27 05:53:39.622: INFO: File jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local from pod  dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 contains 'foo.example.com.
' instead of 'bar.example.com.'
May 27 05:53:39.622: INFO: Lookups using dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 failed for: [wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local]

May 27 05:53:44.607: INFO: File wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local from pod  dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 contains 'foo.example.com.
' instead of 'bar.example.com.'
May 27 05:53:44.614: INFO: File jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local from pod  dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 contains 'foo.example.com.
' instead of 'bar.example.com.'
May 27 05:53:44.614: INFO: Lookups using dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 failed for: [wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local]

May 27 05:53:49.609: INFO: File wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local from pod  dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 contains 'foo.example.com.
' instead of 'bar.example.com.'
May 27 05:53:49.616: INFO: File jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local from pod  dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 contains 'foo.example.com.
' instead of 'bar.example.com.'
May 27 05:53:49.616: INFO: Lookups using dns-3282/dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 failed for: [wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local]

May 27 05:53:54.618: INFO: DNS probes using dns-test-786f3947-ebac-410c-b3ab-3fb4fc6e2928 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3282.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3282.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3282.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3282.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 27 05:53:58.848: INFO: DNS probes using dns-test-cf20cfcc-2f56-4267-88f1-78d658a3a8c0 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
May 27 05:53:58.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3282" for this suite.

• [SLOW TEST:37.690 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":356,"completed":132,"skipped":2638,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:53:58.959: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-8f395860-0983-461b-8eb3-66f7a6ec65cf
STEP: Creating a pod to test consume secrets
May 27 05:53:59.048: INFO: Waiting up to 5m0s for pod "pod-secrets-55dc7c0e-371b-4088-b0d6-11e0d50f4164" in namespace "secrets-9748" to be "Succeeded or Failed"
May 27 05:53:59.064: INFO: Pod "pod-secrets-55dc7c0e-371b-4088-b0d6-11e0d50f4164": Phase="Pending", Reason="", readiness=false. Elapsed: 16.451239ms
May 27 05:54:01.072: INFO: Pod "pod-secrets-55dc7c0e-371b-4088-b0d6-11e0d50f4164": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024336169s
May 27 05:54:03.080: INFO: Pod "pod-secrets-55dc7c0e-371b-4088-b0d6-11e0d50f4164": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032245376s
May 27 05:54:05.095: INFO: Pod "pod-secrets-55dc7c0e-371b-4088-b0d6-11e0d50f4164": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.047168333s
STEP: Saw pod success
May 27 05:54:05.095: INFO: Pod "pod-secrets-55dc7c0e-371b-4088-b0d6-11e0d50f4164" satisfied condition "Succeeded or Failed"
May 27 05:54:05.105: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-secrets-55dc7c0e-371b-4088-b0d6-11e0d50f4164 container secret-volume-test: <nil>
STEP: delete the pod
May 27 05:54:05.164: INFO: Waiting for pod pod-secrets-55dc7c0e-371b-4088-b0d6-11e0d50f4164 to disappear
May 27 05:54:05.170: INFO: Pod pod-secrets-55dc7c0e-371b-4088-b0d6-11e0d50f4164 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
May 27 05:54:05.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9748" for this suite.

• [SLOW TEST:6.242 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":133,"skipped":2648,"failed":0}
SSSSSSS
------------------------------
[sig-node] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:54:05.204: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
May 27 05:54:05.299: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
May 27 05:54:10.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7447" for this suite.

• [SLOW TEST:5.480 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","total":356,"completed":134,"skipped":2655,"failed":0}
SSSS
------------------------------
[sig-apps] CronJob 
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 05:54:10.686: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ForbidConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring no more jobs are scheduled
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
May 27 06:00:00.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-3579" for this suite.

• [SLOW TEST:350.187 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","total":356,"completed":135,"skipped":2659,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:00:00.877: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 06:00:02.271: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 06:00:05.341: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:00:05.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1039" for this suite.
STEP: Destroying namespace "webhook-1039-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":356,"completed":136,"skipped":2699,"failed":0}

------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:00:05.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3887 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3887;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3887 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3887;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3887.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3887.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3887.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3887.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3887.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3887.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3887.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3887.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3887.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3887.svc;check="$$(dig +notcp +noall +answer +search 123.31.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.31.123_udp@PTR;check="$$(dig +tcp +noall +answer +search 123.31.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.31.123_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3887 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3887;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3887 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3887;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3887.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3887.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3887.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3887.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3887.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3887.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3887.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3887.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3887.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3887.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3887.svc;check="$$(dig +notcp +noall +answer +search 123.31.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.31.123_udp@PTR;check="$$(dig +tcp +noall +answer +search 123.31.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.31.123_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 27 06:00:09.897: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:09.904: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:09.913: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:09.925: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:09.930: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:09.938: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:09.948: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:09.954: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:10.002: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:10.011: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:10.021: INFO: Unable to read jessie_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:10.060: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:10.065: INFO: Unable to read jessie_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:10.086: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:10.093: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:10.100: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:10.123: INFO: Lookups using dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3887 wheezy_tcp@dns-test-service.dns-3887 wheezy_udp@dns-test-service.dns-3887.svc wheezy_tcp@dns-test-service.dns-3887.svc wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3887 jessie_tcp@dns-test-service.dns-3887 jessie_udp@dns-test-service.dns-3887.svc jessie_tcp@dns-test-service.dns-3887.svc jessie_udp@_http._tcp.dns-test-service.dns-3887.svc jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc]

May 27 06:00:15.132: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.140: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.147: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.151: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.157: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.163: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.168: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.174: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.226: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.233: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.239: INFO: Unable to read jessie_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.245: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.253: INFO: Unable to read jessie_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.261: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.267: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.284: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:15.315: INFO: Lookups using dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3887 wheezy_tcp@dns-test-service.dns-3887 wheezy_udp@dns-test-service.dns-3887.svc wheezy_tcp@dns-test-service.dns-3887.svc wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3887 jessie_tcp@dns-test-service.dns-3887 jessie_udp@dns-test-service.dns-3887.svc jessie_tcp@dns-test-service.dns-3887.svc jessie_udp@_http._tcp.dns-test-service.dns-3887.svc jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc]

May 27 06:00:20.200: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.217: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.225: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.230: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.241: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.247: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.253: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.261: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.292: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.301: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.312: INFO: Unable to read jessie_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.332: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.341: INFO: Unable to read jessie_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.349: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.373: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.379: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:20.408: INFO: Lookups using dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3887 wheezy_tcp@dns-test-service.dns-3887 wheezy_udp@dns-test-service.dns-3887.svc wheezy_tcp@dns-test-service.dns-3887.svc wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3887 jessie_tcp@dns-test-service.dns-3887 jessie_udp@dns-test-service.dns-3887.svc jessie_tcp@dns-test-service.dns-3887.svc jessie_udp@_http._tcp.dns-test-service.dns-3887.svc jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc]

May 27 06:00:25.135: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.143: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.150: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.158: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.165: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.172: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.179: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.185: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.236: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.243: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.257: INFO: Unable to read jessie_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.265: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.271: INFO: Unable to read jessie_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.280: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.287: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.295: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:25.329: INFO: Lookups using dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3887 wheezy_tcp@dns-test-service.dns-3887 wheezy_udp@dns-test-service.dns-3887.svc wheezy_tcp@dns-test-service.dns-3887.svc wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3887 jessie_tcp@dns-test-service.dns-3887 jessie_udp@dns-test-service.dns-3887.svc jessie_tcp@dns-test-service.dns-3887.svc jessie_udp@_http._tcp.dns-test-service.dns-3887.svc jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc]

May 27 06:00:30.133: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.146: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.154: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.167: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.179: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.186: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.193: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.206: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.265: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.272: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.281: INFO: Unable to read jessie_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.287: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.299: INFO: Unable to read jessie_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.310: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.317: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.325: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:30.364: INFO: Lookups using dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3887 wheezy_tcp@dns-test-service.dns-3887 wheezy_udp@dns-test-service.dns-3887.svc wheezy_tcp@dns-test-service.dns-3887.svc wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3887 jessie_tcp@dns-test-service.dns-3887 jessie_udp@dns-test-service.dns-3887.svc jessie_tcp@dns-test-service.dns-3887.svc jessie_udp@_http._tcp.dns-test-service.dns-3887.svc jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc]

May 27 06:00:35.130: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.140: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.148: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.157: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.166: INFO: Unable to read wheezy_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.174: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.181: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.189: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.266: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.283: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.292: INFO: Unable to read jessie_udp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.298: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887 from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.313: INFO: Unable to read jessie_udp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.321: INFO: Unable to read jessie_tcp@dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.326: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.336: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc from pod dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e: the server could not find the requested resource (get pods dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e)
May 27 06:00:35.401: INFO: Lookups using dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3887 wheezy_tcp@dns-test-service.dns-3887 wheezy_udp@dns-test-service.dns-3887.svc wheezy_tcp@dns-test-service.dns-3887.svc wheezy_udp@_http._tcp.dns-test-service.dns-3887.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3887.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3887 jessie_tcp@dns-test-service.dns-3887 jessie_udp@dns-test-service.dns-3887.svc jessie_tcp@dns-test-service.dns-3887.svc jessie_udp@_http._tcp.dns-test-service.dns-3887.svc jessie_tcp@_http._tcp.dns-test-service.dns-3887.svc]

May 27 06:00:40.421: INFO: DNS probes using dns-3887/dns-test-5fff4e9d-9f97-47d8-842f-0203dea7ac4e succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
May 27 06:00:40.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3887" for this suite.

• [SLOW TEST:35.038 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":356,"completed":137,"skipped":2699,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces 
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:00:40.715: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:00:40.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename disruption-2
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: listing a collection of PDBs across all namespaces
STEP: listing a collection of PDBs in namespace disruption-7324
STEP: deleting a collection of PDBs
STEP: Waiting for the PDB collection to be deleted
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:188
May 27 06:00:44.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-8877" for this suite.
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
May 27 06:00:44.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7324" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","total":356,"completed":138,"skipped":2715,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:00:44.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod with failed condition
STEP: updating the pod
May 27 06:02:45.632: INFO: Successfully updated pod "var-expansion-b0d1f05c-01a8-425f-bbb2-ebc9a5d36bb2"
STEP: waiting for pod running
STEP: deleting the pod gracefully
May 27 06:02:47.655: INFO: Deleting pod "var-expansion-b0d1f05c-01a8-425f-bbb2-ebc9a5d36bb2" in namespace "var-expansion-281"
May 27 06:02:47.667: INFO: Wait up to 5m0s for pod "var-expansion-b0d1f05c-01a8-425f-bbb2-ebc9a5d36bb2" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
May 27 06:03:19.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-281" for this suite.

• [SLOW TEST:154.724 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","total":356,"completed":139,"skipped":2732,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:03:19.722: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
May 27 06:03:19.805: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 27 06:03:19.829: INFO: Waiting for terminating namespaces to be deleted...
May 27 06:03:19.840: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-1 before test
May 27 06:03:19.855: INFO: echo-other-node-6cd597cddc-nc274 from cilium-test started at 2022-05-27 05:12:14 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.855: INFO: 	Container echo-other-node ready: true, restart count 0
May 27 06:03:19.855: INFO: cilium-5bg94 from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.855: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:03:19.855: INFO: cilium-node-init-b2j7g from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.855: INFO: 	Container node-init ready: true, restart count 0
May 27 06:03:19.855: INFO: coredns-6d4b75cb6d-rlht9 from kube-system started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.855: INFO: 	Container coredns ready: true, restart count 0
May 27 06:03:19.855: INFO: kube-addon-manager-bohc9zohd7ee-1 from kube-system started at 2022-05-27 05:09:45 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.855: INFO: 	Container kube-addon-manager ready: true, restart count 0
May 27 06:03:19.855: INFO: kube-apiserver-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:56:59 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.855: INFO: 	Container kube-apiserver ready: true, restart count 0
May 27 06:03:19.855: INFO: kube-controller-manager-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:57:00 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.855: INFO: 	Container kube-controller-manager ready: true, restart count 0
May 27 06:03:19.855: INFO: kube-proxy-lfbdj from kube-system started at 2022-05-27 04:57:12 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.855: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:03:19.855: INFO: kube-scheduler-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:57:00 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.855: INFO: 	Container kube-scheduler ready: true, restart count 0
May 27 06:03:19.855: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-wh4kx from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:03:19.855: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:03:19.855: INFO: 	Container systemd-logs ready: true, restart count 0
May 27 06:03:19.855: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-2 before test
May 27 06:03:19.890: INFO: client-7df6cfbf7b-zqjl4 from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.890: INFO: 	Container client ready: true, restart count 0
May 27 06:03:19.890: INFO: client2-547996d7d8-lrnhm from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.890: INFO: 	Container client2 ready: true, restart count 0
May 27 06:03:19.890: INFO: echo-same-node-6f4976ddbd-2v7fp from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.890: INFO: 	Container echo-same-node ready: true, restart count 0
May 27 06:03:19.890: INFO: cilium-fcn4c from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.890: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:03:19.890: INFO: cilium-node-init-stvc7 from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.890: INFO: 	Container node-init ready: true, restart count 0
May 27 06:03:19.890: INFO: coredns-6d4b75cb6d-fhr75 from kube-system started at 2022-05-27 05:11:02 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.890: INFO: 	Container coredns ready: true, restart count 0
May 27 06:03:19.890: INFO: kube-addon-manager-bohc9zohd7ee-2 from kube-system started at 2022-05-27 05:09:45 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.890: INFO: 	Container kube-addon-manager ready: true, restart count 0
May 27 06:03:19.890: INFO: kube-apiserver-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.890: INFO: 	Container kube-apiserver ready: true, restart count 0
May 27 06:03:19.891: INFO: kube-controller-manager-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.891: INFO: 	Container kube-controller-manager ready: true, restart count 0
May 27 06:03:19.891: INFO: kube-proxy-grpx7 from kube-system started at 2022-05-27 04:57:48 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.891: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:03:19.891: INFO: kube-scheduler-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.891: INFO: 	Container kube-scheduler ready: true, restart count 0
May 27 06:03:19.891: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-vhrdj from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:03:19.891: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:03:19.891: INFO: 	Container systemd-logs ready: true, restart count 0
May 27 06:03:19.891: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-3 before test
May 27 06:03:19.909: INFO: cilium-cdd2v from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.909: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:03:19.909: INFO: cilium-node-init-qd8vn from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.909: INFO: 	Container node-init ready: true, restart count 0
May 27 06:03:19.909: INFO: cilium-operator-75876f779d-pzjgf from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.909: INFO: 	Container cilium-operator ready: true, restart count 0
May 27 06:03:19.909: INFO: kube-proxy-sg7pn from kube-system started at 2022-05-27 04:58:22 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.909: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:03:19.909: INFO: sonobuoy from sonobuoy started at 2022-05-27 05:16:01 +0000 UTC (1 container statuses recorded)
May 27 06:03:19.909: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 27 06:03:19.909: INFO: sonobuoy-e2e-job-117750ad95a24373 from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:03:19.909: INFO: 	Container e2e ready: true, restart count 0
May 27 06:03:19.909: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:03:19.909: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-2m5xp from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:03:19.909: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:03:19.909: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
STEP: verifying the node has the label node bohc9zohd7ee-1
STEP: verifying the node has the label node bohc9zohd7ee-2
STEP: verifying the node has the label node bohc9zohd7ee-3
May 27 06:03:20.295: INFO: Pod client-7df6cfbf7b-zqjl4 requesting resource cpu=0m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod client2-547996d7d8-lrnhm requesting resource cpu=0m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod echo-other-node-6cd597cddc-nc274 requesting resource cpu=0m on Node bohc9zohd7ee-1
May 27 06:03:20.295: INFO: Pod echo-same-node-6f4976ddbd-2v7fp requesting resource cpu=0m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod cilium-5bg94 requesting resource cpu=0m on Node bohc9zohd7ee-1
May 27 06:03:20.295: INFO: Pod cilium-cdd2v requesting resource cpu=0m on Node bohc9zohd7ee-3
May 27 06:03:20.295: INFO: Pod cilium-fcn4c requesting resource cpu=0m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod cilium-node-init-b2j7g requesting resource cpu=0m on Node bohc9zohd7ee-1
May 27 06:03:20.295: INFO: Pod cilium-node-init-qd8vn requesting resource cpu=0m on Node bohc9zohd7ee-3
May 27 06:03:20.295: INFO: Pod cilium-node-init-stvc7 requesting resource cpu=0m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod cilium-operator-75876f779d-pzjgf requesting resource cpu=0m on Node bohc9zohd7ee-3
May 27 06:03:20.295: INFO: Pod coredns-6d4b75cb6d-fhr75 requesting resource cpu=100m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod coredns-6d4b75cb6d-rlht9 requesting resource cpu=100m on Node bohc9zohd7ee-1
May 27 06:03:20.295: INFO: Pod kube-addon-manager-bohc9zohd7ee-1 requesting resource cpu=5m on Node bohc9zohd7ee-1
May 27 06:03:20.295: INFO: Pod kube-addon-manager-bohc9zohd7ee-2 requesting resource cpu=5m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod kube-apiserver-bohc9zohd7ee-1 requesting resource cpu=250m on Node bohc9zohd7ee-1
May 27 06:03:20.295: INFO: Pod kube-apiserver-bohc9zohd7ee-2 requesting resource cpu=250m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod kube-controller-manager-bohc9zohd7ee-1 requesting resource cpu=200m on Node bohc9zohd7ee-1
May 27 06:03:20.295: INFO: Pod kube-controller-manager-bohc9zohd7ee-2 requesting resource cpu=200m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod kube-proxy-grpx7 requesting resource cpu=0m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod kube-proxy-lfbdj requesting resource cpu=0m on Node bohc9zohd7ee-1
May 27 06:03:20.295: INFO: Pod kube-proxy-sg7pn requesting resource cpu=0m on Node bohc9zohd7ee-3
May 27 06:03:20.295: INFO: Pod kube-scheduler-bohc9zohd7ee-1 requesting resource cpu=100m on Node bohc9zohd7ee-1
May 27 06:03:20.295: INFO: Pod kube-scheduler-bohc9zohd7ee-2 requesting resource cpu=100m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod sonobuoy requesting resource cpu=0m on Node bohc9zohd7ee-3
May 27 06:03:20.295: INFO: Pod sonobuoy-e2e-job-117750ad95a24373 requesting resource cpu=0m on Node bohc9zohd7ee-3
May 27 06:03:20.295: INFO: Pod sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-2m5xp requesting resource cpu=0m on Node bohc9zohd7ee-3
May 27 06:03:20.295: INFO: Pod sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-vhrdj requesting resource cpu=0m on Node bohc9zohd7ee-2
May 27 06:03:20.295: INFO: Pod sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-wh4kx requesting resource cpu=0m on Node bohc9zohd7ee-1
STEP: Starting Pods to consume most of the cluster CPU.
May 27 06:03:20.295: INFO: Creating a pod which consumes cpu=661m on Node bohc9zohd7ee-1
May 27 06:03:20.329: INFO: Creating a pod which consumes cpu=661m on Node bohc9zohd7ee-2
May 27 06:03:20.354: INFO: Creating a pod which consumes cpu=1120m on Node bohc9zohd7ee-3
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-519cdae3-8ada-406e-8e59-5c16b2f7ea73.16f2e0ff54e6b327], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3682/filler-pod-519cdae3-8ada-406e-8e59-5c16b2f7ea73 to bohc9zohd7ee-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-519cdae3-8ada-406e-8e59-5c16b2f7ea73.16f2e0ff9d975e9d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-519cdae3-8ada-406e-8e59-5c16b2f7ea73.16f2e0ffb049e926], Reason = [Created], Message = [Created container filler-pod-519cdae3-8ada-406e-8e59-5c16b2f7ea73]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-519cdae3-8ada-406e-8e59-5c16b2f7ea73.16f2e0ffba3df1df], Reason = [Started], Message = [Started container filler-pod-519cdae3-8ada-406e-8e59-5c16b2f7ea73]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87718d82-1117-4acd-80af-15770c42cbda.16f2e0ff4ffe1d0e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3682/filler-pod-87718d82-1117-4acd-80af-15770c42cbda to bohc9zohd7ee-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87718d82-1117-4acd-80af-15770c42cbda.16f2e0ffa92ee61c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87718d82-1117-4acd-80af-15770c42cbda.16f2e0ffc1a389b3], Reason = [Created], Message = [Created container filler-pod-87718d82-1117-4acd-80af-15770c42cbda]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87718d82-1117-4acd-80af-15770c42cbda.16f2e0ffc51814a2], Reason = [Started], Message = [Started container filler-pod-87718d82-1117-4acd-80af-15770c42cbda]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-995b2e23-e9e0-4915-a3c5-577a491f8b06.16f2e0ff52cec9e8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3682/filler-pod-995b2e23-e9e0-4915-a3c5-577a491f8b06 to bohc9zohd7ee-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-995b2e23-e9e0-4915-a3c5-577a491f8b06.16f2e0ffa43344ea], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-995b2e23-e9e0-4915-a3c5-577a491f8b06.16f2e0ffb052ee3a], Reason = [Created], Message = [Created container filler-pod-995b2e23-e9e0-4915-a3c5-577a491f8b06]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-995b2e23-e9e0-4915-a3c5-577a491f8b06.16f2e0ffb3c03d8c], Reason = [Started], Message = [Started container filler-pod-995b2e23-e9e0-4915-a3c5-577a491f8b06]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16f2e1004784b328], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.]
STEP: removing the label node off the node bohc9zohd7ee-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node bohc9zohd7ee-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node bohc9zohd7ee-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
May 27 06:03:25.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3682" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83

• [SLOW TEST:6.168 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":356,"completed":140,"skipped":2743,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:03:25.890: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 06:03:26.915: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 06:03:29.967: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:03:29.981: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7186-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:03:33.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9125" for this suite.
STEP: Destroying namespace "webhook-9125-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:7.636 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":356,"completed":141,"skipped":2748,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run 
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:03:33.531: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
May 27 06:03:33.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5709 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
May 27 06:03:33.974: INFO: stderr: ""
May 27 06:03:33.974: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
May 27 06:03:33.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5709 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "k8s.gcr.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
May 27 06:03:36.044: INFO: stderr: ""
May 27 06:03:36.044: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
May 27 06:03:36.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5709 delete pods e2e-test-httpd-pod'
May 27 06:03:39.006: INFO: stderr: ""
May 27 06:03:39.006: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:03:39.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5709" for this suite.

• [SLOW TEST:5.507 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:927
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":356,"completed":142,"skipped":2887,"failed":0}
S
------------------------------
[sig-node] Variable Expansion 
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:03:39.039: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
May 27 06:03:41.138: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3243 PodName:var-expansion-dcc9a6a9-5f59-4dad-bafe-a8cc5cbe6613 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:03:41.138: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:03:41.139: INFO: ExecWithOptions: Clientset creation
May 27 06:03:41.140: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-3243/pods/var-expansion-dcc9a6a9-5f59-4dad-bafe-a8cc5cbe6613/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path
May 27 06:03:41.386: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3243 PodName:var-expansion-dcc9a6a9-5f59-4dad-bafe-a8cc5cbe6613 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:03:41.387: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:03:41.388: INFO: ExecWithOptions: Clientset creation
May 27 06:03:41.388: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-3243/pods/var-expansion-dcc9a6a9-5f59-4dad-bafe-a8cc5cbe6613/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value
May 27 06:03:42.080: INFO: Successfully updated pod "var-expansion-dcc9a6a9-5f59-4dad-bafe-a8cc5cbe6613"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
May 27 06:03:42.089: INFO: Deleting pod "var-expansion-dcc9a6a9-5f59-4dad-bafe-a8cc5cbe6613" in namespace "var-expansion-3243"
May 27 06:03:42.129: INFO: Wait up to 5m0s for pod "var-expansion-dcc9a6a9-5f59-4dad-bafe-a8cc5cbe6613" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
May 27 06:04:16.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3243" for this suite.

• [SLOW TEST:37.151 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","total":356,"completed":143,"skipped":2888,"failed":0}
[sig-network] DNS 
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:04:16.190: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2687.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2687.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2687.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2687.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 27 06:04:20.366: INFO: DNS probes using dns-2687/dns-test-e24a2948-8341-4fe8-8208-750424b21dbf succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
May 27 06:04:20.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2687" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","total":356,"completed":144,"skipped":2888,"failed":0}
SSSSS
------------------------------
[sig-node] PodTemplates 
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:04:20.511: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
May 27 06:04:20.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-237" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":356,"completed":145,"skipped":2893,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:04:20.607: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
May 27 06:04:27.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4646" for this suite.
STEP: Destroying namespace "nsdeletetest-4628" for this suite.
May 27 06:04:27.796: INFO: Namespace nsdeletetest-4628 was already deleted
STEP: Destroying namespace "nsdeletetest-5514" for this suite.

• [SLOW TEST:7.204 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":356,"completed":146,"skipped":2908,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:04:27.811: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:58
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-b3ecb862-6dba-421c-8fba-43c4a3003ee8 in namespace container-probe-4883
May 27 06:04:29.881: INFO: Started pod busybox-b3ecb862-6dba-421c-8fba-43c4a3003ee8 in namespace container-probe-4883
STEP: checking the pod's current state and verifying that restartCount is present
May 27 06:04:29.888: INFO: Initial restart count of pod busybox-b3ecb862-6dba-421c-8fba-43c4a3003ee8 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
May 27 06:08:31.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4883" for this suite.

• [SLOW TEST:243.927 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":147,"skipped":2958,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:08:31.750: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test service account token: 
May 27 06:08:31.859: INFO: Waiting up to 5m0s for pod "test-pod-1b0f8eb2-ce13-4272-954f-a18e95cfbae6" in namespace "svcaccounts-6089" to be "Succeeded or Failed"
May 27 06:08:31.864: INFO: Pod "test-pod-1b0f8eb2-ce13-4272-954f-a18e95cfbae6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.618033ms
May 27 06:08:33.878: INFO: Pod "test-pod-1b0f8eb2-ce13-4272-954f-a18e95cfbae6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019776949s
May 27 06:08:35.890: INFO: Pod "test-pod-1b0f8eb2-ce13-4272-954f-a18e95cfbae6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031470823s
STEP: Saw pod success
May 27 06:08:35.890: INFO: Pod "test-pod-1b0f8eb2-ce13-4272-954f-a18e95cfbae6" satisfied condition "Succeeded or Failed"
May 27 06:08:35.898: INFO: Trying to get logs from node bohc9zohd7ee-3 pod test-pod-1b0f8eb2-ce13-4272-954f-a18e95cfbae6 container agnhost-container: <nil>
STEP: delete the pod
May 27 06:08:35.958: INFO: Waiting for pod test-pod-1b0f8eb2-ce13-4272-954f-a18e95cfbae6 to disappear
May 27 06:08:35.963: INFO: Pod test-pod-1b0f8eb2-ce13-4272-954f-a18e95cfbae6 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
May 27 06:08:35.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6089" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","total":356,"completed":148,"skipped":2991,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:08:35.984: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating all guestbook components
May 27 06:08:36.030: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

May 27 06:08:36.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 create -f -'
May 27 06:08:36.710: INFO: stderr: ""
May 27 06:08:36.710: INFO: stdout: "service/agnhost-replica created\n"
May 27 06:08:36.710: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

May 27 06:08:36.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 create -f -'
May 27 06:08:38.732: INFO: stderr: ""
May 27 06:08:38.732: INFO: stdout: "service/agnhost-primary created\n"
May 27 06:08:38.732: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 27 06:08:38.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 create -f -'
May 27 06:08:39.098: INFO: stderr: ""
May 27 06:08:39.098: INFO: stdout: "service/frontend created\n"
May 27 06:08:39.099: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.36
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

May 27 06:08:39.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 create -f -'
May 27 06:08:39.549: INFO: stderr: ""
May 27 06:08:39.550: INFO: stdout: "deployment.apps/frontend created\n"
May 27 06:08:39.550: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.36
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 27 06:08:39.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 create -f -'
May 27 06:08:40.030: INFO: stderr: ""
May 27 06:08:40.030: INFO: stdout: "deployment.apps/agnhost-primary created\n"
May 27 06:08:40.030: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.36
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 27 06:08:40.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 create -f -'
May 27 06:08:40.664: INFO: stderr: ""
May 27 06:08:40.664: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
May 27 06:08:40.664: INFO: Waiting for all frontend pods to be Running.
May 27 06:08:45.716: INFO: Waiting for frontend to serve content.
May 27 06:08:45.746: INFO: Trying to add a new entry to the guestbook.
May 27 06:08:45.785: INFO: Verifying that added entry can be retrieved.
May 27 06:08:45.801: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources
May 27 06:08:50.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 delete --grace-period=0 --force -f -'
May 27 06:08:50.980: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 27 06:08:50.980: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
May 27 06:08:50.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 delete --grace-period=0 --force -f -'
May 27 06:08:51.206: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 27 06:08:51.206: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
May 27 06:08:51.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 delete --grace-period=0 --force -f -'
May 27 06:08:51.484: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 27 06:08:51.484: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 27 06:08:51.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 delete --grace-period=0 --force -f -'
May 27 06:08:51.642: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 27 06:08:51.642: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 27 06:08:51.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 delete --grace-period=0 --force -f -'
May 27 06:08:51.821: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 27 06:08:51.821: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
May 27 06:08:51.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5023 delete --grace-period=0 --force -f -'
May 27 06:08:52.025: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 27 06:08:52.025: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:08:52.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5023" for this suite.

• [SLOW TEST:16.141 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:340
    should create and stop a working application  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":356,"completed":149,"skipped":3015,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:08:52.127: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2433
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-2433
May 27 06:08:52.611: INFO: Found 0 stateful pods, waiting for 1
May 27 06:09:02.622: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label
STEP: Getting /status
May 27 06:09:02.657: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status
May 27 06:09:02.670: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated
May 27 06:09:02.679: INFO: Observed &StatefulSet event: ADDED
May 27 06:09:02.679: INFO: Found Statefulset ss in namespace statefulset-2433 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May 27 06:09:02.679: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status
May 27 06:09:02.679: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
May 27 06:09:02.690: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched
May 27 06:09:02.693: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May 27 06:09:02.694: INFO: Deleting all statefulset in ns statefulset-2433
May 27 06:09:02.697: INFO: Scaling statefulset ss to 0
May 27 06:09:12.728: INFO: Waiting for statefulset status.replicas updated to 0
May 27 06:09:12.734: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
May 27 06:09:12.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2433" for this suite.

• [SLOW TEST:20.644 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","total":356,"completed":150,"skipped":3047,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:09:12.774: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6344
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6344
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6344
May 27 06:09:12.862: INFO: Found 0 stateful pods, waiting for 1
May 27 06:09:22.873: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 27 06:09:22.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-6344 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 27 06:09:23.161: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 27 06:09:23.161: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 27 06:09:23.161: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 27 06:09:23.169: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 27 06:09:33.177: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 27 06:09:33.178: INFO: Waiting for statefulset status.replicas updated to 0
May 27 06:09:33.206: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999307s
May 27 06:09:34.216: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99210736s
May 27 06:09:35.225: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.981184991s
May 27 06:09:36.236: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.973291973s
May 27 06:09:37.246: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.962148649s
May 27 06:09:38.256: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.952687385s
May 27 06:09:39.267: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.942742668s
May 27 06:09:40.277: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.931187681s
May 27 06:09:41.285: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.921938208s
May 27 06:09:42.302: INFO: Verifying statefulset ss doesn't scale past 1 for another 913.304025ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6344
May 27 06:09:43.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-6344 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 27 06:09:43.606: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 27 06:09:43.606: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 27 06:09:43.606: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 27 06:09:43.615: INFO: Found 1 stateful pods, waiting for 3
May 27 06:09:53.631: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 27 06:09:53.631: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 27 06:09:53.631: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 27 06:09:53.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-6344 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 27 06:09:53.929: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 27 06:09:53.929: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 27 06:09:53.929: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 27 06:09:53.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-6344 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 27 06:09:54.590: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 27 06:09:54.590: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 27 06:09:54.590: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 27 06:09:54.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-6344 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 27 06:09:54.837: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 27 06:09:54.837: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 27 06:09:54.837: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 27 06:09:54.837: INFO: Waiting for statefulset status.replicas updated to 0
May 27 06:09:54.844: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 27 06:10:04.860: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 27 06:10:04.860: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 27 06:10:04.860: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 27 06:10:04.887: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999945s
May 27 06:10:05.897: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989004763s
May 27 06:10:06.912: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978042773s
May 27 06:10:07.925: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.964517324s
May 27 06:10:08.936: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.950956409s
May 27 06:10:09.946: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.940722433s
May 27 06:10:10.959: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.929828037s
May 27 06:10:11.972: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.916704662s
May 27 06:10:12.981: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.904105498s
May 27 06:10:14.007: INFO: Verifying statefulset ss doesn't scale past 3 for another 894.834125ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6344
May 27 06:10:15.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-6344 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 27 06:10:15.361: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 27 06:10:15.361: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 27 06:10:15.361: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 27 06:10:15.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-6344 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 27 06:10:15.666: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 27 06:10:15.666: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 27 06:10:15.666: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 27 06:10:15.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-6344 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 27 06:10:16.025: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 27 06:10:16.025: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 27 06:10:16.025: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 27 06:10:16.025: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May 27 06:10:26.097: INFO: Deleting all statefulset in ns statefulset-6344
May 27 06:10:26.102: INFO: Scaling statefulset ss to 0
May 27 06:10:26.128: INFO: Waiting for statefulset status.replicas updated to 0
May 27 06:10:26.135: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
May 27 06:10:26.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6344" for this suite.

• [SLOW TEST:73.421 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":356,"completed":151,"skipped":3070,"failed":0}
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:10:26.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7739.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7739.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7739.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7739.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 27 06:10:30.357: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:30.373: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:30.384: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:30.392: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:30.398: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:30.404: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:30.410: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:30.416: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:30.416: INFO: Lookups using dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local]

May 27 06:10:35.425: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:35.434: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:35.441: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:35.446: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:35.451: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:35.458: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:35.466: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:35.471: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:35.471: INFO: Lookups using dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local]

May 27 06:10:40.438: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:40.446: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:40.452: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:40.460: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:40.476: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:40.482: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:40.488: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:40.497: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:40.498: INFO: Lookups using dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local]

May 27 06:10:45.425: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:45.431: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:45.437: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:45.442: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:45.450: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:45.487: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:45.498: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:45.507: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:45.507: INFO: Lookups using dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local]

May 27 06:10:50.425: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:50.431: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:50.441: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:50.450: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:50.456: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:50.470: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:50.481: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:50.491: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:50.491: INFO: Lookups using dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local]

May 27 06:10:55.438: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:55.458: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:55.474: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:55.481: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:55.493: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:55.505: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:55.516: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:55.531: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local from pod dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818: the server could not find the requested resource (get pods dns-test-f75c06b6-5819-4e93-8c5d-602d77852818)
May 27 06:10:55.531: INFO: Lookups using dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7739.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7739.svc.cluster.local jessie_udp@dns-test-service-2.dns-7739.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7739.svc.cluster.local]

May 27 06:11:00.493: INFO: DNS probes using dns-7739/dns-test-f75c06b6-5819-4e93-8c5d-602d77852818 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
May 27 06:11:00.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7739" for this suite.

• [SLOW TEST:34.463 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":356,"completed":152,"skipped":3074,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:11:00.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-eeab28f2-97bd-4b4b-ba04-1a126a06b295
STEP: Creating the pod
May 27 06:11:00.746: INFO: The status of Pod pod-configmaps-ac97df40-7fbb-46c1-be90-cd259bdc47f7 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:11:02.754: INFO: The status of Pod pod-configmaps-ac97df40-7fbb-46c1-be90-cd259bdc47f7 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:11:04.755: INFO: The status of Pod pod-configmaps-ac97df40-7fbb-46c1-be90-cd259bdc47f7 is Running (Ready = true)
STEP: Updating configmap configmap-test-upd-eeab28f2-97bd-4b4b-ba04-1a126a06b295
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
May 27 06:12:35.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8587" for this suite.

• [SLOW TEST:95.081 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":153,"skipped":3097,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:12:35.745: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl
STEP: Watching for error events or started pod
STEP: Waiting for pod completion
STEP: Checking that the pod succeeded
STEP: Getting logs from the pod
STEP: Checking that the sysctl is actually updated
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
May 27 06:12:39.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-1769" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":154,"skipped":3111,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:12:39.961: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:58
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-f9d883a0-bbf9-4353-a24d-d501c6f6424a in namespace container-probe-6000
May 27 06:12:42.045: INFO: Started pod liveness-f9d883a0-bbf9-4353-a24d-d501c6f6424a in namespace container-probe-6000
STEP: checking the pod's current state and verifying that restartCount is present
May 27 06:12:42.059: INFO: Initial restart count of pod liveness-f9d883a0-bbf9-4353-a24d-d501c6f6424a is 0
May 27 06:13:02.270: INFO: Restart count of pod container-probe-6000/liveness-f9d883a0-bbf9-4353-a24d-d501c6f6424a is now 1 (20.211514774s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
May 27 06:13:02.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6000" for this suite.

• [SLOW TEST:22.392 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":155,"skipped":3184,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:13:02.354: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-86472418-aa21-422c-a50c-fbd1dd0196a8
STEP: Creating a pod to test consume configMaps
May 27 06:13:02.448: INFO: Waiting up to 5m0s for pod "pod-configmaps-bd5c67d3-df77-4dbe-a5e1-bf1ff5ccbe10" in namespace "configmap-5402" to be "Succeeded or Failed"
May 27 06:13:02.459: INFO: Pod "pod-configmaps-bd5c67d3-df77-4dbe-a5e1-bf1ff5ccbe10": Phase="Pending", Reason="", readiness=false. Elapsed: 10.853249ms
May 27 06:13:04.475: INFO: Pod "pod-configmaps-bd5c67d3-df77-4dbe-a5e1-bf1ff5ccbe10": Phase="Running", Reason="", readiness=true. Elapsed: 2.02672904s
May 27 06:13:06.483: INFO: Pod "pod-configmaps-bd5c67d3-df77-4dbe-a5e1-bf1ff5ccbe10": Phase="Running", Reason="", readiness=false. Elapsed: 4.034685264s
May 27 06:13:08.495: INFO: Pod "pod-configmaps-bd5c67d3-df77-4dbe-a5e1-bf1ff5ccbe10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.046168155s
STEP: Saw pod success
May 27 06:13:08.495: INFO: Pod "pod-configmaps-bd5c67d3-df77-4dbe-a5e1-bf1ff5ccbe10" satisfied condition "Succeeded or Failed"
May 27 06:13:08.500: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-configmaps-bd5c67d3-df77-4dbe-a5e1-bf1ff5ccbe10 container configmap-volume-test: <nil>
STEP: delete the pod
May 27 06:13:08.539: INFO: Waiting for pod pod-configmaps-bd5c67d3-df77-4dbe-a5e1-bf1ff5ccbe10 to disappear
May 27 06:13:08.545: INFO: Pod pod-configmaps-bd5c67d3-df77-4dbe-a5e1-bf1ff5ccbe10 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
May 27 06:13:08.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5402" for this suite.

• [SLOW TEST:6.208 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":156,"skipped":3195,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:13:08.564: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-3834
May 27 06:13:08.639: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
May 27 06:13:10.652: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
May 27 06:13:10.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-3834 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
May 27 06:13:10.947: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
May 27 06:13:10.947: INFO: stdout: "iptables"
May 27 06:13:10.947: INFO: proxyMode: iptables
May 27 06:13:10.970: INFO: Waiting for pod kube-proxy-mode-detector to disappear
May 27 06:13:10.976: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-3834
STEP: creating replication controller affinity-clusterip-timeout in namespace services-3834
I0527 06:13:11.028561      15 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-3834, replica count: 3
I0527 06:13:14.080423      15 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 27 06:13:14.103: INFO: Creating new exec pod
May 27 06:13:17.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-3834 exec execpod-affinity7szk5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
May 27 06:13:17.572: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
May 27 06:13:17.572: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 06:13:17.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-3834 exec execpod-affinity7szk5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.58.15 80'
May 27 06:13:17.830: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.58.15 80\nConnection to 10.233.58.15 80 port [tcp/http] succeeded!\n"
May 27 06:13:17.831: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 06:13:17.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-3834 exec execpod-affinity7szk5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.58.15:80/ ; done'
May 27 06:13:18.290: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n"
May 27 06:13:18.291: INFO: stdout: "\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd\naffinity-clusterip-timeout-cqlnd"
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Received response from host: affinity-clusterip-timeout-cqlnd
May 27 06:13:18.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-3834 exec execpod-affinity7szk5 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.58.15:80/'
May 27 06:13:18.520: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n"
May 27 06:13:18.520: INFO: stdout: "affinity-clusterip-timeout-cqlnd"
May 27 06:13:38.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-3834 exec execpod-affinity7szk5 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.58.15:80/'
May 27 06:13:38.780: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.58.15:80/\n"
May 27 06:13:38.780: INFO: stdout: "affinity-clusterip-timeout-cgh69"
May 27 06:13:38.780: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-3834, will wait for the garbage collector to delete the pods
May 27 06:13:38.875: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 12.89722ms
May 27 06:13:38.976: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.659527ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 06:13:41.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3834" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:32.793 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":157,"skipped":3219,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:13:41.361: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name secret-emptykey-test-22c6d504-649b-4aa8-bf17-f9fcb4565ea5
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
May 27 06:13:41.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5677" for this suite.
•{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","total":356,"completed":158,"skipped":3229,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:13:41.437: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 06:13:41.505: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9a286f49-bf05-4d8f-a334-af5dde9636d5" in namespace "downward-api-3097" to be "Succeeded or Failed"
May 27 06:13:41.512: INFO: Pod "downwardapi-volume-9a286f49-bf05-4d8f-a334-af5dde9636d5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.459409ms
May 27 06:13:43.525: INFO: Pod "downwardapi-volume-9a286f49-bf05-4d8f-a334-af5dde9636d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020184697s
May 27 06:13:45.540: INFO: Pod "downwardapi-volume-9a286f49-bf05-4d8f-a334-af5dde9636d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034728158s
STEP: Saw pod success
May 27 06:13:45.540: INFO: Pod "downwardapi-volume-9a286f49-bf05-4d8f-a334-af5dde9636d5" satisfied condition "Succeeded or Failed"
May 27 06:13:45.545: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-9a286f49-bf05-4d8f-a334-af5dde9636d5 container client-container: <nil>
STEP: delete the pod
May 27 06:13:45.595: INFO: Waiting for pod downwardapi-volume-9a286f49-bf05-4d8f-a334-af5dde9636d5 to disappear
May 27 06:13:45.599: INFO: Pod downwardapi-volume-9a286f49-bf05-4d8f-a334-af5dde9636d5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
May 27 06:13:45.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3097" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":159,"skipped":3270,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:13:45.621: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 27 06:13:45.690: INFO: Waiting up to 5m0s for pod "pod-7ccb414b-2591-4b47-8930-d478d7d4fbc8" in namespace "emptydir-314" to be "Succeeded or Failed"
May 27 06:13:45.704: INFO: Pod "pod-7ccb414b-2591-4b47-8930-d478d7d4fbc8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.755278ms
May 27 06:13:47.717: INFO: Pod "pod-7ccb414b-2591-4b47-8930-d478d7d4fbc8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02631609s
May 27 06:13:49.734: INFO: Pod "pod-7ccb414b-2591-4b47-8930-d478d7d4fbc8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043978271s
STEP: Saw pod success
May 27 06:13:49.734: INFO: Pod "pod-7ccb414b-2591-4b47-8930-d478d7d4fbc8" satisfied condition "Succeeded or Failed"
May 27 06:13:49.740: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-7ccb414b-2591-4b47-8930-d478d7d4fbc8 container test-container: <nil>
STEP: delete the pod
May 27 06:13:49.784: INFO: Waiting for pod pod-7ccb414b-2591-4b47-8930-d478d7d4fbc8 to disappear
May 27 06:13:49.792: INFO: Pod pod-7ccb414b-2591-4b47-8930-d478d7d4fbc8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 06:13:49.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-314" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":160,"skipped":3270,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:13:49.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with one valid and two invalid sysctls
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
May 27 06:13:49.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-5383" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":161,"skipped":3345,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:13:49.940: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
May 27 06:13:49.975: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:14:19.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9883" for this suite.

• [SLOW TEST:29.606 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":356,"completed":162,"skipped":3348,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:14:19.546: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a collection of services
May 27 06:14:19.596: INFO: Creating e2e-svc-a-f8kzq
May 27 06:14:19.613: INFO: Creating e2e-svc-b-wbw5x
May 27 06:14:19.641: INFO: Creating e2e-svc-c-hn5tr
STEP: deleting service collection
May 27 06:14:19.803: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 06:14:19.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9227" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760
•{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","total":356,"completed":163,"skipped":3371,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:14:19.823: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 06:14:19.894: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03a2d84d-7d7a-4b86-bfb7-2be1f8b4bea2" in namespace "projected-9820" to be "Succeeded or Failed"
May 27 06:14:19.900: INFO: Pod "downwardapi-volume-03a2d84d-7d7a-4b86-bfb7-2be1f8b4bea2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.084426ms
May 27 06:14:21.913: INFO: Pod "downwardapi-volume-03a2d84d-7d7a-4b86-bfb7-2be1f8b4bea2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01856352s
May 27 06:14:23.926: INFO: Pod "downwardapi-volume-03a2d84d-7d7a-4b86-bfb7-2be1f8b4bea2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032089856s
STEP: Saw pod success
May 27 06:14:23.927: INFO: Pod "downwardapi-volume-03a2d84d-7d7a-4b86-bfb7-2be1f8b4bea2" satisfied condition "Succeeded or Failed"
May 27 06:14:23.931: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-03a2d84d-7d7a-4b86-bfb7-2be1f8b4bea2 container client-container: <nil>
STEP: delete the pod
May 27 06:14:23.978: INFO: Waiting for pod downwardapi-volume-03a2d84d-7d7a-4b86-bfb7-2be1f8b4bea2 to disappear
May 27 06:14:23.982: INFO: Pod downwardapi-volume-03a2d84d-7d7a-4b86-bfb7-2be1f8b4bea2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
May 27 06:14:23.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9820" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":164,"skipped":3381,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:14:24.002: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:14:24.183: INFO: The status of Pod busybox-readonly-fs2c257589-909e-4267-a9fc-bd45663ae80c is Pending, waiting for it to be Running (with Ready = true)
May 27 06:14:26.196: INFO: The status of Pod busybox-readonly-fs2c257589-909e-4267-a9fc-bd45663ae80c is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
May 27 06:14:26.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4131" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":165,"skipped":3401,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:14:26.237: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-503a9a00-fbd2-4bcc-b445-691f9f52b677
STEP: Creating a pod to test consume configMaps
May 27 06:14:26.327: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f9bda6bf-6054-4ad6-8660-c73318566d49" in namespace "projected-2411" to be "Succeeded or Failed"
May 27 06:14:26.338: INFO: Pod "pod-projected-configmaps-f9bda6bf-6054-4ad6-8660-c73318566d49": Phase="Pending", Reason="", readiness=false. Elapsed: 11.062704ms
May 27 06:14:28.351: INFO: Pod "pod-projected-configmaps-f9bda6bf-6054-4ad6-8660-c73318566d49": Phase="Running", Reason="", readiness=true. Elapsed: 2.023466902s
May 27 06:14:30.366: INFO: Pod "pod-projected-configmaps-f9bda6bf-6054-4ad6-8660-c73318566d49": Phase="Running", Reason="", readiness=false. Elapsed: 4.038727928s
May 27 06:14:32.382: INFO: Pod "pod-projected-configmaps-f9bda6bf-6054-4ad6-8660-c73318566d49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054120167s
STEP: Saw pod success
May 27 06:14:32.382: INFO: Pod "pod-projected-configmaps-f9bda6bf-6054-4ad6-8660-c73318566d49" satisfied condition "Succeeded or Failed"
May 27 06:14:32.392: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-configmaps-f9bda6bf-6054-4ad6-8660-c73318566d49 container agnhost-container: <nil>
STEP: delete the pod
May 27 06:14:32.434: INFO: Waiting for pod pod-projected-configmaps-f9bda6bf-6054-4ad6-8660-c73318566d49 to disappear
May 27 06:14:32.440: INFO: Pod pod-projected-configmaps-f9bda6bf-6054-4ad6-8660-c73318566d49 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
May 27 06:14:32.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2411" for this suite.

• [SLOW TEST:6.226 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":166,"skipped":3416,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:14:32.471: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating server pod server in namespace prestop-6376
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6376
STEP: Deleting pre-stop pod
May 27 06:14:43.617: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:188
May 27 06:14:43.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6376" for this suite.

• [SLOW TEST:11.243 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":356,"completed":167,"skipped":3462,"failed":0}
SSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:14:43.717: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting a starting resourceVersion
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
May 27 06:14:46.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-330" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":356,"completed":168,"skipped":3465,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:14:46.638: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:14:46.697: INFO: Creating simple deployment test-new-deployment
May 27 06:14:46.726: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
May 27 06:14:48.762: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 14, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 14, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 14, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 14, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-55df494869\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the deployment Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May 27 06:14:50.901: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-8593  f4f4fb78-4877-4706-ad76-5cf3497efebe 21968 3 2022-05-27 06:14:46 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-05-27 06:14:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 06:14:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00297dcf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-05-27 06:14:48 +0000 UTC,LastTransitionTime:2022-05-27 06:14:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-55df494869" has successfully progressed.,LastUpdateTime:2022-05-27 06:14:48 +0000 UTC,LastTransitionTime:2022-05-27 06:14:46 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May 27 06:14:50.964: INFO: New ReplicaSet "test-new-deployment-55df494869" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-55df494869  deployment-8593  b13b3eb1-be25-4b90-b103-820ba4df12f6 21974 2 2022-05-27 06:14:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment f4f4fb78-4877-4706-ad76-5cf3497efebe 0xc005186a37 0xc005186a38}] []  [{kube-controller-manager Update apps/v1 2022-05-27 06:14:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f4f4fb78-4877-4706-ad76-5cf3497efebe\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 06:14:48 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005186ac8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May 27 06:14:50.975: INFO: Pod "test-new-deployment-55df494869-cpk4c" is not available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-cpk4c test-new-deployment-55df494869- deployment-8593  e056bfc3-7cdd-4318-8bf1-12cfa7642545 21973 0 2022-05-27 06:14:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet test-new-deployment-55df494869 b13b3eb1-be25-4b90-b103-820ba4df12f6 0xc005186e87 0xc005186e88}] []  [{kube-controller-manager Update v1 2022-05-27 06:14:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b13b3eb1-be25-4b90-b103-820ba4df12f6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vbzph,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vbzph,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:14:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 06:14:50.976: INFO: Pod "test-new-deployment-55df494869-v77rb" is available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-v77rb test-new-deployment-55df494869- deployment-8593  81d8d84a-6a0b-4c77-aed8-5dde17a121db 21947 0 2022-05-27 06:14:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet test-new-deployment-55df494869 b13b3eb1-be25-4b90-b103-820ba4df12f6 0xc005186ff0 0xc005186ff1}] []  [{kube-controller-manager Update v1 2022-05-27 06:14:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b13b3eb1-be25-4b90-b103-820ba4df12f6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 06:14:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.122\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k5mmz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k5mmz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:14:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:14:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:14:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:14:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.16,PodIP:10.233.65.122,StartTime:2022-05-27 06:14:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 06:14:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://ec66e5d707646bdce4d707cbb42461015b7e3763bc873dd6224690ca65d00374,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.122,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
May 27 06:14:50.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8593" for this suite.
•{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","total":356,"completed":169,"skipped":3484,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:14:51.024: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-f647ce93-717d-49fe-a76c-b2d55ff32c6d
STEP: Creating configMap with name cm-test-opt-upd-1694ccd6-ff83-475e-b23f-4943ff43b5a5
STEP: Creating the pod
May 27 06:14:51.136: INFO: The status of Pod pod-configmaps-69651f4b-76c2-4996-8da4-3f69fa689161 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:14:53.155: INFO: The status of Pod pod-configmaps-69651f4b-76c2-4996-8da4-3f69fa689161 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:14:55.153: INFO: The status of Pod pod-configmaps-69651f4b-76c2-4996-8da4-3f69fa689161 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-f647ce93-717d-49fe-a76c-b2d55ff32c6d
STEP: Updating configmap cm-test-opt-upd-1694ccd6-ff83-475e-b23f-4943ff43b5a5
STEP: Creating configMap with name cm-test-opt-create-a3e82fd4-0dc3-4696-a719-5f1d7dd4d101
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
May 27 06:16:00.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8466" for this suite.

• [SLOW TEST:69.233 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":170,"skipped":3509,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:16:00.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 06:16:00.358: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cbb9120f-62bb-4e2d-ae80-2c51e1444569" in namespace "projected-5643" to be "Succeeded or Failed"
May 27 06:16:00.396: INFO: Pod "downwardapi-volume-cbb9120f-62bb-4e2d-ae80-2c51e1444569": Phase="Pending", Reason="", readiness=false. Elapsed: 37.772054ms
May 27 06:16:02.409: INFO: Pod "downwardapi-volume-cbb9120f-62bb-4e2d-ae80-2c51e1444569": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050301991s
May 27 06:16:04.426: INFO: Pod "downwardapi-volume-cbb9120f-62bb-4e2d-ae80-2c51e1444569": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067835393s
STEP: Saw pod success
May 27 06:16:04.426: INFO: Pod "downwardapi-volume-cbb9120f-62bb-4e2d-ae80-2c51e1444569" satisfied condition "Succeeded or Failed"
May 27 06:16:04.433: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-cbb9120f-62bb-4e2d-ae80-2c51e1444569 container client-container: <nil>
STEP: delete the pod
May 27 06:16:04.501: INFO: Waiting for pod downwardapi-volume-cbb9120f-62bb-4e2d-ae80-2c51e1444569 to disappear
May 27 06:16:04.510: INFO: Pod downwardapi-volume-cbb9120f-62bb-4e2d-ae80-2c51e1444569 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
May 27 06:16:04.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5643" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":171,"skipped":3523,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:16:04.540: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
May 27 06:16:11.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8567" for this suite.

• [SLOW TEST:7.123 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":356,"completed":172,"skipped":3545,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:16:11.664: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on tmpfs
May 27 06:16:11.732: INFO: Waiting up to 5m0s for pod "pod-e79b8c2e-9985-46b8-aa6a-2fb02264f97c" in namespace "emptydir-6268" to be "Succeeded or Failed"
May 27 06:16:11.737: INFO: Pod "pod-e79b8c2e-9985-46b8-aa6a-2fb02264f97c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.569806ms
May 27 06:16:13.751: INFO: Pod "pod-e79b8c2e-9985-46b8-aa6a-2fb02264f97c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018975901s
May 27 06:16:15.765: INFO: Pod "pod-e79b8c2e-9985-46b8-aa6a-2fb02264f97c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033375744s
STEP: Saw pod success
May 27 06:16:15.765: INFO: Pod "pod-e79b8c2e-9985-46b8-aa6a-2fb02264f97c" satisfied condition "Succeeded or Failed"
May 27 06:16:15.776: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-e79b8c2e-9985-46b8-aa6a-2fb02264f97c container test-container: <nil>
STEP: delete the pod
May 27 06:16:15.820: INFO: Waiting for pod pod-e79b8c2e-9985-46b8-aa6a-2fb02264f97c to disappear
May 27 06:16:15.837: INFO: Pod pod-e79b8c2e-9985-46b8-aa6a-2fb02264f97c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 06:16:15.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6268" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":173,"skipped":3554,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:16:15.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
May 27 06:16:15.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-469" for this suite.
STEP: Destroying namespace "nspatchtest-ec02c309-9f89-44b1-8f29-d3f6fc01d435-8620" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":356,"completed":174,"skipped":3562,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:16:16.009: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
May 27 06:16:16.199: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May 27 06:16:18.210: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
May 27 06:16:18.248: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
May 27 06:16:20.263: INFO: The status of Pod pod-with-poststart-http-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 27 06:16:20.299: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 27 06:16:20.305: INFO: Pod pod-with-poststart-http-hook still exists
May 27 06:16:22.305: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 27 06:16:22.320: INFO: Pod pod-with-poststart-http-hook still exists
May 27 06:16:24.306: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 27 06:16:24.322: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
May 27 06:16:24.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5765" for this suite.

• [SLOW TEST:8.334 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":356,"completed":175,"skipped":3570,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:16:24.346: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-99bfc569-a769-4569-bf5c-36b0a6b18d4c
STEP: Creating a pod to test consume secrets
May 27 06:16:24.432: INFO: Waiting up to 5m0s for pod "pod-secrets-f2933abc-01f7-4313-a31d-2225c77fa5f7" in namespace "secrets-9643" to be "Succeeded or Failed"
May 27 06:16:24.441: INFO: Pod "pod-secrets-f2933abc-01f7-4313-a31d-2225c77fa5f7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.074271ms
May 27 06:16:26.459: INFO: Pod "pod-secrets-f2933abc-01f7-4313-a31d-2225c77fa5f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026137412s
May 27 06:16:28.474: INFO: Pod "pod-secrets-f2933abc-01f7-4313-a31d-2225c77fa5f7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041206168s
May 27 06:16:30.488: INFO: Pod "pod-secrets-f2933abc-01f7-4313-a31d-2225c77fa5f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.055867065s
STEP: Saw pod success
May 27 06:16:30.489: INFO: Pod "pod-secrets-f2933abc-01f7-4313-a31d-2225c77fa5f7" satisfied condition "Succeeded or Failed"
May 27 06:16:30.493: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-secrets-f2933abc-01f7-4313-a31d-2225c77fa5f7 container secret-volume-test: <nil>
STEP: delete the pod
May 27 06:16:30.547: INFO: Waiting for pod pod-secrets-f2933abc-01f7-4313-a31d-2225c77fa5f7 to disappear
May 27 06:16:30.555: INFO: Pod pod-secrets-f2933abc-01f7-4313-a31d-2225c77fa5f7 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
May 27 06:16:30.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9643" for this suite.

• [SLOW TEST:6.228 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":176,"skipped":3583,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:16:30.575: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
May 27 06:16:58.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7944" for this suite.

• [SLOW TEST:28.199 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":356,"completed":177,"skipped":3585,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:16:58.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3933
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3933
STEP: Waiting until pod test-pod will start running in namespace statefulset-3933
STEP: Creating statefulset with conflicting port in namespace statefulset-3933
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3933
May 27 06:17:00.946: INFO: Observed stateful pod in namespace: statefulset-3933, name: ss-0, uid: fc025590-c170-4601-96ea-ae3bcef823f8, status phase: Pending. Waiting for statefulset controller to delete.
May 27 06:17:00.979: INFO: Observed stateful pod in namespace: statefulset-3933, name: ss-0, uid: fc025590-c170-4601-96ea-ae3bcef823f8, status phase: Failed. Waiting for statefulset controller to delete.
May 27 06:17:00.998: INFO: Observed stateful pod in namespace: statefulset-3933, name: ss-0, uid: fc025590-c170-4601-96ea-ae3bcef823f8, status phase: Failed. Waiting for statefulset controller to delete.
May 27 06:17:01.008: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3933
STEP: Removing pod with conflicting port in namespace statefulset-3933
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3933 and will be in running state
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May 27 06:17:19.203: INFO: Deleting all statefulset in ns statefulset-3933
May 27 06:17:19.211: INFO: Scaling statefulset ss to 0
May 27 06:17:29.294: INFO: Waiting for statefulset status.replicas updated to 0
May 27 06:17:29.305: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
May 27 06:17:29.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3933" for this suite.

• [SLOW TEST:30.597 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":356,"completed":178,"skipped":3594,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:17:29.375: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
May 27 06:17:38.790: INFO: 84 pods remaining
May 27 06:17:38.790: INFO: 80 pods has nil DeletionTimestamp
May 27 06:17:38.790: INFO: 
May 27 06:17:39.908: INFO: 71 pods remaining
May 27 06:17:39.908: INFO: 61 pods has nil DeletionTimestamp
May 27 06:17:39.908: INFO: 
May 27 06:17:41.870: INFO: 58 pods remaining
May 27 06:17:41.870: INFO: 44 pods has nil DeletionTimestamp
May 27 06:17:41.875: INFO: 
May 27 06:17:43.602: INFO: 44 pods remaining
May 27 06:17:43.602: INFO: 23 pods has nil DeletionTimestamp
May 27 06:17:43.602: INFO: 
May 27 06:17:45.181: INFO: 36 pods remaining
May 27 06:17:45.182: INFO: 2 pods has nil DeletionTimestamp
May 27 06:17:45.182: INFO: 
May 27 06:17:46.122: INFO: 25 pods remaining
May 27 06:17:46.123: INFO: 0 pods has nil DeletionTimestamp
May 27 06:17:46.123: INFO: 
May 27 06:17:47.289: INFO: 16 pods remaining
May 27 06:17:47.289: INFO: 0 pods has nil DeletionTimestamp
May 27 06:17:47.289: INFO: 
May 27 06:17:47.678: INFO: 14 pods remaining
May 27 06:17:47.678: INFO: 0 pods has nil DeletionTimestamp
May 27 06:17:47.678: INFO: 
May 27 06:17:49.378: INFO: 3 pods remaining
May 27 06:17:49.378: INFO: 0 pods has nil DeletionTimestamp
May 27 06:17:49.378: INFO: 
May 27 06:17:49.747: INFO: 1 pods remaining
May 27 06:17:49.747: INFO: 0 pods has nil DeletionTimestamp
May 27 06:17:49.747: INFO: 
STEP: Gathering metrics
May 27 06:17:51.065: INFO: The status of Pod kube-controller-manager-bohc9zohd7ee-2 is Running (Ready = true)
May 27 06:17:51.991: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
May 27 06:17:51.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3360" for this suite.

• [SLOW TEST:22.821 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":356,"completed":179,"skipped":3598,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:17:52.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 06:17:52.903: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9" in namespace "projected-2005" to be "Succeeded or Failed"
May 27 06:17:52.924: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 21.067866ms
May 27 06:17:54.974: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071089461s
May 27 06:17:57.016: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.113592582s
May 27 06:17:59.176: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.273166742s
May 27 06:18:01.454: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.551798781s
May 27 06:18:03.473: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.570089372s
May 27 06:18:05.562: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.659440876s
May 27 06:18:07.616: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.713215575s
May 27 06:18:09.880: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.977634892s
May 27 06:18:11.906: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 19.002919744s
May 27 06:18:13.943: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 21.040029529s
May 27 06:18:15.961: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 23.05877513s
May 27 06:18:17.987: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 25.084473252s
May 27 06:18:20.004: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 27.101136407s
May 27 06:18:22.019: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 29.116414124s
May 27 06:18:24.033: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 31.129889051s
STEP: Saw pod success
May 27 06:18:24.033: INFO: Pod "downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9" satisfied condition "Succeeded or Failed"
May 27 06:18:24.039: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9 container client-container: <nil>
STEP: delete the pod
May 27 06:18:24.259: INFO: Waiting for pod downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9 to disappear
May 27 06:18:24.268: INFO: Pod downwardapi-volume-9387acad-8d76-4cd5-b2f3-d86e68e59bc9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
May 27 06:18:24.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2005" for this suite.

• [SLOW TEST:32.099 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":180,"skipped":3648,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:18:24.300: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
May 27 06:18:24.410: INFO: Waiting up to 5m0s for pod "pod-aef954d3-6e54-4d99-949f-65026015ed47" in namespace "emptydir-9499" to be "Succeeded or Failed"
May 27 06:18:24.429: INFO: Pod "pod-aef954d3-6e54-4d99-949f-65026015ed47": Phase="Pending", Reason="", readiness=false. Elapsed: 19.327436ms
May 27 06:18:26.445: INFO: Pod "pod-aef954d3-6e54-4d99-949f-65026015ed47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034992099s
May 27 06:18:28.461: INFO: Pod "pod-aef954d3-6e54-4d99-949f-65026015ed47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051199361s
STEP: Saw pod success
May 27 06:18:28.461: INFO: Pod "pod-aef954d3-6e54-4d99-949f-65026015ed47" satisfied condition "Succeeded or Failed"
May 27 06:18:28.481: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-aef954d3-6e54-4d99-949f-65026015ed47 container test-container: <nil>
STEP: delete the pod
May 27 06:18:28.520: INFO: Waiting for pod pod-aef954d3-6e54-4d99-949f-65026015ed47 to disappear
May 27 06:18:28.526: INFO: Pod pod-aef954d3-6e54-4d99-949f-65026015ed47 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 06:18:28.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9499" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":181,"skipped":3652,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:18:28.549: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 06:18:28.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7506" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":356,"completed":182,"skipped":3663,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:18:28.650: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
May 27 06:18:55.585: INFO: 93 pods remaining
May 27 06:18:55.585: INFO: 70 pods has nil DeletionTimestamp
May 27 06:18:55.585: INFO: 
May 27 06:18:59.633: INFO: 78 pods remaining
May 27 06:18:59.633: INFO: 50 pods has nil DeletionTimestamp
May 27 06:18:59.633: INFO: 
STEP: Gathering metrics
May 27 06:19:05.230: INFO: The status of Pod kube-controller-manager-bohc9zohd7ee-2 is Running (Ready = true)
May 27 06:19:05.974: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

May 27 06:19:05.974: INFO: Deleting pod "simpletest-rc-to-be-deleted-24wxm" in namespace "gc-8957"
May 27 06:19:06.313: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lp6c" in namespace "gc-8957"
May 27 06:19:06.606: INFO: Deleting pod "simpletest-rc-to-be-deleted-2s8hf" in namespace "gc-8957"
May 27 06:19:06.801: INFO: Deleting pod "simpletest-rc-to-be-deleted-2tzzb" in namespace "gc-8957"
May 27 06:19:06.934: INFO: Deleting pod "simpletest-rc-to-be-deleted-2v94g" in namespace "gc-8957"
May 27 06:19:07.259: INFO: Deleting pod "simpletest-rc-to-be-deleted-2w6t4" in namespace "gc-8957"
May 27 06:19:07.414: INFO: Deleting pod "simpletest-rc-to-be-deleted-4mvf2" in namespace "gc-8957"
May 27 06:19:07.514: INFO: Deleting pod "simpletest-rc-to-be-deleted-4wgg8" in namespace "gc-8957"
May 27 06:19:07.720: INFO: Deleting pod "simpletest-rc-to-be-deleted-5tgjg" in namespace "gc-8957"
May 27 06:19:07.868: INFO: Deleting pod "simpletest-rc-to-be-deleted-5tj95" in namespace "gc-8957"
May 27 06:19:07.982: INFO: Deleting pod "simpletest-rc-to-be-deleted-5zt76" in namespace "gc-8957"
May 27 06:19:08.449: INFO: Deleting pod "simpletest-rc-to-be-deleted-67m5p" in namespace "gc-8957"
May 27 06:19:08.750: INFO: Deleting pod "simpletest-rc-to-be-deleted-696sx" in namespace "gc-8957"
May 27 06:19:09.136: INFO: Deleting pod "simpletest-rc-to-be-deleted-6h6wz" in namespace "gc-8957"
May 27 06:19:09.493: INFO: Deleting pod "simpletest-rc-to-be-deleted-6kwcn" in namespace "gc-8957"
May 27 06:19:09.711: INFO: Deleting pod "simpletest-rc-to-be-deleted-786n4" in namespace "gc-8957"
May 27 06:19:09.794: INFO: Deleting pod "simpletest-rc-to-be-deleted-7b94p" in namespace "gc-8957"
May 27 06:19:09.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-7l2tt" in namespace "gc-8957"
May 27 06:19:09.995: INFO: Deleting pod "simpletest-rc-to-be-deleted-7mnt2" in namespace "gc-8957"
May 27 06:19:10.433: INFO: Deleting pod "simpletest-rc-to-be-deleted-7pck4" in namespace "gc-8957"
May 27 06:19:10.611: INFO: Deleting pod "simpletest-rc-to-be-deleted-7zpg2" in namespace "gc-8957"
May 27 06:19:10.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-8bbhw" in namespace "gc-8957"
May 27 06:19:11.140: INFO: Deleting pod "simpletest-rc-to-be-deleted-8dnb6" in namespace "gc-8957"
May 27 06:19:11.348: INFO: Deleting pod "simpletest-rc-to-be-deleted-8hv4x" in namespace "gc-8957"
May 27 06:19:11.529: INFO: Deleting pod "simpletest-rc-to-be-deleted-8k62g" in namespace "gc-8957"
May 27 06:19:11.636: INFO: Deleting pod "simpletest-rc-to-be-deleted-b46mm" in namespace "gc-8957"
May 27 06:19:11.963: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbp4q" in namespace "gc-8957"
May 27 06:19:12.276: INFO: Deleting pod "simpletest-rc-to-be-deleted-bc6c9" in namespace "gc-8957"
May 27 06:19:12.797: INFO: Deleting pod "simpletest-rc-to-be-deleted-bvm5x" in namespace "gc-8957"
May 27 06:19:13.052: INFO: Deleting pod "simpletest-rc-to-be-deleted-bxfcg" in namespace "gc-8957"
May 27 06:19:13.182: INFO: Deleting pod "simpletest-rc-to-be-deleted-c8t8b" in namespace "gc-8957"
May 27 06:19:13.312: INFO: Deleting pod "simpletest-rc-to-be-deleted-cfsrj" in namespace "gc-8957"
May 27 06:19:13.395: INFO: Deleting pod "simpletest-rc-to-be-deleted-ckjs6" in namespace "gc-8957"
May 27 06:19:13.464: INFO: Deleting pod "simpletest-rc-to-be-deleted-crv7t" in namespace "gc-8957"
May 27 06:19:13.526: INFO: Deleting pod "simpletest-rc-to-be-deleted-czc2k" in namespace "gc-8957"
May 27 06:19:13.637: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6qnx" in namespace "gc-8957"
May 27 06:19:13.837: INFO: Deleting pod "simpletest-rc-to-be-deleted-d9q2j" in namespace "gc-8957"
May 27 06:19:13.988: INFO: Deleting pod "simpletest-rc-to-be-deleted-dfw72" in namespace "gc-8957"
May 27 06:19:14.186: INFO: Deleting pod "simpletest-rc-to-be-deleted-dgqfj" in namespace "gc-8957"
May 27 06:19:14.470: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhnvm" in namespace "gc-8957"
May 27 06:19:14.631: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhtlw" in namespace "gc-8957"
May 27 06:19:14.826: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnqr5" in namespace "gc-8957"
May 27 06:19:14.986: INFO: Deleting pod "simpletest-rc-to-be-deleted-drcgs" in namespace "gc-8957"
May 27 06:19:15.052: INFO: Deleting pod "simpletest-rc-to-be-deleted-fgvsl" in namespace "gc-8957"
May 27 06:19:15.171: INFO: Deleting pod "simpletest-rc-to-be-deleted-fkmpq" in namespace "gc-8957"
May 27 06:19:15.296: INFO: Deleting pod "simpletest-rc-to-be-deleted-fkmpt" in namespace "gc-8957"
May 27 06:19:15.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-fssmr" in namespace "gc-8957"
May 27 06:19:15.483: INFO: Deleting pod "simpletest-rc-to-be-deleted-fz8kn" in namespace "gc-8957"
May 27 06:19:15.538: INFO: Deleting pod "simpletest-rc-to-be-deleted-g8fxk" in namespace "gc-8957"
May 27 06:19:15.621: INFO: Deleting pod "simpletest-rc-to-be-deleted-gdzf4" in namespace "gc-8957"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
May 27 06:19:15.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8957" for this suite.

• [SLOW TEST:47.125 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":356,"completed":183,"skipped":3671,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:19:15.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
May 27 06:19:15.955: INFO: Waiting up to 5m0s for pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3" in namespace "emptydir-6691" to be "Succeeded or Failed"
May 27 06:19:15.982: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 26.77034ms
May 27 06:19:18.008: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052529505s
May 27 06:19:20.019: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063284681s
May 27 06:19:22.187: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.232176702s
May 27 06:19:24.363: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.407477509s
May 27 06:19:26.386: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.430438754s
May 27 06:19:28.397: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.441303222s
May 27 06:19:30.407: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.451814185s
May 27 06:19:32.428: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 16.472356353s
May 27 06:19:34.444: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 18.488738838s
May 27 06:19:36.459: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.503330927s
May 27 06:19:38.475: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 22.519293102s
May 27 06:19:40.486: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 24.530207762s
May 27 06:19:42.508: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 26.55231248s
May 27 06:19:44.523: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Pending", Reason="", readiness=false. Elapsed: 28.567796611s
May 27 06:19:46.538: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.583185157s
STEP: Saw pod success
May 27 06:19:46.539: INFO: Pod "pod-0098ab89-265a-4159-8f63-e51f10d689f3" satisfied condition "Succeeded or Failed"
May 27 06:19:46.546: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-0098ab89-265a-4159-8f63-e51f10d689f3 container test-container: <nil>
STEP: delete the pod
May 27 06:19:46.614: INFO: Waiting for pod pod-0098ab89-265a-4159-8f63-e51f10d689f3 to disappear
May 27 06:19:46.636: INFO: Pod pod-0098ab89-265a-4159-8f63-e51f10d689f3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 06:19:46.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6691" for this suite.

• [SLOW TEST:30.895 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":184,"skipped":3691,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:19:46.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-81b816f1-0808-4c17-aa4c-7bd97bd6ade5
STEP: Creating a pod to test consume secrets
May 27 06:19:46.807: INFO: Waiting up to 5m0s for pod "pod-secrets-3710ef11-a530-4e00-a500-d637efce80b5" in namespace "secrets-4602" to be "Succeeded or Failed"
May 27 06:19:46.827: INFO: Pod "pod-secrets-3710ef11-a530-4e00-a500-d637efce80b5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.830569ms
May 27 06:19:48.844: INFO: Pod "pod-secrets-3710ef11-a530-4e00-a500-d637efce80b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036445506s
May 27 06:19:50.853: INFO: Pod "pod-secrets-3710ef11-a530-4e00-a500-d637efce80b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045477024s
STEP: Saw pod success
May 27 06:19:50.853: INFO: Pod "pod-secrets-3710ef11-a530-4e00-a500-d637efce80b5" satisfied condition "Succeeded or Failed"
May 27 06:19:50.860: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-secrets-3710ef11-a530-4e00-a500-d637efce80b5 container secret-env-test: <nil>
STEP: delete the pod
May 27 06:19:50.895: INFO: Waiting for pod pod-secrets-3710ef11-a530-4e00-a500-d637efce80b5 to disappear
May 27 06:19:50.902: INFO: Pod pod-secrets-3710ef11-a530-4e00-a500-d637efce80b5 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
May 27 06:19:50.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4602" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":356,"completed":185,"skipped":3725,"failed":0}
SSS
------------------------------
[sig-network] EndpointSlice 
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:19:50.924: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/discovery.k8s.io
STEP: getting /apis/discovery.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
May 27 06:19:51.023: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
May 27 06:19:51.030: INFO: starting watch
STEP: patching
STEP: updating
May 27 06:19:51.065: INFO: waiting for watch events with expected annotations
May 27 06:19:51.065: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
May 27 06:19:51.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-3266" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","total":356,"completed":186,"skipped":3728,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:19:51.153: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-49c1015e-cbce-48f1-b798-d6f568bc3e24
STEP: Creating a pod to test consume secrets
May 27 06:19:51.228: INFO: Waiting up to 5m0s for pod "pod-secrets-328110bf-f3a1-4da4-a5d6-af9bb0a79849" in namespace "secrets-8716" to be "Succeeded or Failed"
May 27 06:19:51.235: INFO: Pod "pod-secrets-328110bf-f3a1-4da4-a5d6-af9bb0a79849": Phase="Pending", Reason="", readiness=false. Elapsed: 6.668475ms
May 27 06:19:53.262: INFO: Pod "pod-secrets-328110bf-f3a1-4da4-a5d6-af9bb0a79849": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033245074s
May 27 06:19:55.306: INFO: Pod "pod-secrets-328110bf-f3a1-4da4-a5d6-af9bb0a79849": Phase="Pending", Reason="", readiness=false. Elapsed: 4.077051465s
May 27 06:19:57.332: INFO: Pod "pod-secrets-328110bf-f3a1-4da4-a5d6-af9bb0a79849": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.103410562s
STEP: Saw pod success
May 27 06:19:57.332: INFO: Pod "pod-secrets-328110bf-f3a1-4da4-a5d6-af9bb0a79849" satisfied condition "Succeeded or Failed"
May 27 06:19:57.343: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-secrets-328110bf-f3a1-4da4-a5d6-af9bb0a79849 container secret-volume-test: <nil>
STEP: delete the pod
May 27 06:19:57.625: INFO: Waiting for pod pod-secrets-328110bf-f3a1-4da4-a5d6-af9bb0a79849 to disappear
May 27 06:19:57.632: INFO: Pod pod-secrets-328110bf-f3a1-4da4-a5d6-af9bb0a79849 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
May 27 06:19:57.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8716" for this suite.

• [SLOW TEST:6.515 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":187,"skipped":3731,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:19:57.668: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:19:57.748: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties
May 27 06:20:05.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 --namespace=crd-publish-openapi-2389 create -f -'
May 27 06:20:07.027: INFO: stderr: ""
May 27 06:20:07.027: INFO: stdout: "e2e-test-crd-publish-openapi-8217-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May 27 06:20:07.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 --namespace=crd-publish-openapi-2389 delete e2e-test-crd-publish-openapi-8217-crds test-foo'
May 27 06:20:07.175: INFO: stderr: ""
May 27 06:20:07.175: INFO: stdout: "e2e-test-crd-publish-openapi-8217-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
May 27 06:20:07.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 --namespace=crd-publish-openapi-2389 apply -f -'
May 27 06:20:08.653: INFO: stderr: ""
May 27 06:20:08.653: INFO: stdout: "e2e-test-crd-publish-openapi-8217-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May 27 06:20:08.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 --namespace=crd-publish-openapi-2389 delete e2e-test-crd-publish-openapi-8217-crds test-foo'
May 27 06:20:08.827: INFO: stderr: ""
May 27 06:20:08.827: INFO: stdout: "e2e-test-crd-publish-openapi-8217-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values
May 27 06:20:08.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 --namespace=crd-publish-openapi-2389 create -f -'
May 27 06:20:09.123: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
May 27 06:20:09.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 --namespace=crd-publish-openapi-2389 create -f -'
May 27 06:20:09.574: INFO: rc: 1
May 27 06:20:09.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 --namespace=crd-publish-openapi-2389 apply -f -'
May 27 06:20:10.078: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties
May 27 06:20:10.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 --namespace=crd-publish-openapi-2389 create -f -'
May 27 06:20:10.517: INFO: rc: 1
May 27 06:20:10.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 --namespace=crd-publish-openapi-2389 apply -f -'
May 27 06:20:10.916: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
May 27 06:20:10.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 explain e2e-test-crd-publish-openapi-8217-crds'
May 27 06:20:11.198: INFO: stderr: ""
May 27 06:20:11.198: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8217-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
May 27 06:20:11.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 explain e2e-test-crd-publish-openapi-8217-crds.metadata'
May 27 06:20:11.668: INFO: stderr: ""
May 27 06:20:11.668: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8217-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     Deprecated: ClusterName is a legacy field that was always cleared by the\n     system and never used; it will be removed completely in 1.25.\n\n     The name in the go struct is changed to help clients detect accidental use.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
May 27 06:20:11.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 explain e2e-test-crd-publish-openapi-8217-crds.spec'
May 27 06:20:12.133: INFO: stderr: ""
May 27 06:20:12.133: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8217-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
May 27 06:20:12.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 explain e2e-test-crd-publish-openapi-8217-crds.spec.bars'
May 27 06:20:12.724: INFO: stderr: ""
May 27 06:20:12.724: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8217-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
May 27 06:20:12.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-2389 explain e2e-test-crd-publish-openapi-8217-crds.spec.bars2'
May 27 06:20:13.136: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:20:19.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2389" for this suite.

• [SLOW TEST:22.235 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":356,"completed":188,"skipped":3734,"failed":0}
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:20:19.904: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
May 27 06:20:20.021: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May 27 06:20:22.036: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
May 27 06:20:22.065: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
May 27 06:20:24.084: INFO: The status of Pod pod-with-prestop-http-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
May 27 06:20:24.192: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 27 06:20:24.199: INFO: Pod pod-with-prestop-http-hook still exists
May 27 06:20:26.200: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 27 06:20:26.216: INFO: Pod pod-with-prestop-http-hook still exists
May 27 06:20:28.200: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 27 06:20:28.218: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
May 27 06:20:28.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1892" for this suite.

• [SLOW TEST:8.350 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":356,"completed":189,"skipped":3738,"failed":0}
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:20:28.255: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
May 27 06:20:28.319: INFO: Waiting up to 5m0s for pod "downward-api-6a31e012-5665-4603-b909-49c454c73ff4" in namespace "downward-api-564" to be "Succeeded or Failed"
May 27 06:20:28.326: INFO: Pod "downward-api-6a31e012-5665-4603-b909-49c454c73ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.846341ms
May 27 06:20:30.343: INFO: Pod "downward-api-6a31e012-5665-4603-b909-49c454c73ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024270505s
May 27 06:20:32.363: INFO: Pod "downward-api-6a31e012-5665-4603-b909-49c454c73ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043861181s
May 27 06:20:34.386: INFO: Pod "downward-api-6a31e012-5665-4603-b909-49c454c73ff4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.066889018s
STEP: Saw pod success
May 27 06:20:34.386: INFO: Pod "downward-api-6a31e012-5665-4603-b909-49c454c73ff4" satisfied condition "Succeeded or Failed"
May 27 06:20:34.393: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downward-api-6a31e012-5665-4603-b909-49c454c73ff4 container dapi-container: <nil>
STEP: delete the pod
May 27 06:20:34.439: INFO: Waiting for pod downward-api-6a31e012-5665-4603-b909-49c454c73ff4 to disappear
May 27 06:20:34.447: INFO: Pod downward-api-6a31e012-5665-4603-b909-49c454c73ff4 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
May 27 06:20:34.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-564" for this suite.

• [SLOW TEST:6.232 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":356,"completed":190,"skipped":3738,"failed":0}
SSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:20:34.491: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-projected-all-test-volume-b2fcffee-ce56-4d63-86ca-8b2acd2326af
STEP: Creating secret with name secret-projected-all-test-volume-29428a20-05fb-49dd-902d-1c03a995935b
STEP: Creating a pod to test Check all projections for projected volume plugin
May 27 06:20:34.611: INFO: Waiting up to 5m0s for pod "projected-volume-252ad8b1-549d-49dc-908f-e60872980059" in namespace "projected-8387" to be "Succeeded or Failed"
May 27 06:20:34.618: INFO: Pod "projected-volume-252ad8b1-549d-49dc-908f-e60872980059": Phase="Pending", Reason="", readiness=false. Elapsed: 6.002822ms
May 27 06:20:36.684: INFO: Pod "projected-volume-252ad8b1-549d-49dc-908f-e60872980059": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072460093s
May 27 06:20:38.703: INFO: Pod "projected-volume-252ad8b1-549d-49dc-908f-e60872980059": Phase="Pending", Reason="", readiness=false. Elapsed: 4.091597074s
May 27 06:20:40.714: INFO: Pod "projected-volume-252ad8b1-549d-49dc-908f-e60872980059": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.10241275s
STEP: Saw pod success
May 27 06:20:40.714: INFO: Pod "projected-volume-252ad8b1-549d-49dc-908f-e60872980059" satisfied condition "Succeeded or Failed"
May 27 06:20:40.720: INFO: Trying to get logs from node bohc9zohd7ee-3 pod projected-volume-252ad8b1-549d-49dc-908f-e60872980059 container projected-all-volume-test: <nil>
STEP: delete the pod
May 27 06:20:40.761: INFO: Waiting for pod projected-volume-252ad8b1-549d-49dc-908f-e60872980059 to disappear
May 27 06:20:40.770: INFO: Pod projected-volume-252ad8b1-549d-49dc-908f-e60872980059 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:188
May 27 06:20:40.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8387" for this suite.

• [SLOW TEST:6.306 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":356,"completed":191,"skipped":3741,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:20:40.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
May 27 06:20:41.371: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
May 27 06:20:43.400: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 20, 41, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 20, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 20, 41, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 20, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-677b6dd845\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 06:20:46.459: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:20:46.475: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:20:49.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3389" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

• [SLOW TEST:9.353 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":356,"completed":192,"skipped":3762,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:20:50.151: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
May 27 06:20:50.261: INFO: PodSpec: initContainers in spec.initContainers
May 27 06:21:34.061: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-f05658d5-4e54-4f64-989f-14f39765e456", GenerateName:"", Namespace:"init-container-714", SelfLink:"", UID:"97efd025-2904-4da5-bde5-0e4d0917d11a", ResourceVersion:"26388", Generation:0, CreationTimestamp:time.Date(2022, time.May, 27, 6, 20, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"261301919"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.May, 27, 6, 20, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00429b1d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.May, 27, 6, 20, 51, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00429b200), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-pzrxl", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0087747c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pzrxl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pzrxl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.7", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pzrxl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0067f85e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"bohc9zohd7ee-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002c48070), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0067f8670)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0067f8690)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0067f8698), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0067f869c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc006132810), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.May, 27, 6, 20, 50, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.May, 27, 6, 20, 50, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.May, 27, 6, 20, 50, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.May, 27, 6, 20, 50, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.16", PodIP:"10.233.65.133", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.65.133"}}, StartTime:time.Date(2022, time.May, 27, 6, 20, 50, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002c48150)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002c481c0)}, Ready:false, RestartCount:3, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"k8s.gcr.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"cri-o://3d1f4baa35ec5a08c76220fb7108b482968d550e17c4d4d9483f379cd58027fe", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc008774840), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc008774820), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.7", ImageID:"", ContainerID:"", Started:(*bool)(0xc0067f8714)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
May 27 06:21:34.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-714" for this suite.

• [SLOW TEST:43.951 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":356,"completed":193,"skipped":3778,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:21:34.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
May 27 06:21:34.207: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 27 06:21:34.232: INFO: Waiting for terminating namespaces to be deleted...
May 27 06:21:34.247: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-1 before test
May 27 06:21:34.266: INFO: echo-other-node-6cd597cddc-nc274 from cilium-test started at 2022-05-27 05:12:14 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.266: INFO: 	Container echo-other-node ready: true, restart count 0
May 27 06:21:34.266: INFO: cilium-5bg94 from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.266: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:21:34.266: INFO: cilium-node-init-b2j7g from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.266: INFO: 	Container node-init ready: true, restart count 0
May 27 06:21:34.266: INFO: coredns-6d4b75cb6d-rlht9 from kube-system started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.266: INFO: 	Container coredns ready: true, restart count 0
May 27 06:21:34.266: INFO: kube-addon-manager-bohc9zohd7ee-1 from kube-system started at 2022-05-27 05:09:45 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.266: INFO: 	Container kube-addon-manager ready: true, restart count 0
May 27 06:21:34.266: INFO: kube-apiserver-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:56:59 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.266: INFO: 	Container kube-apiserver ready: true, restart count 0
May 27 06:21:34.266: INFO: kube-controller-manager-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:57:00 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.267: INFO: 	Container kube-controller-manager ready: true, restart count 0
May 27 06:21:34.267: INFO: kube-proxy-lfbdj from kube-system started at 2022-05-27 04:57:12 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.267: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:21:34.267: INFO: kube-scheduler-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:57:00 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.267: INFO: 	Container kube-scheduler ready: true, restart count 0
May 27 06:21:34.267: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-wh4kx from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:21:34.267: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:21:34.267: INFO: 	Container systemd-logs ready: true, restart count 0
May 27 06:21:34.267: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-2 before test
May 27 06:21:34.286: INFO: client-7df6cfbf7b-zqjl4 from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.286: INFO: 	Container client ready: true, restart count 0
May 27 06:21:34.286: INFO: client2-547996d7d8-lrnhm from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.286: INFO: 	Container client2 ready: true, restart count 0
May 27 06:21:34.286: INFO: echo-same-node-6f4976ddbd-2v7fp from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.286: INFO: 	Container echo-same-node ready: true, restart count 0
May 27 06:21:34.286: INFO: cilium-fcn4c from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.286: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:21:34.286: INFO: cilium-node-init-stvc7 from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.286: INFO: 	Container node-init ready: true, restart count 0
May 27 06:21:34.286: INFO: coredns-6d4b75cb6d-fhr75 from kube-system started at 2022-05-27 05:11:02 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.286: INFO: 	Container coredns ready: true, restart count 0
May 27 06:21:34.287: INFO: kube-addon-manager-bohc9zohd7ee-2 from kube-system started at 2022-05-27 05:09:45 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.287: INFO: 	Container kube-addon-manager ready: true, restart count 0
May 27 06:21:34.287: INFO: kube-apiserver-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.287: INFO: 	Container kube-apiserver ready: true, restart count 0
May 27 06:21:34.287: INFO: kube-controller-manager-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.287: INFO: 	Container kube-controller-manager ready: true, restart count 0
May 27 06:21:34.287: INFO: kube-proxy-grpx7 from kube-system started at 2022-05-27 04:57:48 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.287: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:21:34.287: INFO: kube-scheduler-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.287: INFO: 	Container kube-scheduler ready: true, restart count 0
May 27 06:21:34.287: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-vhrdj from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:21:34.287: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:21:34.287: INFO: 	Container systemd-logs ready: true, restart count 0
May 27 06:21:34.287: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-3 before test
May 27 06:21:34.312: INFO: pod-init-f05658d5-4e54-4f64-989f-14f39765e456 from init-container-714 started at 2022-05-27 06:20:50 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.312: INFO: 	Container run1 ready: false, restart count 0
May 27 06:21:34.312: INFO: cilium-cdd2v from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.312: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:21:34.312: INFO: cilium-node-init-qd8vn from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.312: INFO: 	Container node-init ready: true, restart count 0
May 27 06:21:34.312: INFO: cilium-operator-75876f779d-pzjgf from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.312: INFO: 	Container cilium-operator ready: true, restart count 0
May 27 06:21:34.312: INFO: kube-proxy-sg7pn from kube-system started at 2022-05-27 04:58:22 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.312: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:21:34.312: INFO: sonobuoy from sonobuoy started at 2022-05-27 05:16:01 +0000 UTC (1 container statuses recorded)
May 27 06:21:34.312: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 27 06:21:34.312: INFO: sonobuoy-e2e-job-117750ad95a24373 from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:21:34.312: INFO: 	Container e2e ready: true, restart count 0
May 27 06:21:34.312: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:21:34.312: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-2m5xp from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:21:34.312: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:21:34.312: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16f2e1fe084e975e], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
May 27 06:21:35.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2270" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":356,"completed":194,"skipped":3785,"failed":0}
SSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:21:35.418: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's args
May 27 06:21:35.501: INFO: Waiting up to 5m0s for pod "var-expansion-82b21e9a-5682-4618-8da7-3a6f849cb3f9" in namespace "var-expansion-3715" to be "Succeeded or Failed"
May 27 06:21:35.509: INFO: Pod "var-expansion-82b21e9a-5682-4618-8da7-3a6f849cb3f9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.276613ms
May 27 06:21:37.535: INFO: Pod "var-expansion-82b21e9a-5682-4618-8da7-3a6f849cb3f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034419629s
May 27 06:21:39.552: INFO: Pod "var-expansion-82b21e9a-5682-4618-8da7-3a6f849cb3f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051408122s
May 27 06:21:41.562: INFO: Pod "var-expansion-82b21e9a-5682-4618-8da7-3a6f849cb3f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.060856262s
STEP: Saw pod success
May 27 06:21:41.562: INFO: Pod "var-expansion-82b21e9a-5682-4618-8da7-3a6f849cb3f9" satisfied condition "Succeeded or Failed"
May 27 06:21:41.570: INFO: Trying to get logs from node bohc9zohd7ee-3 pod var-expansion-82b21e9a-5682-4618-8da7-3a6f849cb3f9 container dapi-container: <nil>
STEP: delete the pod
May 27 06:21:41.609: INFO: Waiting for pod var-expansion-82b21e9a-5682-4618-8da7-3a6f849cb3f9 to disappear
May 27 06:21:41.616: INFO: Pod var-expansion-82b21e9a-5682-4618-8da7-3a6f849cb3f9 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
May 27 06:21:41.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3715" for this suite.

• [SLOW TEST:6.224 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":356,"completed":195,"skipped":3789,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:21:41.655: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Starting the proxy
May 27 06:21:41.706: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-4689 proxy --unix-socket=/tmp/kubectl-proxy-unix1336497047/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:21:41.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4689" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":356,"completed":196,"skipped":3842,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:21:41.882: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:21:41.953: INFO: The status of Pod busybox-scheduling-6d3f39d5-1072-4faa-bda2-5925b7a11749 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:21:43.966: INFO: The status of Pod busybox-scheduling-6d3f39d5-1072-4faa-bda2-5925b7a11749 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
May 27 06:21:43.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4069" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":356,"completed":197,"skipped":3851,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:21:44.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:58
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:21:44.168: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:21:46.180: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Running (Ready = false)
May 27 06:21:48.216: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Running (Ready = false)
May 27 06:21:50.182: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Running (Ready = false)
May 27 06:21:52.205: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Running (Ready = false)
May 27 06:21:54.181: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Running (Ready = false)
May 27 06:21:56.217: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Running (Ready = false)
May 27 06:21:58.185: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Running (Ready = false)
May 27 06:22:00.185: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Running (Ready = false)
May 27 06:22:02.180: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Running (Ready = false)
May 27 06:22:04.207: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Running (Ready = false)
May 27 06:22:06.181: INFO: The status of Pod test-webserver-dd6554a7-890b-4e40-a2f4-ee424ce0c448 is Running (Ready = true)
May 27 06:22:06.186: INFO: Container started at 2022-05-27 06:21:45 +0000 UTC, pod became ready at 2022-05-27 06:22:04 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
May 27 06:22:06.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8399" for this suite.

• [SLOW TEST:22.205 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":356,"completed":198,"skipped":3878,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:22:06.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-518.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-518.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-518.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-518.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 27 06:22:10.367: INFO: DNS probes using dns-518/dns-test-3435a1c7-7639-4652-8ff4-0b59658e0abf succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
May 27 06:22:10.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-518" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","total":356,"completed":199,"skipped":3902,"failed":0}
S
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:22:10.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
May 27 06:22:10.506: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
May 27 06:22:16.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8784" for this suite.

• [SLOW TEST:6.129 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":356,"completed":200,"skipped":3903,"failed":0}
SSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:22:16.552: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:22:18.658: INFO: Deleting pod "var-expansion-2ff990d9-9a28-477c-9fc8-d9d4ad9cb274" in namespace "var-expansion-1943"
May 27 06:22:18.679: INFO: Wait up to 5m0s for pod "var-expansion-2ff990d9-9a28-477c-9fc8-d9d4ad9cb274" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
May 27 06:22:20.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1943" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","total":356,"completed":201,"skipped":3910,"failed":0}
SSS
------------------------------
[sig-architecture] Conformance Tests 
  should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:22:20.731: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename conformance-tests
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
STEP: Getting node addresses
May 27 06:22:20.786: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:188
May 27 06:22:20.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-6865" for this suite.
•{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","total":356,"completed":202,"skipped":3913,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:22:20.822: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:22:20.870: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Creating first CR 
May 27 06:22:23.696: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-27T06:22:23Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-27T06:22:23Z]] name:name1 resourceVersion:26721 uid:ab542e60-89b7-4cd8-9186-d50980580e4f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
May 27 06:22:33.735: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-27T06:22:33Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-27T06:22:33Z]] name:name2 resourceVersion:26754 uid:ea6c5935-f0bd-4df5-b92c-8aba225715d9] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
May 27 06:22:43.759: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-27T06:22:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-27T06:22:43Z]] name:name1 resourceVersion:26774 uid:ab542e60-89b7-4cd8-9186-d50980580e4f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
May 27 06:22:53.780: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-27T06:22:33Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-27T06:22:53Z]] name:name2 resourceVersion:26795 uid:ea6c5935-f0bd-4df5-b92c-8aba225715d9] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
May 27 06:23:03.801: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-27T06:22:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-27T06:22:43Z]] name:name1 resourceVersion:26816 uid:ab542e60-89b7-4cd8-9186-d50980580e4f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
May 27 06:23:13.827: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-05-27T06:22:33Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-05-27T06:22:53Z]] name:name2 resourceVersion:26837 uid:ea6c5935-f0bd-4df5-b92c-8aba225715d9] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:23:24.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-2640" for this suite.

• [SLOW TEST:63.607 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":356,"completed":203,"skipped":3943,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:23:24.444: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ReplaceConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring the job is replaced with a new one
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
May 27 06:25:00.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1557" for this suite.

• [SLOW TEST:96.240 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","total":356,"completed":204,"skipped":3972,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:25:00.692: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 06:25:02.002: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 27 06:25:04.033: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 25, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 25, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 25, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 25, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 06:25:07.114: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:25:07.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1641" for this suite.
STEP: Destroying namespace "webhook-1641-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.685 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":356,"completed":205,"skipped":3996,"failed":0}
SSSSSS
------------------------------
[sig-node] RuntimeClass 
   should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:25:07.380: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/node.k8s.io
STEP: getting /apis/node.k8s.io/v1
STEP: creating
STEP: watching
May 27 06:25:07.490: INFO: starting watch
STEP: getting
STEP: listing
STEP: patching
STEP: updating
May 27 06:25:07.556: INFO: waiting for watch events with expected annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
May 27 06:25:07.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3508" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","total":356,"completed":206,"skipped":4002,"failed":0}
SSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:25:07.628: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:25:07.672: INFO: Creating pod...
May 27 06:25:11.710: INFO: Creating service...
May 27 06:25:11.754: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/pods/agnhost/proxy?method=DELETE
May 27 06:25:11.786: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
May 27 06:25:11.786: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/pods/agnhost/proxy?method=OPTIONS
May 27 06:25:11.796: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
May 27 06:25:11.796: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/pods/agnhost/proxy?method=PATCH
May 27 06:25:11.808: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
May 27 06:25:11.808: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/pods/agnhost/proxy?method=POST
May 27 06:25:11.816: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
May 27 06:25:11.816: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/pods/agnhost/proxy?method=PUT
May 27 06:25:11.825: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
May 27 06:25:11.825: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/services/e2e-proxy-test-service/proxy?method=DELETE
May 27 06:25:11.845: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
May 27 06:25:11.845: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/services/e2e-proxy-test-service/proxy?method=OPTIONS
May 27 06:25:11.868: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
May 27 06:25:11.868: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/services/e2e-proxy-test-service/proxy?method=PATCH
May 27 06:25:11.884: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
May 27 06:25:11.884: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/services/e2e-proxy-test-service/proxy?method=POST
May 27 06:25:11.922: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
May 27 06:25:11.922: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/services/e2e-proxy-test-service/proxy?method=PUT
May 27 06:25:11.933: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
May 27 06:25:11.933: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/pods/agnhost/proxy?method=GET
May 27 06:25:11.940: INFO: http.Client request:GET StatusCode:301
May 27 06:25:11.940: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/services/e2e-proxy-test-service/proxy?method=GET
May 27 06:25:11.949: INFO: http.Client request:GET StatusCode:301
May 27 06:25:11.949: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/pods/agnhost/proxy?method=HEAD
May 27 06:25:11.956: INFO: http.Client request:HEAD StatusCode:301
May 27 06:25:11.957: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-5606/services/e2e-proxy-test-service/proxy?method=HEAD
May 27 06:25:11.964: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:188
May 27 06:25:11.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5606" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","total":356,"completed":207,"skipped":4006,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:25:11.986: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1574
[It] should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
May 27 06:25:12.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-8461 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
May 27 06:25:12.326: INFO: stderr: ""
May 27 06:25:12.326: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
May 27 06:25:17.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-8461 get pod e2e-test-httpd-pod -o json'
May 27 06:25:17.664: INFO: stderr: ""
May 27 06:25:17.664: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-05-27T06:25:12Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8461\",\n        \"resourceVersion\": \"27257\",\n        \"uid\": \"1f3039f3-d5d0-4063-b5fa-53a78ea2f2dd\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-9s4q4\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"bohc9zohd7ee-3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-9s4q4\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-05-27T06:25:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-05-27T06:25:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-05-27T06:25:14Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-05-27T06:25:12Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://ebde0bc6bdbd59860bc4c1f898371935a17e648025d6928baa05a72ae2d4c5ff\",\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-05-27T06:25:13Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.121.16\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.65.162\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.65.162\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-05-27T06:25:12Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 27 06:25:17.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-8461 replace -f -'
May 27 06:25:18.413: INFO: stderr: ""
May 27 06:25:18.413: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/busybox:1.29-2
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1578
May 27 06:25:18.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-8461 delete pods e2e-test-httpd-pod'
May 27 06:25:20.620: INFO: stderr: ""
May 27 06:25:20.620: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:25:20.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8461" for this suite.

• [SLOW TEST:8.657 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1571
    should update a single-container pod's image  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":356,"completed":208,"skipped":4026,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:25:20.645: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a job [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-5159, will wait for the garbage collector to delete the pods
May 27 06:25:24.802: INFO: Deleting Job.batch foo took: 15.798606ms
May 27 06:25:24.902: INFO: Terminating Job.batch foo pods took: 100.481814ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
May 27 06:25:56.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5159" for this suite.

• [SLOW TEST:35.889 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":356,"completed":209,"skipped":4044,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:25:56.546: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-7e6d6f68-f67c-4d7f-875a-fcc3280125b8
STEP: Creating a pod to test consume secrets
May 27 06:25:56.619: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2f9f3598-d049-42c9-8db7-bdcb34546f0f" in namespace "projected-1270" to be "Succeeded or Failed"
May 27 06:25:56.625: INFO: Pod "pod-projected-secrets-2f9f3598-d049-42c9-8db7-bdcb34546f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.927465ms
May 27 06:25:58.645: INFO: Pod "pod-projected-secrets-2f9f3598-d049-42c9-8db7-bdcb34546f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025714969s
May 27 06:26:00.659: INFO: Pod "pod-projected-secrets-2f9f3598-d049-42c9-8db7-bdcb34546f0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039939648s
STEP: Saw pod success
May 27 06:26:00.660: INFO: Pod "pod-projected-secrets-2f9f3598-d049-42c9-8db7-bdcb34546f0f" satisfied condition "Succeeded or Failed"
May 27 06:26:00.665: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-secrets-2f9f3598-d049-42c9-8db7-bdcb34546f0f container projected-secret-volume-test: <nil>
STEP: delete the pod
May 27 06:26:00.713: INFO: Waiting for pod pod-projected-secrets-2f9f3598-d049-42c9-8db7-bdcb34546f0f to disappear
May 27 06:26:00.719: INFO: Pod pod-projected-secrets-2f9f3598-d049-42c9-8db7-bdcb34546f0f no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
May 27 06:26:00.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1270" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":210,"skipped":4106,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:26:00.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 06:26:00.800: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1cde544f-1087-4f9d-9c8f-1365320b2890" in namespace "downward-api-4968" to be "Succeeded or Failed"
May 27 06:26:00.807: INFO: Pod "downwardapi-volume-1cde544f-1087-4f9d-9c8f-1365320b2890": Phase="Pending", Reason="", readiness=false. Elapsed: 6.184292ms
May 27 06:26:02.820: INFO: Pod "downwardapi-volume-1cde544f-1087-4f9d-9c8f-1365320b2890": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019669505s
May 27 06:26:04.831: INFO: Pod "downwardapi-volume-1cde544f-1087-4f9d-9c8f-1365320b2890": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030309012s
May 27 06:26:06.845: INFO: Pod "downwardapi-volume-1cde544f-1087-4f9d-9c8f-1365320b2890": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044819431s
STEP: Saw pod success
May 27 06:26:06.846: INFO: Pod "downwardapi-volume-1cde544f-1087-4f9d-9c8f-1365320b2890" satisfied condition "Succeeded or Failed"
May 27 06:26:06.850: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-1cde544f-1087-4f9d-9c8f-1365320b2890 container client-container: <nil>
STEP: delete the pod
May 27 06:26:06.883: INFO: Waiting for pod downwardapi-volume-1cde544f-1087-4f9d-9c8f-1365320b2890 to disappear
May 27 06:26:06.888: INFO: Pod downwardapi-volume-1cde544f-1087-4f9d-9c8f-1365320b2890 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
May 27 06:26:06.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4968" for this suite.

• [SLOW TEST:6.168 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":211,"skipped":4129,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:26:06.908: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 27 06:26:06.968: INFO: Waiting up to 5m0s for pod "pod-f28c6370-78e1-4c89-aeda-8e933cd88664" in namespace "emptydir-4759" to be "Succeeded or Failed"
May 27 06:26:06.976: INFO: Pod "pod-f28c6370-78e1-4c89-aeda-8e933cd88664": Phase="Pending", Reason="", readiness=false. Elapsed: 7.34542ms
May 27 06:26:08.992: INFO: Pod "pod-f28c6370-78e1-4c89-aeda-8e933cd88664": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023004386s
May 27 06:26:11.004: INFO: Pod "pod-f28c6370-78e1-4c89-aeda-8e933cd88664": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035154405s
STEP: Saw pod success
May 27 06:26:11.004: INFO: Pod "pod-f28c6370-78e1-4c89-aeda-8e933cd88664" satisfied condition "Succeeded or Failed"
May 27 06:26:11.008: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-f28c6370-78e1-4c89-aeda-8e933cd88664 container test-container: <nil>
STEP: delete the pod
May 27 06:26:11.038: INFO: Waiting for pod pod-f28c6370-78e1-4c89-aeda-8e933cd88664 to disappear
May 27 06:26:11.047: INFO: Pod pod-f28c6370-78e1-4c89-aeda-8e933cd88664 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 06:26:11.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4759" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":212,"skipped":4200,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:26:11.076: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
May 27 06:26:11.127: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
May 27 06:26:11.141: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
May 27 06:26:11.141: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
May 27 06:26:11.167: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
May 27 06:26:11.167: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
May 27 06:26:11.181: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
May 27 06:26:11.181: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
May 27 06:26:18.288: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:188
May 27 06:26:18.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-479" for this suite.

• [SLOW TEST:7.267 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":356,"completed":213,"skipped":4225,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:26:18.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-xnfn
STEP: Creating a pod to test atomic-volume-subpath
May 27 06:26:18.461: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xnfn" in namespace "subpath-7923" to be "Succeeded or Failed"
May 27 06:26:18.483: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Pending", Reason="", readiness=false. Elapsed: 21.940552ms
May 27 06:26:20.497: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Running", Reason="", readiness=true. Elapsed: 2.03642196s
May 27 06:26:22.517: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Running", Reason="", readiness=true. Elapsed: 4.056212354s
May 27 06:26:24.530: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Running", Reason="", readiness=true. Elapsed: 6.069290508s
May 27 06:26:26.544: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Running", Reason="", readiness=true. Elapsed: 8.083196171s
May 27 06:26:28.558: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Running", Reason="", readiness=true. Elapsed: 10.09756254s
May 27 06:26:30.571: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Running", Reason="", readiness=true. Elapsed: 12.109930184s
May 27 06:26:32.587: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Running", Reason="", readiness=true. Elapsed: 14.125966671s
May 27 06:26:34.602: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Running", Reason="", readiness=true. Elapsed: 16.141221911s
May 27 06:26:36.618: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Running", Reason="", readiness=true. Elapsed: 18.157772811s
May 27 06:26:38.632: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Running", Reason="", readiness=true. Elapsed: 20.171113825s
May 27 06:26:40.644: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Running", Reason="", readiness=false. Elapsed: 22.183547544s
May 27 06:26:42.658: INFO: Pod "pod-subpath-test-configmap-xnfn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.196945886s
STEP: Saw pod success
May 27 06:26:42.658: INFO: Pod "pod-subpath-test-configmap-xnfn" satisfied condition "Succeeded or Failed"
May 27 06:26:42.668: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-subpath-test-configmap-xnfn container test-container-subpath-configmap-xnfn: <nil>
STEP: delete the pod
May 27 06:26:42.720: INFO: Waiting for pod pod-subpath-test-configmap-xnfn to disappear
May 27 06:26:42.726: INFO: Pod pod-subpath-test-configmap-xnfn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xnfn
May 27 06:26:42.727: INFO: Deleting pod "pod-subpath-test-configmap-xnfn" in namespace "subpath-7923"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
May 27 06:26:42.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7923" for this suite.

• [SLOW TEST:24.420 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","total":356,"completed":214,"skipped":4260,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:26:42.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
May 27 06:26:46.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5473" for this suite.
•{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":356,"completed":215,"skipped":4273,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:26:46.907: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
May 27 06:26:46.950: INFO: Waiting up to 1m0s for all nodes to be ready
May 27 06:27:47.004: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:27:47.014: INFO: Starting informer...
STEP: Starting pod...
May 27 06:27:47.244: INFO: Pod is running on bohc9zohd7ee-3. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
May 27 06:27:47.293: INFO: Pod wasn't evicted. Proceeding
May 27 06:27:47.294: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
May 27 06:29:02.318: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:188
May 27 06:29:02.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-1221" for this suite.

• [SLOW TEST:135.456 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":356,"completed":216,"skipped":4284,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:29:02.366: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 06:29:03.681: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 27 06:29:05.716: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 29, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 29, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 29, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 06:29:08.773: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:29:09.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-850" for this suite.
STEP: Destroying namespace "webhook-850-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.848 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":356,"completed":217,"skipped":4288,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:29:09.218: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 06:29:11.172: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 06:29:14.220: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:29:14.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1650" for this suite.
STEP: Destroying namespace "webhook-1650-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:5.903 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":356,"completed":218,"skipped":4318,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:29:15.124: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 27 06:29:15.258: INFO: Pod name pod-release: Found 0 pods out of 1
May 27 06:29:20.278: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
May 27 06:29:21.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3824" for this suite.

• [SLOW TEST:6.221 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":356,"completed":219,"skipped":4326,"failed":0}
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:29:21.347: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1540
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
May 27 06:29:21.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-4129 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2'
May 27 06:29:21.541: INFO: stderr: ""
May 27 06:29:21.541: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1544
May 27 06:29:21.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-4129 delete pods e2e-test-httpd-pod'
May 27 06:29:25.152: INFO: stderr: ""
May 27 06:29:25.152: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:29:25.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4129" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":356,"completed":220,"skipped":4326,"failed":0}
SSS
------------------------------
[sig-node] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:29:25.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:29:25.245: INFO: The status of Pod server-envvars-539e5777-1725-4a39-85f3-eb1d5fa8a773 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:29:27.266: INFO: The status of Pod server-envvars-539e5777-1725-4a39-85f3-eb1d5fa8a773 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:29:29.263: INFO: The status of Pod server-envvars-539e5777-1725-4a39-85f3-eb1d5fa8a773 is Running (Ready = true)
May 27 06:29:29.307: INFO: Waiting up to 5m0s for pod "client-envvars-86cf1768-eed0-4d01-883e-5e82ea6c32aa" in namespace "pods-7362" to be "Succeeded or Failed"
May 27 06:29:29.314: INFO: Pod "client-envvars-86cf1768-eed0-4d01-883e-5e82ea6c32aa": Phase="Pending", Reason="", readiness=false. Elapsed: 6.977207ms
May 27 06:29:31.326: INFO: Pod "client-envvars-86cf1768-eed0-4d01-883e-5e82ea6c32aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018851325s
May 27 06:29:33.340: INFO: Pod "client-envvars-86cf1768-eed0-4d01-883e-5e82ea6c32aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032231786s
STEP: Saw pod success
May 27 06:29:33.340: INFO: Pod "client-envvars-86cf1768-eed0-4d01-883e-5e82ea6c32aa" satisfied condition "Succeeded or Failed"
May 27 06:29:33.345: INFO: Trying to get logs from node bohc9zohd7ee-3 pod client-envvars-86cf1768-eed0-4d01-883e-5e82ea6c32aa container env3cont: <nil>
STEP: delete the pod
May 27 06:29:33.567: INFO: Waiting for pod client-envvars-86cf1768-eed0-4d01-883e-5e82ea6c32aa to disappear
May 27 06:29:33.575: INFO: Pod client-envvars-86cf1768-eed0-4d01-883e-5e82ea6c32aa no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
May 27 06:29:33.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7362" for this suite.

• [SLOW TEST:8.417 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":356,"completed":221,"skipped":4329,"failed":0}
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:29:33.601: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
May 27 06:29:33.655: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 27 06:29:33.674: INFO: Waiting for terminating namespaces to be deleted...
May 27 06:29:33.680: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-1 before test
May 27 06:29:33.700: INFO: echo-other-node-6cd597cddc-nc274 from cilium-test started at 2022-05-27 05:12:14 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.700: INFO: 	Container echo-other-node ready: true, restart count 0
May 27 06:29:33.700: INFO: cilium-5bg94 from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.700: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:29:33.700: INFO: cilium-node-init-b2j7g from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.700: INFO: 	Container node-init ready: true, restart count 0
May 27 06:29:33.700: INFO: coredns-6d4b75cb6d-rlht9 from kube-system started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.700: INFO: 	Container coredns ready: true, restart count 0
May 27 06:29:33.700: INFO: kube-addon-manager-bohc9zohd7ee-1 from kube-system started at 2022-05-27 05:09:45 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.700: INFO: 	Container kube-addon-manager ready: true, restart count 0
May 27 06:29:33.700: INFO: kube-apiserver-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:56:59 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.700: INFO: 	Container kube-apiserver ready: true, restart count 0
May 27 06:29:33.700: INFO: kube-controller-manager-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:57:00 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.700: INFO: 	Container kube-controller-manager ready: true, restart count 0
May 27 06:29:33.700: INFO: kube-proxy-lfbdj from kube-system started at 2022-05-27 04:57:12 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.700: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:29:33.700: INFO: kube-scheduler-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:57:00 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.700: INFO: 	Container kube-scheduler ready: true, restart count 0
May 27 06:29:33.700: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-wh4kx from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:29:33.700: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:29:33.700: INFO: 	Container systemd-logs ready: true, restart count 0
May 27 06:29:33.700: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-2 before test
May 27 06:29:33.714: INFO: client-7df6cfbf7b-zqjl4 from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container client ready: true, restart count 0
May 27 06:29:33.714: INFO: client2-547996d7d8-lrnhm from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container client2 ready: true, restart count 0
May 27 06:29:33.714: INFO: echo-same-node-6f4976ddbd-2v7fp from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container echo-same-node ready: true, restart count 0
May 27 06:29:33.714: INFO: cilium-fcn4c from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:29:33.714: INFO: cilium-node-init-stvc7 from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container node-init ready: true, restart count 0
May 27 06:29:33.714: INFO: coredns-6d4b75cb6d-fhr75 from kube-system started at 2022-05-27 05:11:02 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container coredns ready: true, restart count 0
May 27 06:29:33.714: INFO: kube-addon-manager-bohc9zohd7ee-2 from kube-system started at 2022-05-27 05:09:45 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container kube-addon-manager ready: true, restart count 0
May 27 06:29:33.714: INFO: kube-apiserver-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container kube-apiserver ready: true, restart count 0
May 27 06:29:33.714: INFO: kube-controller-manager-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container kube-controller-manager ready: true, restart count 0
May 27 06:29:33.714: INFO: kube-proxy-grpx7 from kube-system started at 2022-05-27 04:57:48 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:29:33.714: INFO: kube-scheduler-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container kube-scheduler ready: true, restart count 0
May 27 06:29:33.714: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-vhrdj from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:29:33.714: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:29:33.714: INFO: 	Container systemd-logs ready: true, restart count 0
May 27 06:29:33.714: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-3 before test
May 27 06:29:33.727: INFO: cilium-cdd2v from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.728: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:29:33.728: INFO: cilium-node-init-qd8vn from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.728: INFO: 	Container node-init ready: true, restart count 0
May 27 06:29:33.728: INFO: cilium-operator-75876f779d-pzjgf from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.728: INFO: 	Container cilium-operator ready: true, restart count 0
May 27 06:29:33.728: INFO: kube-proxy-sg7pn from kube-system started at 2022-05-27 04:58:22 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.728: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:29:33.728: INFO: server-envvars-539e5777-1725-4a39-85f3-eb1d5fa8a773 from pods-7362 started at 2022-05-27 06:29:25 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.728: INFO: 	Container srv ready: true, restart count 0
May 27 06:29:33.728: INFO: sonobuoy from sonobuoy started at 2022-05-27 05:16:01 +0000 UTC (1 container statuses recorded)
May 27 06:29:33.728: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 27 06:29:33.728: INFO: sonobuoy-e2e-job-117750ad95a24373 from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:29:33.728: INFO: 	Container e2e ready: true, restart count 0
May 27 06:29:33.728: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:29:33.728: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-2m5xp from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:29:33.728: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:29:33.728: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d96f414e-35d5-4659-955f-4f5af5cf5465 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.16 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-d96f414e-35d5-4659-955f-4f5af5cf5465 off the node bohc9zohd7ee-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d96f414e-35d5-4659-955f-4f5af5cf5465
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
May 27 06:34:38.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2173" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83

• [SLOW TEST:304.436 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":356,"completed":222,"skipped":4337,"failed":0}
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:34:38.037: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-rw4nf in namespace proxy-6589
I0527 06:34:38.261385      15 runners.go:193] Created replication controller with name: proxy-service-rw4nf, namespace: proxy-6589, replica count: 1
I0527 06:34:39.312892      15 runners.go:193] proxy-service-rw4nf Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0527 06:34:40.313672      15 runners.go:193] proxy-service-rw4nf Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 27 06:34:40.339: INFO: setup took 2.131281786s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 27 06:34:40.384: INFO: (0) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 44.027449ms)
May 27 06:34:40.384: INFO: (0) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 43.600983ms)
May 27 06:34:40.384: INFO: (0) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 44.340713ms)
May 27 06:34:40.391: INFO: (0) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 50.676879ms)
May 27 06:34:40.392: INFO: (0) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 51.006457ms)
May 27 06:34:40.392: INFO: (0) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 52.502336ms)
May 27 06:34:40.392: INFO: (0) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 52.132896ms)
May 27 06:34:40.393: INFO: (0) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 51.541361ms)
May 27 06:34:40.393: INFO: (0) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 51.675023ms)
May 27 06:34:40.394: INFO: (0) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 53.919318ms)
May 27 06:34:40.402: INFO: (0) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 62.373694ms)
May 27 06:34:40.406: INFO: (0) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 64.495582ms)
May 27 06:34:40.406: INFO: (0) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 64.654444ms)
May 27 06:34:40.407: INFO: (0) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 66.239966ms)
May 27 06:34:40.421: INFO: (0) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 81.023559ms)
May 27 06:34:40.421: INFO: (0) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 80.308931ms)
May 27 06:34:40.440: INFO: (1) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 18.016285ms)
May 27 06:34:40.441: INFO: (1) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 18.920507ms)
May 27 06:34:40.440: INFO: (1) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 17.189898ms)
May 27 06:34:40.441: INFO: (1) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 18.545558ms)
May 27 06:34:40.443: INFO: (1) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 20.027794ms)
May 27 06:34:40.443: INFO: (1) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 21.238207ms)
May 27 06:34:40.451: INFO: (1) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 28.576433ms)
May 27 06:34:40.454: INFO: (1) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 31.621508ms)
May 27 06:34:40.454: INFO: (1) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 31.763355ms)
May 27 06:34:40.454: INFO: (1) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 32.592848ms)
May 27 06:34:40.454: INFO: (1) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 31.953312ms)
May 27 06:34:40.455: INFO: (1) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 32.490728ms)
May 27 06:34:40.467: INFO: (1) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 44.790356ms)
May 27 06:34:40.476: INFO: (1) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 54.112256ms)
May 27 06:34:40.477: INFO: (1) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 54.193432ms)
May 27 06:34:40.477: INFO: (1) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 54.277098ms)
May 27 06:34:40.489: INFO: (2) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 11.422031ms)
May 27 06:34:40.492: INFO: (2) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 14.643746ms)
May 27 06:34:40.495: INFO: (2) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 17.541675ms)
May 27 06:34:40.495: INFO: (2) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 14.914744ms)
May 27 06:34:40.495: INFO: (2) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 17.350323ms)
May 27 06:34:40.508: INFO: (2) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 26.856571ms)
May 27 06:34:40.508: INFO: (2) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 27.636748ms)
May 27 06:34:40.508: INFO: (2) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 28.386673ms)
May 27 06:34:40.509: INFO: (2) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 26.914366ms)
May 27 06:34:40.509: INFO: (2) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 26.408791ms)
May 27 06:34:40.513: INFO: (2) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 31.992024ms)
May 27 06:34:40.521: INFO: (2) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 37.281953ms)
May 27 06:34:40.521: INFO: (2) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 42.304217ms)
May 27 06:34:40.522: INFO: (2) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 39.738253ms)
May 27 06:34:40.534: INFO: (2) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 51.177111ms)
May 27 06:34:40.544: INFO: (2) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 61.045156ms)
May 27 06:34:40.564: INFO: (3) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 19.25639ms)
May 27 06:34:40.566: INFO: (3) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 20.604398ms)
May 27 06:34:40.567: INFO: (3) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 20.0582ms)
May 27 06:34:40.570: INFO: (3) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 26.123323ms)
May 27 06:34:40.572: INFO: (3) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 25.887258ms)
May 27 06:34:40.581: INFO: (3) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 33.852319ms)
May 27 06:34:40.581: INFO: (3) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 36.878036ms)
May 27 06:34:40.581: INFO: (3) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 35.039568ms)
May 27 06:34:40.581: INFO: (3) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 36.317303ms)
May 27 06:34:40.581: INFO: (3) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 33.806006ms)
May 27 06:34:40.590: INFO: (3) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 45.29889ms)
May 27 06:34:40.590: INFO: (3) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 42.953727ms)
May 27 06:34:40.590: INFO: (3) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 43.374501ms)
May 27 06:34:40.592: INFO: (3) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 44.81874ms)
May 27 06:34:40.603: INFO: (3) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 58.240849ms)
May 27 06:34:40.608: INFO: (3) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 62.605215ms)
May 27 06:34:40.619: INFO: (4) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 10.798556ms)
May 27 06:34:40.620: INFO: (4) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 10.307123ms)
May 27 06:34:40.627: INFO: (4) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 17.842714ms)
May 27 06:34:40.631: INFO: (4) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 21.485817ms)
May 27 06:34:40.636: INFO: (4) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 28.130701ms)
May 27 06:34:40.637: INFO: (4) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 26.832339ms)
May 27 06:34:40.638: INFO: (4) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 28.484157ms)
May 27 06:34:40.638: INFO: (4) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 28.307649ms)
May 27 06:34:40.643: INFO: (4) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 32.705025ms)
May 27 06:34:40.643: INFO: (4) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 34.118014ms)
May 27 06:34:40.645: INFO: (4) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 34.668963ms)
May 27 06:34:40.646: INFO: (4) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 36.434049ms)
May 27 06:34:40.650: INFO: (4) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 40.082409ms)
May 27 06:34:40.656: INFO: (4) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 45.67842ms)
May 27 06:34:40.661: INFO: (4) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 52.678678ms)
May 27 06:34:40.661: INFO: (4) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 52.353534ms)
May 27 06:34:40.676: INFO: (5) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 13.335833ms)
May 27 06:34:40.681: INFO: (5) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 18.32858ms)
May 27 06:34:40.684: INFO: (5) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 22.004479ms)
May 27 06:34:40.684: INFO: (5) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 21.385186ms)
May 27 06:34:40.687: INFO: (5) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 24.414017ms)
May 27 06:34:40.687: INFO: (5) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 24.446359ms)
May 27 06:34:40.687: INFO: (5) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 24.941315ms)
May 27 06:34:40.700: INFO: (5) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 37.313381ms)
May 27 06:34:40.706: INFO: (5) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 44.00786ms)
May 27 06:34:40.708: INFO: (5) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 44.763099ms)
May 27 06:34:40.708: INFO: (5) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 44.192553ms)
May 27 06:34:40.709: INFO: (5) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 45.810893ms)
May 27 06:34:40.709: INFO: (5) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 46.104483ms)
May 27 06:34:40.709: INFO: (5) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 46.896222ms)
May 27 06:34:40.712: INFO: (5) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 48.934987ms)
May 27 06:34:40.717: INFO: (5) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 55.078704ms)
May 27 06:34:40.733: INFO: (6) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 15.579064ms)
May 27 06:34:40.733: INFO: (6) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 15.07397ms)
May 27 06:34:40.733: INFO: (6) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 15.370966ms)
May 27 06:34:40.739: INFO: (6) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 20.882069ms)
May 27 06:34:40.742: INFO: (6) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 23.170939ms)
May 27 06:34:40.743: INFO: (6) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 24.599823ms)
May 27 06:34:40.743: INFO: (6) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 25.233331ms)
May 27 06:34:40.744: INFO: (6) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 26.255898ms)
May 27 06:34:40.753: INFO: (6) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 34.860291ms)
May 27 06:34:40.754: INFO: (6) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 36.08729ms)
May 27 06:34:40.764: INFO: (6) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 45.624326ms)
May 27 06:34:40.771: INFO: (6) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 53.099086ms)
May 27 06:34:40.773: INFO: (6) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 54.500128ms)
May 27 06:34:40.786: INFO: (6) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 67.681427ms)
May 27 06:34:40.793: INFO: (6) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 75.018552ms)
May 27 06:34:40.806: INFO: (6) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 88.151202ms)
May 27 06:34:40.824: INFO: (7) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 16.791514ms)
May 27 06:34:40.827: INFO: (7) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 20.001993ms)
May 27 06:34:40.829: INFO: (7) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 22.450059ms)
May 27 06:34:40.836: INFO: (7) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 29.727967ms)
May 27 06:34:40.837: INFO: (7) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 29.652076ms)
May 27 06:34:40.840: INFO: (7) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 33.0791ms)
May 27 06:34:40.840: INFO: (7) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 33.168447ms)
May 27 06:34:40.846: INFO: (7) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 38.40201ms)
May 27 06:34:40.846: INFO: (7) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 38.988115ms)
May 27 06:34:40.846: INFO: (7) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 39.151742ms)
May 27 06:34:40.852: INFO: (7) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 45.085048ms)
May 27 06:34:40.852: INFO: (7) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 45.266601ms)
May 27 06:34:40.853: INFO: (7) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 45.686403ms)
May 27 06:34:40.854: INFO: (7) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 46.472813ms)
May 27 06:34:40.863: INFO: (7) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 55.834ms)
May 27 06:34:40.892: INFO: (7) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 84.685927ms)
May 27 06:34:40.942: INFO: (8) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 46.321304ms)
May 27 06:34:40.943: INFO: (8) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 49.344577ms)
May 27 06:34:40.944: INFO: (8) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 48.870237ms)
May 27 06:34:40.951: INFO: (8) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 57.040576ms)
May 27 06:34:40.951: INFO: (8) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 57.950512ms)
May 27 06:34:40.951: INFO: (8) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 56.270352ms)
May 27 06:34:40.952: INFO: (8) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 54.608402ms)
May 27 06:34:40.952: INFO: (8) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 58.711618ms)
May 27 06:34:40.953: INFO: (8) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 58.727756ms)
May 27 06:34:40.953: INFO: (8) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 57.797303ms)
May 27 06:34:40.954: INFO: (8) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 61.03444ms)
May 27 06:34:40.979: INFO: (8) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 84.278396ms)
May 27 06:34:40.981: INFO: (8) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 84.451864ms)
May 27 06:34:40.981: INFO: (8) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 84.977072ms)
May 27 06:34:40.981: INFO: (8) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 88.180971ms)
May 27 06:34:40.981: INFO: (8) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 85.531983ms)
May 27 06:34:41.026: INFO: (9) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 44.904955ms)
May 27 06:34:41.027: INFO: (9) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 44.122956ms)
May 27 06:34:41.027: INFO: (9) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 44.780833ms)
May 27 06:34:41.027: INFO: (9) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 44.616293ms)
May 27 06:34:41.035: INFO: (9) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 52.109437ms)
May 27 06:34:41.035: INFO: (9) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 52.75101ms)
May 27 06:34:41.035: INFO: (9) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 52.981312ms)
May 27 06:34:41.035: INFO: (9) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 52.63899ms)
May 27 06:34:41.035: INFO: (9) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 52.928722ms)
May 27 06:34:41.057: INFO: (9) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 75.397037ms)
May 27 06:34:41.081: INFO: (9) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 98.533858ms)
May 27 06:34:41.081: INFO: (9) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 100.291258ms)
May 27 06:34:41.082: INFO: (9) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 98.898815ms)
May 27 06:34:41.083: INFO: (9) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 100.626038ms)
May 27 06:34:41.083: INFO: (9) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 100.889546ms)
May 27 06:34:41.083: INFO: (9) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 100.826788ms)
May 27 06:34:41.098: INFO: (10) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 14.293129ms)
May 27 06:34:41.104: INFO: (10) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 18.437179ms)
May 27 06:34:41.104: INFO: (10) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 18.887111ms)
May 27 06:34:41.108: INFO: (10) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 22.065183ms)
May 27 06:34:41.116: INFO: (10) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 29.773848ms)
May 27 06:34:41.116: INFO: (10) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 30.388824ms)
May 27 06:34:41.117: INFO: (10) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 30.631107ms)
May 27 06:34:41.117: INFO: (10) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 31.144964ms)
May 27 06:34:41.131: INFO: (10) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 46.038705ms)
May 27 06:34:41.150: INFO: (10) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 63.971356ms)
May 27 06:34:41.152: INFO: (10) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 65.464708ms)
May 27 06:34:41.152: INFO: (10) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 65.208764ms)
May 27 06:34:41.152: INFO: (10) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 66.102376ms)
May 27 06:34:41.153: INFO: (10) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 69.235011ms)
May 27 06:34:41.153: INFO: (10) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 67.823736ms)
May 27 06:34:41.156: INFO: (10) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 70.417966ms)
May 27 06:34:41.168: INFO: (11) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 11.905328ms)
May 27 06:34:41.171: INFO: (11) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 14.27196ms)
May 27 06:34:41.177: INFO: (11) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 20.321318ms)
May 27 06:34:41.179: INFO: (11) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 21.404346ms)
May 27 06:34:41.179: INFO: (11) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 22.276394ms)
May 27 06:34:41.181: INFO: (11) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 24.359846ms)
May 27 06:34:41.182: INFO: (11) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 24.466727ms)
May 27 06:34:41.184: INFO: (11) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 26.707343ms)
May 27 06:34:41.184: INFO: (11) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 28.008565ms)
May 27 06:34:41.185: INFO: (11) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 28.014627ms)
May 27 06:34:41.186: INFO: (11) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 29.204766ms)
May 27 06:34:41.186: INFO: (11) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 28.829075ms)
May 27 06:34:41.187: INFO: (11) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 30.421342ms)
May 27 06:34:41.188: INFO: (11) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 31.206007ms)
May 27 06:34:41.191: INFO: (11) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 33.141512ms)
May 27 06:34:41.196: INFO: (11) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 38.429457ms)
May 27 06:34:41.212: INFO: (12) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 15.248933ms)
May 27 06:34:41.212: INFO: (12) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 16.143902ms)
May 27 06:34:41.212: INFO: (12) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 16.193651ms)
May 27 06:34:41.221: INFO: (12) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 22.769174ms)
May 27 06:34:41.221: INFO: (12) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 23.434802ms)
May 27 06:34:41.222: INFO: (12) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 25.103218ms)
May 27 06:34:41.222: INFO: (12) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 24.782558ms)
May 27 06:34:41.224: INFO: (12) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 26.98482ms)
May 27 06:34:41.224: INFO: (12) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 25.851756ms)
May 27 06:34:41.224: INFO: (12) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 26.660264ms)
May 27 06:34:41.261: INFO: (12) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 64.720469ms)
May 27 06:34:41.261: INFO: (12) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 63.89353ms)
May 27 06:34:41.262: INFO: (12) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 65.261436ms)
May 27 06:34:41.263: INFO: (12) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 65.596025ms)
May 27 06:34:41.264: INFO: (12) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 67.620983ms)
May 27 06:34:41.289: INFO: (12) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 91.242663ms)
May 27 06:34:41.332: INFO: (13) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 42.426881ms)
May 27 06:34:41.333: INFO: (13) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 42.453779ms)
May 27 06:34:41.333: INFO: (13) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 42.354179ms)
May 27 06:34:41.333: INFO: (13) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 42.664134ms)
May 27 06:34:41.351: INFO: (13) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 60.079803ms)
May 27 06:34:41.351: INFO: (13) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 60.368604ms)
May 27 06:34:41.351: INFO: (13) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 60.871092ms)
May 27 06:34:41.351: INFO: (13) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 61.314091ms)
May 27 06:34:41.352: INFO: (13) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 61.945188ms)
May 27 06:34:41.352: INFO: (13) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 62.166806ms)
May 27 06:34:41.353: INFO: (13) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 62.831679ms)
May 27 06:34:41.360: INFO: (13) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 69.640934ms)
May 27 06:34:41.360: INFO: (13) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 70.336231ms)
May 27 06:34:41.360: INFO: (13) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 70.173623ms)
May 27 06:34:41.360: INFO: (13) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 69.820986ms)
May 27 06:34:41.364: INFO: (13) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 73.638564ms)
May 27 06:34:41.379: INFO: (14) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 15.361344ms)
May 27 06:34:41.379: INFO: (14) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 15.067801ms)
May 27 06:34:41.403: INFO: (14) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 39.508825ms)
May 27 06:34:41.404: INFO: (14) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 39.120268ms)
May 27 06:34:41.404: INFO: (14) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 39.548063ms)
May 27 06:34:41.404: INFO: (14) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 39.36539ms)
May 27 06:34:41.404: INFO: (14) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 39.667381ms)
May 27 06:34:41.405: INFO: (14) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 40.305943ms)
May 27 06:34:41.407: INFO: (14) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 43.601585ms)
May 27 06:34:41.414: INFO: (14) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 49.063792ms)
May 27 06:34:41.415: INFO: (14) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 50.267171ms)
May 27 06:34:41.415: INFO: (14) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 50.114287ms)
May 27 06:34:41.416: INFO: (14) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 50.98129ms)
May 27 06:34:41.419: INFO: (14) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 54.161283ms)
May 27 06:34:41.420: INFO: (14) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 54.80829ms)
May 27 06:34:41.439: INFO: (14) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 74.318873ms)
May 27 06:34:41.452: INFO: (15) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 12.150058ms)
May 27 06:34:41.470: INFO: (15) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 30.277478ms)
May 27 06:34:41.472: INFO: (15) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 31.420453ms)
May 27 06:34:41.472: INFO: (15) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 31.674197ms)
May 27 06:34:41.472: INFO: (15) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 31.68729ms)
May 27 06:34:41.472: INFO: (15) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 30.220875ms)
May 27 06:34:41.472: INFO: (15) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 32.478755ms)
May 27 06:34:41.472: INFO: (15) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 31.333594ms)
May 27 06:34:41.473: INFO: (15) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 32.53144ms)
May 27 06:34:41.473: INFO: (15) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 33.023529ms)
May 27 06:34:41.475: INFO: (15) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 35.081514ms)
May 27 06:34:41.475: INFO: (15) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 35.073799ms)
May 27 06:34:41.476: INFO: (15) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 35.504215ms)
May 27 06:34:41.478: INFO: (15) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 37.900831ms)
May 27 06:34:41.481: INFO: (15) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 41.386496ms)
May 27 06:34:41.483: INFO: (15) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 42.37504ms)
May 27 06:34:41.500: INFO: (16) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 16.690728ms)
May 27 06:34:41.504: INFO: (16) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 20.48963ms)
May 27 06:34:41.504: INFO: (16) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 20.66161ms)
May 27 06:34:41.506: INFO: (16) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 22.954565ms)
May 27 06:34:41.508: INFO: (16) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 24.260965ms)
May 27 06:34:41.508: INFO: (16) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 24.714652ms)
May 27 06:34:41.510: INFO: (16) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 26.422611ms)
May 27 06:34:41.510: INFO: (16) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 26.47461ms)
May 27 06:34:41.510: INFO: (16) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 27.119613ms)
May 27 06:34:41.511: INFO: (16) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 26.568139ms)
May 27 06:34:41.511: INFO: (16) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 26.985418ms)
May 27 06:34:41.511: INFO: (16) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 27.579924ms)
May 27 06:34:41.512: INFO: (16) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 28.906588ms)
May 27 06:34:41.516: INFO: (16) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 32.248152ms)
May 27 06:34:41.518: INFO: (16) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 34.487601ms)
May 27 06:34:41.523: INFO: (16) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 38.68606ms)
May 27 06:34:41.536: INFO: (17) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 13.223619ms)
May 27 06:34:41.537: INFO: (17) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 13.669497ms)
May 27 06:34:41.537: INFO: (17) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 13.902727ms)
May 27 06:34:41.541: INFO: (17) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 17.696441ms)
May 27 06:34:41.545: INFO: (17) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 21.831075ms)
May 27 06:34:41.549: INFO: (17) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 25.381069ms)
May 27 06:34:41.549: INFO: (17) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 25.733538ms)
May 27 06:34:41.551: INFO: (17) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 28.073782ms)
May 27 06:34:41.552: INFO: (17) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 29.063359ms)
May 27 06:34:41.552: INFO: (17) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 28.985261ms)
May 27 06:34:41.552: INFO: (17) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 29.529274ms)
May 27 06:34:41.552: INFO: (17) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 29.305646ms)
May 27 06:34:41.554: INFO: (17) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 30.949063ms)
May 27 06:34:41.554: INFO: (17) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 30.801595ms)
May 27 06:34:41.554: INFO: (17) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 30.786629ms)
May 27 06:34:41.554: INFO: (17) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 31.089486ms)
May 27 06:34:41.575: INFO: (18) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 20.853874ms)
May 27 06:34:41.578: INFO: (18) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 22.942661ms)
May 27 06:34:41.578: INFO: (18) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 23.117078ms)
May 27 06:34:41.580: INFO: (18) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 24.483134ms)
May 27 06:34:41.581: INFO: (18) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 24.892603ms)
May 27 06:34:41.581: INFO: (18) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 25.141228ms)
May 27 06:34:41.583: INFO: (18) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 26.664791ms)
May 27 06:34:41.583: INFO: (18) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 27.196177ms)
May 27 06:34:41.585: INFO: (18) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 28.609202ms)
May 27 06:34:41.586: INFO: (18) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 30.507622ms)
May 27 06:34:41.589: INFO: (18) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 33.699842ms)
May 27 06:34:41.590: INFO: (18) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 35.05898ms)
May 27 06:34:41.590: INFO: (18) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 35.375704ms)
May 27 06:34:41.590: INFO: (18) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 34.496142ms)
May 27 06:34:41.591: INFO: (18) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 34.594692ms)
May 27 06:34:41.599: INFO: (18) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 43.277156ms)
May 27 06:34:41.626: INFO: (19) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">test<... (200; 26.550858ms)
May 27 06:34:41.627: INFO: (19) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:1080/proxy/rewriteme">... (200; 27.275326ms)
May 27 06:34:41.627: INFO: (19) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 27.622993ms)
May 27 06:34:41.628: INFO: (19) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:443/proxy/tlsrewritem... (200; 28.341846ms)
May 27 06:34:41.631: INFO: (19) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:460/proxy/: tls baz (200; 31.673893ms)
May 27 06:34:41.632: INFO: (19) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 31.836064ms)
May 27 06:34:41.632: INFO: (19) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:162/proxy/: bar (200; 32.422957ms)
May 27 06:34:41.633: INFO: (19) /api/v1/namespaces/proxy-6589/pods/http:proxy-service-rw4nf-nd6k5:160/proxy/: foo (200; 32.913163ms)
May 27 06:34:41.633: INFO: (19) /api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/: <a href="/api/v1/namespaces/proxy-6589/pods/proxy-service-rw4nf-nd6k5/proxy/rewriteme">test</a> (200; 33.205863ms)
May 27 06:34:41.634: INFO: (19) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname1/proxy/: tls baz (200; 34.295779ms)
May 27 06:34:41.635: INFO: (19) /api/v1/namespaces/proxy-6589/pods/https:proxy-service-rw4nf-nd6k5:462/proxy/: tls qux (200; 35.213765ms)
May 27 06:34:41.635: INFO: (19) /api/v1/namespaces/proxy-6589/services/https:proxy-service-rw4nf:tlsportname2/proxy/: tls qux (200; 35.577287ms)
May 27 06:34:41.637: INFO: (19) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname2/proxy/: bar (200; 36.365661ms)
May 27 06:34:41.637: INFO: (19) /api/v1/namespaces/proxy-6589/services/http:proxy-service-rw4nf:portname1/proxy/: foo (200; 36.940582ms)
May 27 06:34:41.639: INFO: (19) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname2/proxy/: bar (200; 39.103881ms)
May 27 06:34:41.639: INFO: (19) /api/v1/namespaces/proxy-6589/services/proxy-service-rw4nf:portname1/proxy/: foo (200; 39.016468ms)
STEP: deleting ReplicationController proxy-service-rw4nf in namespace proxy-6589, will wait for the garbage collector to delete the pods
May 27 06:34:41.716: INFO: Deleting ReplicationController proxy-service-rw4nf took: 16.034008ms
May 27 06:34:41.817: INFO: Terminating ReplicationController proxy-service-rw4nf pods took: 101.089169ms
[AfterEach] version v1
  test/e2e/framework/framework.go:188
May 27 06:34:45.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6589" for this suite.

• [SLOW TEST:7.024 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":356,"completed":223,"skipped":4337,"failed":0}
SS
------------------------------
[sig-node] Containers 
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:34:45.062: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override arguments
May 27 06:34:45.140: INFO: Waiting up to 5m0s for pod "client-containers-849e7d24-8734-4729-aef5-9bf24c631136" in namespace "containers-8917" to be "Succeeded or Failed"
May 27 06:34:45.146: INFO: Pod "client-containers-849e7d24-8734-4729-aef5-9bf24c631136": Phase="Pending", Reason="", readiness=false. Elapsed: 6.560011ms
May 27 06:34:47.160: INFO: Pod "client-containers-849e7d24-8734-4729-aef5-9bf24c631136": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020284836s
May 27 06:34:49.173: INFO: Pod "client-containers-849e7d24-8734-4729-aef5-9bf24c631136": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032674071s
May 27 06:34:51.181: INFO: Pod "client-containers-849e7d24-8734-4729-aef5-9bf24c631136": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.041478422s
STEP: Saw pod success
May 27 06:34:51.181: INFO: Pod "client-containers-849e7d24-8734-4729-aef5-9bf24c631136" satisfied condition "Succeeded or Failed"
May 27 06:34:51.187: INFO: Trying to get logs from node bohc9zohd7ee-3 pod client-containers-849e7d24-8734-4729-aef5-9bf24c631136 container agnhost-container: <nil>
STEP: delete the pod
May 27 06:34:51.566: INFO: Waiting for pod client-containers-849e7d24-8734-4729-aef5-9bf24c631136 to disappear
May 27 06:34:51.574: INFO: Pod client-containers-849e7d24-8734-4729-aef5-9bf24c631136 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
May 27 06:34:51.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8917" for this suite.

• [SLOW TEST:6.534 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","total":356,"completed":224,"skipped":4339,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:34:51.599: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 27 06:34:51.676: INFO: Waiting up to 5m0s for pod "pod-20e88103-c4ad-4ed1-959d-8a2e4f826d25" in namespace "emptydir-8386" to be "Succeeded or Failed"
May 27 06:34:51.688: INFO: Pod "pod-20e88103-c4ad-4ed1-959d-8a2e4f826d25": Phase="Pending", Reason="", readiness=false. Elapsed: 12.070168ms
May 27 06:34:53.704: INFO: Pod "pod-20e88103-c4ad-4ed1-959d-8a2e4f826d25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028016539s
May 27 06:34:55.720: INFO: Pod "pod-20e88103-c4ad-4ed1-959d-8a2e4f826d25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04354181s
May 27 06:34:57.735: INFO: Pod "pod-20e88103-c4ad-4ed1-959d-8a2e4f826d25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.058867884s
STEP: Saw pod success
May 27 06:34:57.735: INFO: Pod "pod-20e88103-c4ad-4ed1-959d-8a2e4f826d25" satisfied condition "Succeeded or Failed"
May 27 06:34:57.744: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-20e88103-c4ad-4ed1-959d-8a2e4f826d25 container test-container: <nil>
STEP: delete the pod
May 27 06:34:57.796: INFO: Waiting for pod pod-20e88103-c4ad-4ed1-959d-8a2e4f826d25 to disappear
May 27 06:34:57.803: INFO: Pod pod-20e88103-c4ad-4ed1-959d-8a2e4f826d25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 06:34:57.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8386" for this suite.

• [SLOW TEST:6.230 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":225,"skipped":4357,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:34:57.829: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 27 06:34:57.906: INFO: Waiting up to 5m0s for pod "pod-f7619f5a-ff28-4e23-9c28-27e361cb84d0" in namespace "emptydir-1858" to be "Succeeded or Failed"
May 27 06:34:57.925: INFO: Pod "pod-f7619f5a-ff28-4e23-9c28-27e361cb84d0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.340079ms
May 27 06:34:59.944: INFO: Pod "pod-f7619f5a-ff28-4e23-9c28-27e361cb84d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037083336s
May 27 06:35:01.958: INFO: Pod "pod-f7619f5a-ff28-4e23-9c28-27e361cb84d0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051688703s
May 27 06:35:03.988: INFO: Pod "pod-f7619f5a-ff28-4e23-9c28-27e361cb84d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.08157025s
STEP: Saw pod success
May 27 06:35:03.988: INFO: Pod "pod-f7619f5a-ff28-4e23-9c28-27e361cb84d0" satisfied condition "Succeeded or Failed"
May 27 06:35:03.998: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-f7619f5a-ff28-4e23-9c28-27e361cb84d0 container test-container: <nil>
STEP: delete the pod
May 27 06:35:04.045: INFO: Waiting for pod pod-f7619f5a-ff28-4e23-9c28-27e361cb84d0 to disappear
May 27 06:35:04.051: INFO: Pod pod-f7619f5a-ff28-4e23-9c28-27e361cb84d0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 06:35:04.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1858" for this suite.

• [SLOW TEST:6.264 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":226,"skipped":4365,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:35:04.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
May 27 06:35:04.323: INFO: Waiting up to 5m0s for pod "downward-api-d61f5448-cba1-45a7-ba3a-8d125125f562" in namespace "downward-api-1632" to be "Succeeded or Failed"
May 27 06:35:04.347: INFO: Pod "downward-api-d61f5448-cba1-45a7-ba3a-8d125125f562": Phase="Pending", Reason="", readiness=false. Elapsed: 24.459795ms
May 27 06:35:06.365: INFO: Pod "downward-api-d61f5448-cba1-45a7-ba3a-8d125125f562": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042446413s
May 27 06:35:08.395: INFO: Pod "downward-api-d61f5448-cba1-45a7-ba3a-8d125125f562": Phase="Pending", Reason="", readiness=false. Elapsed: 4.071828918s
May 27 06:35:10.411: INFO: Pod "downward-api-d61f5448-cba1-45a7-ba3a-8d125125f562": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.088251853s
STEP: Saw pod success
May 27 06:35:10.411: INFO: Pod "downward-api-d61f5448-cba1-45a7-ba3a-8d125125f562" satisfied condition "Succeeded or Failed"
May 27 06:35:10.421: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downward-api-d61f5448-cba1-45a7-ba3a-8d125125f562 container dapi-container: <nil>
STEP: delete the pod
May 27 06:35:10.475: INFO: Waiting for pod downward-api-d61f5448-cba1-45a7-ba3a-8d125125f562 to disappear
May 27 06:35:10.485: INFO: Pod downward-api-d61f5448-cba1-45a7-ba3a-8d125125f562 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
May 27 06:35:10.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1632" for this suite.

• [SLOW TEST:6.413 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":356,"completed":227,"skipped":4375,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:35:10.511: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 06:35:10.585: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1e1f770e-a68a-4634-a8bb-449edbc815c4" in namespace "projected-9219" to be "Succeeded or Failed"
May 27 06:35:10.594: INFO: Pod "downwardapi-volume-1e1f770e-a68a-4634-a8bb-449edbc815c4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.937033ms
May 27 06:35:12.612: INFO: Pod "downwardapi-volume-1e1f770e-a68a-4634-a8bb-449edbc815c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02666619s
May 27 06:35:14.629: INFO: Pod "downwardapi-volume-1e1f770e-a68a-4634-a8bb-449edbc815c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043760341s
May 27 06:35:16.642: INFO: Pod "downwardapi-volume-1e1f770e-a68a-4634-a8bb-449edbc815c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.056652407s
STEP: Saw pod success
May 27 06:35:16.642: INFO: Pod "downwardapi-volume-1e1f770e-a68a-4634-a8bb-449edbc815c4" satisfied condition "Succeeded or Failed"
May 27 06:35:16.647: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-1e1f770e-a68a-4634-a8bb-449edbc815c4 container client-container: <nil>
STEP: delete the pod
May 27 06:35:16.688: INFO: Waiting for pod downwardapi-volume-1e1f770e-a68a-4634-a8bb-449edbc815c4 to disappear
May 27 06:35:16.694: INFO: Pod downwardapi-volume-1e1f770e-a68a-4634-a8bb-449edbc815c4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
May 27 06:35:16.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9219" for this suite.

• [SLOW TEST:6.201 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":228,"skipped":4396,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:35:16.716: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 27 06:35:16.813: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2727  60510892-a3a7-4c1e-9b7c-8fc2ec396cea 29386 0 2022-05-27 06:35:16 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-05-27 06:35:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 06:35:16.813: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2727  60510892-a3a7-4c1e-9b7c-8fc2ec396cea 29387 0 2022-05-27 06:35:16 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-05-27 06:35:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
May 27 06:35:16.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2727" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":356,"completed":229,"skipped":4405,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:35:16.842: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1412
STEP: creating an pod
May 27 06:35:16.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6167 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.36 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
May 27 06:35:17.029: INFO: stderr: ""
May 27 06:35:17.029: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for log generator to start.
May 27 06:35:17.029: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
May 27 06:35:17.029: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6167" to be "running and ready, or succeeded"
May 27 06:35:17.051: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 21.857814ms
May 27 06:35:19.062: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.033711947s
May 27 06:35:19.063: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
May 27 06:35:19.063: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
May 27 06:35:19.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6167 logs logs-generator logs-generator'
May 27 06:35:19.202: INFO: stderr: ""
May 27 06:35:19.202: INFO: stdout: "I0527 06:35:18.612457       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/jst 489\nI0527 06:35:18.812498       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/b9tb 395\nI0527 06:35:19.011785       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/6dd 546\n"
May 27 06:35:21.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6167 logs logs-generator logs-generator'
May 27 06:35:21.497: INFO: stderr: ""
May 27 06:35:21.497: INFO: stdout: "I0527 06:35:18.612457       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/jst 489\nI0527 06:35:18.812498       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/b9tb 395\nI0527 06:35:19.011785       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/6dd 546\nI0527 06:35:19.222069       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/dlpz 500\nI0527 06:35:19.412424       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/g8t9 560\nI0527 06:35:19.611766       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/4vm 387\nI0527 06:35:19.812168       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/cqkp 243\nI0527 06:35:20.012483       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/bn4 548\nI0527 06:35:20.211757       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/cqm 491\nI0527 06:35:20.412151       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/q5p7 578\nI0527 06:35:20.612710       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/vl4s 307\nI0527 06:35:20.812085       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/4gvs 546\nI0527 06:35:21.012618       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/4gg5 292\nI0527 06:35:21.212006       1 logs_generator.go:76] 13 POST /api/v1/namespaces/default/pods/9n66 491\nI0527 06:35:21.412185       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/8dxk 379\n"
STEP: limiting log lines
May 27 06:35:21.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6167 logs logs-generator logs-generator --tail=1'
May 27 06:35:21.726: INFO: stderr: ""
May 27 06:35:21.726: INFO: stdout: "I0527 06:35:21.612778       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/vrvx 561\n"
May 27 06:35:21.726: INFO: got output "I0527 06:35:21.612778       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/vrvx 561\n"
STEP: limiting log bytes
May 27 06:35:21.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6167 logs logs-generator logs-generator --limit-bytes=1'
May 27 06:35:21.925: INFO: stderr: ""
May 27 06:35:21.925: INFO: stdout: "I"
May 27 06:35:21.925: INFO: got output "I"
STEP: exposing timestamps
May 27 06:35:21.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6167 logs logs-generator logs-generator --tail=1 --timestamps'
May 27 06:35:22.141: INFO: stderr: ""
May 27 06:35:22.141: INFO: stdout: "2022-05-27T06:35:22.014723849Z I0527 06:35:22.014094       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/5s8 223\n"
May 27 06:35:22.141: INFO: got output "2022-05-27T06:35:22.014723849Z I0527 06:35:22.014094       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/5s8 223\n"
STEP: restricting to a time range
May 27 06:35:24.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6167 logs logs-generator logs-generator --since=1s'
May 27 06:35:24.780: INFO: stderr: ""
May 27 06:35:24.780: INFO: stdout: "I0527 06:35:23.812643       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/5pg 204\nI0527 06:35:24.012182       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/zxn 536\nI0527 06:35:24.212614       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/gf5s 307\nI0527 06:35:24.412051       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/default/pods/slh 570\nI0527 06:35:24.612500       1 logs_generator.go:76] 30 POST /api/v1/namespaces/kube-system/pods/mc4k 266\n"
May 27 06:35:24.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6167 logs logs-generator logs-generator --since=24h'
May 27 06:35:24.927: INFO: stderr: ""
May 27 06:35:24.927: INFO: stdout: "I0527 06:35:18.612457       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/jst 489\nI0527 06:35:18.812498       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/b9tb 395\nI0527 06:35:19.011785       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/6dd 546\nI0527 06:35:19.222069       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/dlpz 500\nI0527 06:35:19.412424       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/g8t9 560\nI0527 06:35:19.611766       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/4vm 387\nI0527 06:35:19.812168       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/cqkp 243\nI0527 06:35:20.012483       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/bn4 548\nI0527 06:35:20.211757       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/cqm 491\nI0527 06:35:20.412151       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/q5p7 578\nI0527 06:35:20.612710       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/vl4s 307\nI0527 06:35:20.812085       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/4gvs 546\nI0527 06:35:21.012618       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/4gg5 292\nI0527 06:35:21.212006       1 logs_generator.go:76] 13 POST /api/v1/namespaces/default/pods/9n66 491\nI0527 06:35:21.412185       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/8dxk 379\nI0527 06:35:21.612778       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/vrvx 561\nI0527 06:35:21.815296       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/rz4f 233\nI0527 06:35:22.014094       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/5s8 223\nI0527 06:35:22.212681       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/8rd9 473\nI0527 06:35:22.412488       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/76z 463\nI0527 06:35:22.611828       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/lnmh 307\nI0527 06:35:22.812249       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/bpr 469\nI0527 06:35:23.011781       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/p8j 534\nI0527 06:35:23.212344       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/x28 275\nI0527 06:35:23.411709       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/rx7 284\nI0527 06:35:23.612406       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/default/pods/qmxh 293\nI0527 06:35:23.812643       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/5pg 204\nI0527 06:35:24.012182       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/zxn 536\nI0527 06:35:24.212614       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/gf5s 307\nI0527 06:35:24.412051       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/default/pods/slh 570\nI0527 06:35:24.612500       1 logs_generator.go:76] 30 POST /api/v1/namespaces/kube-system/pods/mc4k 266\nI0527 06:35:24.811963       1 logs_generator.go:76] 31 GET /api/v1/namespaces/kube-system/pods/9hm 508\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1417
May 27 06:35:24.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6167 delete pod logs-generator'
May 27 06:35:26.490: INFO: stderr: ""
May 27 06:35:26.490: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:35:26.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6167" for this suite.

• [SLOW TEST:9.671 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1409
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":356,"completed":230,"skipped":4455,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:35:26.513: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 06:35:26.574: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eabfb4e1-2b11-4970-aaa8-3b763bf29584" in namespace "projected-4475" to be "Succeeded or Failed"
May 27 06:35:26.597: INFO: Pod "downwardapi-volume-eabfb4e1-2b11-4970-aaa8-3b763bf29584": Phase="Pending", Reason="", readiness=false. Elapsed: 22.077213ms
May 27 06:35:28.613: INFO: Pod "downwardapi-volume-eabfb4e1-2b11-4970-aaa8-3b763bf29584": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038753543s
May 27 06:35:30.628: INFO: Pod "downwardapi-volume-eabfb4e1-2b11-4970-aaa8-3b763bf29584": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05392935s
May 27 06:35:32.643: INFO: Pod "downwardapi-volume-eabfb4e1-2b11-4970-aaa8-3b763bf29584": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.068768747s
STEP: Saw pod success
May 27 06:35:32.643: INFO: Pod "downwardapi-volume-eabfb4e1-2b11-4970-aaa8-3b763bf29584" satisfied condition "Succeeded or Failed"
May 27 06:35:32.650: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-eabfb4e1-2b11-4970-aaa8-3b763bf29584 container client-container: <nil>
STEP: delete the pod
May 27 06:35:32.698: INFO: Waiting for pod downwardapi-volume-eabfb4e1-2b11-4970-aaa8-3b763bf29584 to disappear
May 27 06:35:32.705: INFO: Pod downwardapi-volume-eabfb4e1-2b11-4970-aaa8-3b763bf29584 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
May 27 06:35:32.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4475" for this suite.

• [SLOW TEST:6.213 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":356,"completed":231,"skipped":4480,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:35:32.727: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
May 27 06:35:32.801: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May 27 06:35:34.813: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May 27 06:35:36.813: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
May 27 06:35:36.839: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
May 27 06:35:38.852: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
May 27 06:35:40.852: INFO: The status of Pod pod-with-prestop-exec-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
May 27 06:35:40.873: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 27 06:35:40.880: INFO: Pod pod-with-prestop-exec-hook still exists
May 27 06:35:42.881: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 27 06:35:42.893: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
May 27 06:35:42.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-450" for this suite.

• [SLOW TEST:10.224 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":356,"completed":232,"skipped":4490,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints 
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:35:42.956: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
May 27 06:35:43.018: INFO: Waiting up to 1m0s for all nodes to be ready
May 27 06:36:43.081: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:36:43.088: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:36:43.163: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: Value: Forbidden: may not be changed in an update.
May 27 06:36:43.169: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: Value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:188
May 27 06:36:43.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-3323" for this suite.
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
May 27 06:36:43.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7313" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:60.473 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","total":356,"completed":233,"skipped":4513,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:36:43.429: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
May 27 06:36:53.609: INFO: The status of Pod kube-controller-manager-bohc9zohd7ee-2 is Running (Ready = true)
May 27 06:36:53.709: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
May 27 06:36:53.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6024" for this suite.

• [SLOW TEST:10.307 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":356,"completed":234,"skipped":4540,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:36:53.738: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 06:36:54.954: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 27 06:36:56.980: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 36, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 36, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 36, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 36, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 06:37:00.014: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:37:00.029: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:37:03.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7772" for this suite.
STEP: Destroying namespace "webhook-7772-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:9.881 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":356,"completed":235,"skipped":4574,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] HostPort 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:37:03.620: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename hostport
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled
May 27 06:37:03.835: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:37:05.850: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.180 on the node which pod1 resides and expect scheduled
May 27 06:37:05.873: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:37:07.889: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.180 but use UDP protocol on the node which pod2 resides
May 27 06:37:07.912: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:37:09.926: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:37:11.926: INFO: The status of Pod pod3 is Running (Ready = true)
May 27 06:37:11.948: INFO: The status of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
May 27 06:37:13.961: INFO: The status of Pod e2e-host-exec is Running (Ready = true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323
May 27 06:37:13.967: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.180 http://127.0.0.1:54323/hostname] Namespace:hostport-1029 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:37:13.967: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:37:13.968: INFO: ExecWithOptions: Clientset creation
May 27 06:37:13.968: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-1029/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.180+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.180, port: 54323
May 27 06:37:14.321: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.180:54323/hostname] Namespace:hostport-1029 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:37:14.321: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:37:14.323: INFO: ExecWithOptions: Clientset creation
May 27 06:37:14.323: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-1029/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.180%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.180, port: 54323 UDP
May 27 06:37:14.586: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vuz -w 5 192.168.121.180 54323] Namespace:hostport-1029 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:37:14.587: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:37:14.588: INFO: ExecWithOptions: Clientset creation
May 27 06:37:14.588: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-1029/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=nc+-vuz+-w+5+192.168.121.180+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:188
May 27 06:37:19.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-1029" for this suite.

• [SLOW TEST:16.185 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","total":356,"completed":236,"skipped":4586,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:37:19.805: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
May 27 06:37:19.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 create -f -'
May 27 06:37:21.713: INFO: stderr: ""
May 27 06:37:21.713: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 27 06:37:21.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May 27 06:37:21.938: INFO: stderr: ""
May 27 06:37:21.938: INFO: stdout: "update-demo-nautilus-7ml5j update-demo-nautilus-bzjdl "
May 27 06:37:21.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods update-demo-nautilus-7ml5j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 06:37:22.146: INFO: stderr: ""
May 27 06:37:22.146: INFO: stdout: ""
May 27 06:37:22.146: INFO: update-demo-nautilus-7ml5j is created but not running
May 27 06:37:27.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May 27 06:37:27.340: INFO: stderr: ""
May 27 06:37:27.340: INFO: stdout: "update-demo-nautilus-7ml5j update-demo-nautilus-bzjdl "
May 27 06:37:27.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods update-demo-nautilus-7ml5j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 06:37:27.490: INFO: stderr: ""
May 27 06:37:27.490: INFO: stdout: "true"
May 27 06:37:27.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods update-demo-nautilus-7ml5j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May 27 06:37:27.665: INFO: stderr: ""
May 27 06:37:27.665: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
May 27 06:37:27.665: INFO: validating pod update-demo-nautilus-7ml5j
May 27 06:37:27.683: INFO: got data: {
  "image": "nautilus.jpg"
}

May 27 06:37:27.683: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 27 06:37:27.683: INFO: update-demo-nautilus-7ml5j is verified up and running
May 27 06:37:27.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods update-demo-nautilus-bzjdl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 06:37:27.846: INFO: stderr: ""
May 27 06:37:27.846: INFO: stdout: ""
May 27 06:37:27.846: INFO: update-demo-nautilus-bzjdl is created but not running
May 27 06:37:32.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May 27 06:37:33.001: INFO: stderr: ""
May 27 06:37:33.001: INFO: stdout: "update-demo-nautilus-7ml5j update-demo-nautilus-bzjdl "
May 27 06:37:33.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods update-demo-nautilus-7ml5j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 06:37:33.116: INFO: stderr: ""
May 27 06:37:33.116: INFO: stdout: "true"
May 27 06:37:33.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods update-demo-nautilus-7ml5j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May 27 06:37:33.270: INFO: stderr: ""
May 27 06:37:33.270: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
May 27 06:37:33.271: INFO: validating pod update-demo-nautilus-7ml5j
May 27 06:37:33.282: INFO: got data: {
  "image": "nautilus.jpg"
}

May 27 06:37:33.282: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 27 06:37:33.282: INFO: update-demo-nautilus-7ml5j is verified up and running
May 27 06:37:33.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods update-demo-nautilus-bzjdl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May 27 06:37:33.451: INFO: stderr: ""
May 27 06:37:33.451: INFO: stdout: "true"
May 27 06:37:33.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods update-demo-nautilus-bzjdl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May 27 06:37:33.606: INFO: stderr: ""
May 27 06:37:33.606: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
May 27 06:37:33.606: INFO: validating pod update-demo-nautilus-bzjdl
May 27 06:37:33.629: INFO: got data: {
  "image": "nautilus.jpg"
}

May 27 06:37:33.629: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 27 06:37:33.629: INFO: update-demo-nautilus-bzjdl is verified up and running
STEP: using delete to clean up resources
May 27 06:37:33.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 delete --grace-period=0 --force -f -'
May 27 06:37:33.782: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 27 06:37:33.782: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 27 06:37:33.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get rc,svc -l name=update-demo --no-headers'
May 27 06:37:33.993: INFO: stderr: "No resources found in kubectl-6385 namespace.\n"
May 27 06:37:33.993: INFO: stdout: ""
May 27 06:37:33.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-6385 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 27 06:37:34.233: INFO: stderr: ""
May 27 06:37:34.233: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:37:34.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6385" for this suite.

• [SLOW TEST:14.453 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should create and stop a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":356,"completed":237,"skipped":4587,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:37:34.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
May 27 06:37:38.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2708" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":356,"completed":238,"skipped":4604,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:37:38.400: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-downwardapi-n2xj
STEP: Creating a pod to test atomic-volume-subpath
May 27 06:37:38.503: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-n2xj" in namespace "subpath-2389" to be "Succeeded or Failed"
May 27 06:37:38.514: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Pending", Reason="", readiness=false. Elapsed: 10.84901ms
May 27 06:37:40.528: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02520482s
May 27 06:37:42.547: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Running", Reason="", readiness=true. Elapsed: 4.04455026s
May 27 06:37:44.566: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Running", Reason="", readiness=true. Elapsed: 6.063436675s
May 27 06:37:46.590: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Running", Reason="", readiness=true. Elapsed: 8.087204963s
May 27 06:37:48.605: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Running", Reason="", readiness=true. Elapsed: 10.101822269s
May 27 06:37:50.621: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Running", Reason="", readiness=true. Elapsed: 12.11856568s
May 27 06:37:52.636: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Running", Reason="", readiness=true. Elapsed: 14.13365641s
May 27 06:37:54.651: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Running", Reason="", readiness=true. Elapsed: 16.148221041s
May 27 06:37:56.666: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Running", Reason="", readiness=true. Elapsed: 18.163690324s
May 27 06:37:58.678: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Running", Reason="", readiness=true. Elapsed: 20.17547988s
May 27 06:38:00.691: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Running", Reason="", readiness=true. Elapsed: 22.18876381s
May 27 06:38:02.705: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Running", Reason="", readiness=false. Elapsed: 24.20270153s
May 27 06:38:04.721: INFO: Pod "pod-subpath-test-downwardapi-n2xj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.217926555s
STEP: Saw pod success
May 27 06:38:04.721: INFO: Pod "pod-subpath-test-downwardapi-n2xj" satisfied condition "Succeeded or Failed"
May 27 06:38:04.728: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-subpath-test-downwardapi-n2xj container test-container-subpath-downwardapi-n2xj: <nil>
STEP: delete the pod
May 27 06:38:04.783: INFO: Waiting for pod pod-subpath-test-downwardapi-n2xj to disappear
May 27 06:38:04.788: INFO: Pod pod-subpath-test-downwardapi-n2xj no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-n2xj
May 27 06:38:04.788: INFO: Deleting pod "pod-subpath-test-downwardapi-n2xj" in namespace "subpath-2389"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
May 27 06:38:04.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2389" for this suite.

• [SLOW TEST:26.411 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","total":356,"completed":239,"skipped":4614,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:38:04.816: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-4635
STEP: creating service affinity-clusterip in namespace services-4635
STEP: creating replication controller affinity-clusterip in namespace services-4635
I0527 06:38:04.905085      15 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-4635, replica count: 3
I0527 06:38:07.956717      15 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 27 06:38:07.976: INFO: Creating new exec pod
May 27 06:38:13.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-4635 exec execpod-affinity8gdbx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
May 27 06:38:13.374: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
May 27 06:38:13.374: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 06:38:13.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-4635 exec execpod-affinity8gdbx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.32.239 80'
May 27 06:38:13.716: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.32.239 80\nConnection to 10.233.32.239 80 port [tcp/http] succeeded!\n"
May 27 06:38:13.716: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May 27 06:38:13.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-4635 exec execpod-affinity8gdbx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.32.239:80/ ; done'
May 27 06:38:14.247: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.32.239:80/\n"
May 27 06:38:14.247: INFO: stdout: "\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz\naffinity-clusterip-t4fkz"
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Received response from host: affinity-clusterip-t4fkz
May 27 06:38:14.247: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-4635, will wait for the garbage collector to delete the pods
May 27 06:38:14.374: INFO: Deleting ReplicationController affinity-clusterip took: 21.3382ms
May 27 06:38:14.574: INFO: Terminating ReplicationController affinity-clusterip pods took: 200.669742ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 06:38:17.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4635" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:12.633 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":240,"skipped":4624,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:38:17.451: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
May 27 06:38:17.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6100" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":241,"skipped":4661,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:38:17.566: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a Replicaset
STEP: Verify that the required pods have come up.
May 27 06:38:17.634: INFO: Pod name sample-pod: Found 0 pods out of 1
May 27 06:38:22.657: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Getting /status
May 27 06:38:22.680: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status
May 27 06:38:22.723: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated
May 27 06:38:22.727: INFO: Observed &ReplicaSet event: ADDED
May 27 06:38:22.727: INFO: Observed &ReplicaSet event: MODIFIED
May 27 06:38:22.728: INFO: Observed &ReplicaSet event: MODIFIED
May 27 06:38:22.728: INFO: Observed &ReplicaSet event: MODIFIED
May 27 06:38:22.740: INFO: Found replicaset test-rs in namespace replicaset-5628 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
May 27 06:38:22.740: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status
May 27 06:38:22.741: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
May 27 06:38:22.775: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched
May 27 06:38:22.779: INFO: Observed &ReplicaSet event: ADDED
May 27 06:38:22.779: INFO: Observed &ReplicaSet event: MODIFIED
May 27 06:38:22.779: INFO: Observed &ReplicaSet event: MODIFIED
May 27 06:38:22.780: INFO: Observed &ReplicaSet event: MODIFIED
May 27 06:38:22.780: INFO: Observed replicaset test-rs in namespace replicaset-5628 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May 27 06:38:22.780: INFO: Observed &ReplicaSet event: MODIFIED
May 27 06:38:22.780: INFO: Found replicaset test-rs in namespace replicaset-5628 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
May 27 06:38:22.780: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
May 27 06:38:22.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5628" for this suite.

• [SLOW TEST:5.265 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","total":356,"completed":242,"skipped":4701,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:38:22.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
May 27 06:38:22.893: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:38:29.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:38:55.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5678" for this suite.

• [SLOW TEST:32.488 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":356,"completed":243,"skipped":4718,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:38:55.322: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-f99dc686-8dbf-4132-8c34-c1854483e841
STEP: Creating a pod to test consume configMaps
May 27 06:38:55.399: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b8da3f7b-ce97-4b71-a1dd-0a1e9ae9c405" in namespace "projected-2406" to be "Succeeded or Failed"
May 27 06:38:55.406: INFO: Pod "pod-projected-configmaps-b8da3f7b-ce97-4b71-a1dd-0a1e9ae9c405": Phase="Pending", Reason="", readiness=false. Elapsed: 6.951261ms
May 27 06:38:57.419: INFO: Pod "pod-projected-configmaps-b8da3f7b-ce97-4b71-a1dd-0a1e9ae9c405": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019798221s
May 27 06:38:59.428: INFO: Pod "pod-projected-configmaps-b8da3f7b-ce97-4b71-a1dd-0a1e9ae9c405": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027974255s
May 27 06:39:01.436: INFO: Pod "pod-projected-configmaps-b8da3f7b-ce97-4b71-a1dd-0a1e9ae9c405": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036522228s
STEP: Saw pod success
May 27 06:39:01.436: INFO: Pod "pod-projected-configmaps-b8da3f7b-ce97-4b71-a1dd-0a1e9ae9c405" satisfied condition "Succeeded or Failed"
May 27 06:39:01.443: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-configmaps-b8da3f7b-ce97-4b71-a1dd-0a1e9ae9c405 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 27 06:39:01.708: INFO: Waiting for pod pod-projected-configmaps-b8da3f7b-ce97-4b71-a1dd-0a1e9ae9c405 to disappear
May 27 06:39:01.716: INFO: Pod pod-projected-configmaps-b8da3f7b-ce97-4b71-a1dd-0a1e9ae9c405 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
May 27 06:39:01.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2406" for this suite.

• [SLOW TEST:6.413 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":244,"skipped":4741,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:39:01.736: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pods
May 27 06:39:01.803: INFO: created test-pod-1
May 27 06:39:01.820: INFO: created test-pod-2
May 27 06:39:01.832: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running
May 27 06:39:01.832: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-3441' to be running and ready
May 27 06:39:01.879: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 27 06:39:01.879: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 27 06:39:01.879: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 27 06:39:01.879: INFO: 0 / 3 pods in namespace 'pods-3441' are running and ready (0 seconds elapsed)
May 27 06:39:01.879: INFO: expected 0 pod replicas in namespace 'pods-3441', 0 are Running and Ready.
May 27 06:39:01.879: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
May 27 06:39:01.879: INFO: test-pod-1  bohc9zohd7ee-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC  }]
May 27 06:39:01.879: INFO: test-pod-2  bohc9zohd7ee-3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC  }]
May 27 06:39:01.879: INFO: test-pod-3  bohc9zohd7ee-3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC  }]
May 27 06:39:01.879: INFO: 
May 27 06:39:03.914: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 27 06:39:03.914: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 27 06:39:03.914: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 27 06:39:03.914: INFO: 0 / 3 pods in namespace 'pods-3441' are running and ready (2 seconds elapsed)
May 27 06:39:03.914: INFO: expected 0 pod replicas in namespace 'pods-3441', 0 are Running and Ready.
May 27 06:39:03.914: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
May 27 06:39:03.914: INFO: test-pod-1  bohc9zohd7ee-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC  }]
May 27 06:39:03.914: INFO: test-pod-2  bohc9zohd7ee-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC  }]
May 27 06:39:03.914: INFO: test-pod-3  bohc9zohd7ee-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-05-27 06:39:01 +0000 UTC  }]
May 27 06:39:03.914: INFO: 
May 27 06:39:05.901: INFO: 3 / 3 pods in namespace 'pods-3441' are running and ready (4 seconds elapsed)
May 27 06:39:05.901: INFO: expected 0 pod replicas in namespace 'pods-3441', 0 are Running and Ready.
STEP: waiting for all pods to be deleted
May 27 06:39:05.966: INFO: Pod quantity 3 is different from expected quantity 0
May 27 06:39:06.973: INFO: Pod quantity 3 is different from expected quantity 0
May 27 06:39:07.977: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
May 27 06:39:08.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3441" for this suite.

• [SLOW TEST:7.271 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","total":356,"completed":245,"skipped":4760,"failed":0}
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:39:09.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-7f518a9e-3d2b-4de4-bed2-05d81104f7d5
STEP: Creating a pod to test consume secrets
May 27 06:39:09.073: INFO: Waiting up to 5m0s for pod "pod-secrets-1889887a-cf00-4833-b99d-2b8a246f7294" in namespace "secrets-4530" to be "Succeeded or Failed"
May 27 06:39:09.081: INFO: Pod "pod-secrets-1889887a-cf00-4833-b99d-2b8a246f7294": Phase="Pending", Reason="", readiness=false. Elapsed: 7.466693ms
May 27 06:39:11.095: INFO: Pod "pod-secrets-1889887a-cf00-4833-b99d-2b8a246f7294": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021874599s
May 27 06:39:13.114: INFO: Pod "pod-secrets-1889887a-cf00-4833-b99d-2b8a246f7294": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040627072s
May 27 06:39:15.124: INFO: Pod "pod-secrets-1889887a-cf00-4833-b99d-2b8a246f7294": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050515799s
STEP: Saw pod success
May 27 06:39:15.124: INFO: Pod "pod-secrets-1889887a-cf00-4833-b99d-2b8a246f7294" satisfied condition "Succeeded or Failed"
May 27 06:39:15.129: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-secrets-1889887a-cf00-4833-b99d-2b8a246f7294 container secret-volume-test: <nil>
STEP: delete the pod
May 27 06:39:15.166: INFO: Waiting for pod pod-secrets-1889887a-cf00-4833-b99d-2b8a246f7294 to disappear
May 27 06:39:15.171: INFO: Pod pod-secrets-1889887a-cf00-4833-b99d-2b8a246f7294 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
May 27 06:39:15.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4530" for this suite.

• [SLOW TEST:6.185 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":246,"skipped":4760,"failed":0}
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:39:15.193: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
May 27 06:39:15.242: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
May 27 06:39:19.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7383" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":356,"completed":247,"skipped":4765,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:39:19.238: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating pod
May 27 06:39:19.341: INFO: The status of Pod pod-hostip-0d46183e-adb5-427b-b3bf-aedac8c493b3 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:39:21.352: INFO: The status of Pod pod-hostip-0d46183e-adb5-427b-b3bf-aedac8c493b3 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:39:23.354: INFO: The status of Pod pod-hostip-0d46183e-adb5-427b-b3bf-aedac8c493b3 is Running (Ready = true)
May 27 06:39:23.368: INFO: Pod pod-hostip-0d46183e-adb5-427b-b3bf-aedac8c493b3 has hostIP: 192.168.121.16
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
May 27 06:39:23.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6160" for this suite.
•{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","total":356,"completed":248,"skipped":4778,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:39:23.390: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-3193a9ff-0dff-4263-921b-abd072c0bfb6
STEP: Creating a pod to test consume secrets
May 27 06:39:23.508: INFO: Waiting up to 5m0s for pod "pod-secrets-7c3116de-354f-4b81-8cef-4f8ca2960b26" in namespace "secrets-2805" to be "Succeeded or Failed"
May 27 06:39:23.515: INFO: Pod "pod-secrets-7c3116de-354f-4b81-8cef-4f8ca2960b26": Phase="Pending", Reason="", readiness=false. Elapsed: 6.731293ms
May 27 06:39:25.526: INFO: Pod "pod-secrets-7c3116de-354f-4b81-8cef-4f8ca2960b26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017372666s
May 27 06:39:27.542: INFO: Pod "pod-secrets-7c3116de-354f-4b81-8cef-4f8ca2960b26": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033268988s
May 27 06:39:29.553: INFO: Pod "pod-secrets-7c3116de-354f-4b81-8cef-4f8ca2960b26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04444907s
STEP: Saw pod success
May 27 06:39:29.553: INFO: Pod "pod-secrets-7c3116de-354f-4b81-8cef-4f8ca2960b26" satisfied condition "Succeeded or Failed"
May 27 06:39:29.560: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-secrets-7c3116de-354f-4b81-8cef-4f8ca2960b26 container secret-volume-test: <nil>
STEP: delete the pod
May 27 06:39:29.605: INFO: Waiting for pod pod-secrets-7c3116de-354f-4b81-8cef-4f8ca2960b26 to disappear
May 27 06:39:29.610: INFO: Pod pod-secrets-7c3116de-354f-4b81-8cef-4f8ca2960b26 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
May 27 06:39:29.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2805" for this suite.
STEP: Destroying namespace "secret-namespace-1593" for this suite.

• [SLOW TEST:6.262 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":356,"completed":249,"skipped":4791,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:39:29.659: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:39:29.710: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: creating the pod
STEP: submitting the pod to kubernetes
May 27 06:39:29.748: INFO: The status of Pod pod-exec-websocket-fb593899-1604-4ed1-b49d-213883ab1d00 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:39:31.762: INFO: The status of Pod pod-exec-websocket-fb593899-1604-4ed1-b49d-213883ab1d00 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:39:33.763: INFO: The status of Pod pod-exec-websocket-fb593899-1604-4ed1-b49d-213883ab1d00 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
May 27 06:39:33.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6807" for this suite.
•{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":356,"completed":250,"skipped":4820,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff 
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:39:33.924: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
STEP: create deployment with httpd image
May 27 06:39:33.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-1361 create -f -'
May 27 06:39:35.590: INFO: stderr: ""
May 27 06:39:35.590: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
May 27 06:39:35.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-1361 diff -f -'
May 27 06:39:36.023: INFO: rc: 1
May 27 06:39:36.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-1361 delete -f -'
May 27 06:39:36.214: INFO: stderr: ""
May 27 06:39:36.214: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:39:36.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1361" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":356,"completed":251,"skipped":4851,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:39:36.254: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 06:39:36.309: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8370eaf0-9023-441f-9288-0fd574632104" in namespace "projected-1204" to be "Succeeded or Failed"
May 27 06:39:36.322: INFO: Pod "downwardapi-volume-8370eaf0-9023-441f-9288-0fd574632104": Phase="Pending", Reason="", readiness=false. Elapsed: 11.896445ms
May 27 06:39:38.338: INFO: Pod "downwardapi-volume-8370eaf0-9023-441f-9288-0fd574632104": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02816121s
May 27 06:39:40.346: INFO: Pod "downwardapi-volume-8370eaf0-9023-441f-9288-0fd574632104": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036755434s
May 27 06:39:42.362: INFO: Pod "downwardapi-volume-8370eaf0-9023-441f-9288-0fd574632104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.051901922s
May 27 06:39:44.372: INFO: Pod "downwardapi-volume-8370eaf0-9023-441f-9288-0fd574632104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.062438748s
STEP: Saw pod success
May 27 06:39:44.372: INFO: Pod "downwardapi-volume-8370eaf0-9023-441f-9288-0fd574632104" satisfied condition "Succeeded or Failed"
May 27 06:39:44.378: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-8370eaf0-9023-441f-9288-0fd574632104 container client-container: <nil>
STEP: delete the pod
May 27 06:39:44.446: INFO: Waiting for pod downwardapi-volume-8370eaf0-9023-441f-9288-0fd574632104 to disappear
May 27 06:39:44.453: INFO: Pod downwardapi-volume-8370eaf0-9023-441f-9288-0fd574632104 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
May 27 06:39:44.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1204" for this suite.

• [SLOW TEST:8.230 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":252,"skipped":4853,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:39:44.485: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
May 27 06:39:44.601: INFO: namespace kubectl-4908
May 27 06:39:44.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-4908 create -f -'
May 27 06:39:44.949: INFO: stderr: ""
May 27 06:39:44.949: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
May 27 06:39:46.029: INFO: Selector matched 1 pods for map[app:agnhost]
May 27 06:39:46.029: INFO: Found 0 / 1
May 27 06:39:46.959: INFO: Selector matched 1 pods for map[app:agnhost]
May 27 06:39:46.959: INFO: Found 1 / 1
May 27 06:39:46.960: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 27 06:39:46.966: INFO: Selector matched 1 pods for map[app:agnhost]
May 27 06:39:46.966: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 27 06:39:46.966: INFO: wait on agnhost-primary startup in kubectl-4908 
May 27 06:39:46.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-4908 logs agnhost-primary-cnjz9 agnhost-primary'
May 27 06:39:47.122: INFO: stderr: ""
May 27 06:39:47.122: INFO: stdout: "Paused\n"
STEP: exposing RC
May 27 06:39:47.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-4908 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
May 27 06:39:47.327: INFO: stderr: ""
May 27 06:39:47.327: INFO: stdout: "service/rm2 exposed\n"
May 27 06:39:47.335: INFO: Service rm2 in namespace kubectl-4908 found.
STEP: exposing service
May 27 06:39:49.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-4908 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
May 27 06:39:49.550: INFO: stderr: ""
May 27 06:39:49.550: INFO: stdout: "service/rm3 exposed\n"
May 27 06:39:49.604: INFO: Service rm3 in namespace kubectl-4908 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:39:51.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4908" for this suite.

• [SLOW TEST:7.161 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1249
    should create services for rc  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":356,"completed":253,"skipped":4855,"failed":0}
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:39:51.646: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
May 27 06:39:51.751: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May 27 06:39:53.768: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May 27 06:39:55.768: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
May 27 06:39:55.796: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
May 27 06:39:57.825: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
May 27 06:39:59.807: INFO: The status of Pod pod-with-poststart-exec-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 27 06:39:59.861: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 27 06:39:59.868: INFO: Pod pod-with-poststart-exec-hook still exists
May 27 06:40:01.869: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 27 06:40:01.885: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
May 27 06:40:01.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9748" for this suite.

• [SLOW TEST:10.258 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":356,"completed":254,"skipped":4859,"failed":0}
S
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:40:01.906: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching services
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 06:40:01.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8223" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":356,"completed":255,"skipped":4860,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:40:01.991: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
STEP: waiting for Deployment to be created
STEP: waiting for all Replicas to be Ready
May 27 06:40:02.104: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May 27 06:40:02.104: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May 27 06:40:02.162: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May 27 06:40:02.162: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May 27 06:40:02.217: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May 27 06:40:02.217: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May 27 06:40:02.348: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May 27 06:40:02.348: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May 27 06:40:04.360: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1 and labels map[test-deployment-static:true]
May 27 06:40:04.360: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1 and labels map[test-deployment-static:true]
May 27 06:40:04.702: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment
May 27 06:40:04.726: INFO: observed event type ADDED
STEP: waiting for Replicas to scale
May 27 06:40:04.729: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0
May 27 06:40:04.729: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0
May 27 06:40:04.729: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0
May 27 06:40:04.729: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0
May 27 06:40:04.729: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0
May 27 06:40:04.729: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0
May 27 06:40:04.729: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0
May 27 06:40:04.729: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 0
May 27 06:40:04.730: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:04.730: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:04.730: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:04.730: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:04.730: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:04.730: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:04.770: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:04.770: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:04.833: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:04.833: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:04.874: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:04.874: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:04.926: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:04.926: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:07.839: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:07.840: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:07.943: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
STEP: listing Deployments
May 27 06:40:07.965: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment
May 27 06:40:08.013: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
STEP: fetching the DeploymentStatus
May 27 06:40:08.045: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May 27 06:40:08.045: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May 27 06:40:08.161: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May 27 06:40:08.288: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May 27 06:40:08.334: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May 27 06:40:08.347: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May 27 06:40:10.295: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
May 27 06:40:10.357: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
May 27 06:40:10.418: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
May 27 06:40:10.474: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
May 27 06:40:10.502: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
May 27 06:40:12.803: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus
STEP: fetching the DeploymentStatus
May 27 06:40:12.948: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:12.949: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:12.949: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:12.949: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:12.949: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:12.950: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 1
May 27 06:40:12.950: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:12.950: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:12.951: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:12.951: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:12.951: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 2
May 27 06:40:12.951: INFO: observed Deployment test-deployment in namespace deployment-4941 with ReadyReplicas 3
STEP: deleting the Deployment
May 27 06:40:12.986: INFO: observed event type MODIFIED
May 27 06:40:12.987: INFO: observed event type MODIFIED
May 27 06:40:12.987: INFO: observed event type MODIFIED
May 27 06:40:12.988: INFO: observed event type MODIFIED
May 27 06:40:12.988: INFO: observed event type MODIFIED
May 27 06:40:12.989: INFO: observed event type MODIFIED
May 27 06:40:12.989: INFO: observed event type MODIFIED
May 27 06:40:12.989: INFO: observed event type MODIFIED
May 27 06:40:12.989: INFO: observed event type MODIFIED
May 27 06:40:12.989: INFO: observed event type MODIFIED
May 27 06:40:12.990: INFO: observed event type MODIFIED
May 27 06:40:12.990: INFO: observed event type MODIFIED
May 27 06:40:12.990: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May 27 06:40:13.008: INFO: Log out all the ReplicaSets if there is no deployment created
May 27 06:40:13.019: INFO: ReplicaSet "test-deployment-6bdc46c995":
&ReplicaSet{ObjectMeta:{test-deployment-6bdc46c995  deployment-4941  6a9989bf-9bde-4ea1-93d5-758476a42692 31148 3 2022-05-27 06:40:02 +0000 UTC <nil> <nil> map[pod-template-hash:6bdc46c995 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 0e8105d6-fdca-4284-bb77-b9283aeebdf5 0xc003ea0d97 0xc003ea0d98}] []  [{kube-controller-manager Update apps/v1 2022-05-27 06:40:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0e8105d6-fdca-4284-bb77-b9283aeebdf5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 06:40:07 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 6bdc46c995,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:6bdc46c995 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/agnhost:2.36 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ea0e50 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

May 27 06:40:13.035: INFO: ReplicaSet "test-deployment-74c6dd549b":
&ReplicaSet{ObjectMeta:{test-deployment-74c6dd549b  deployment-4941  4ad398ca-efe7-4e86-a7ec-8182415f1fa0 31234 2 2022-05-27 06:40:08 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 0e8105d6-fdca-4284-bb77-b9283aeebdf5 0xc003ea0ee7 0xc003ea0ee8}] []  [{kube-controller-manager Update apps/v1 2022-05-27 06:40:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0e8105d6-fdca-4284-bb77-b9283aeebdf5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 06:40:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 74c6dd549b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ea0fd0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

May 27 06:40:13.061: INFO: pod: "test-deployment-74c6dd549b-6kwd7":
&Pod{ObjectMeta:{test-deployment-74c6dd549b-6kwd7 test-deployment-74c6dd549b- deployment-4941  d0f1a23c-c871-4768-87db-3da45ddf398d 31233 0 2022-05-27 06:40:10 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-74c6dd549b 4ad398ca-efe7-4e86-a7ec-8182415f1fa0 0xc003ea1887 0xc003ea1888}] []  [{kube-controller-manager Update v1 2022-05-27 06:40:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4ad398ca-efe7-4e86-a7ec-8182415f1fa0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 06:40:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.60\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z9mr9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z9mr9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.180,PodIP:10.233.66.60,StartTime:2022-05-27 06:40:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 06:40:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://a65685ec2631ac1d53922eb50a785dd3e9a7bb390e2cfc2a3eb0bb73d59e390e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

May 27 06:40:13.065: INFO: pod: "test-deployment-74c6dd549b-9cz7v":
&Pod{ObjectMeta:{test-deployment-74c6dd549b-9cz7v test-deployment-74c6dd549b- deployment-4941  7ee52ad8-40e7-4dc6-8cdb-b45505b3c1cf 31191 0 2022-05-27 06:40:08 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-74c6dd549b 4ad398ca-efe7-4e86-a7ec-8182415f1fa0 0xc003ea1bb7 0xc003ea1bb8}] []  [{kube-controller-manager Update v1 2022-05-27 06:40:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4ad398ca-efe7-4e86-a7ec-8182415f1fa0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 06:40:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.135\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wftg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wftg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.16,PodIP:10.233.65.135,StartTime:2022-05-27 06:40:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 06:40:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://026b0076310571da04611494dd11650fe3187854b685a9617d5288dbd8c2fd95,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.135,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

May 27 06:40:13.066: INFO: ReplicaSet "test-deployment-84b949bdfc":
&ReplicaSet{ObjectMeta:{test-deployment-84b949bdfc  deployment-4941  72f6b19d-c25f-4387-acc0-d5637f2a9288 31242 4 2022-05-27 06:40:04 +0000 UTC <nil> <nil> map[pod-template-hash:84b949bdfc test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 0e8105d6-fdca-4284-bb77-b9283aeebdf5 0xc003ea1067 0xc003ea1068}] []  [{kube-controller-manager Update apps/v1 2022-05-27 06:40:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0e8105d6-fdca-4284-bb77-b9283aeebdf5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-05-27 06:40:12 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 84b949bdfc,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:84b949bdfc test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/pause:3.7 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ea1110 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

May 27 06:40:13.080: INFO: pod: "test-deployment-84b949bdfc-d4jqr":
&Pod{ObjectMeta:{test-deployment-84b949bdfc-d4jqr test-deployment-84b949bdfc- deployment-4941  a25d811f-239f-461d-8d0c-84955ed02056 31238 0 2022-05-27 06:40:04 +0000 UTC 2022-05-27 06:40:13 +0000 UTC 0xc003ebfb50 map[pod-template-hash:84b949bdfc test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-84b949bdfc 72f6b19d-c25f-4387-acc0-d5637f2a9288 0xc003ebfb87 0xc003ebfb88}] []  [{kube-controller-manager Update v1 2022-05-27 06:40:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72f6b19d-c25f-4387-acc0-d5637f2a9288\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-05-27 06:40:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.70\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-76xf4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.7,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-76xf4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bohc9zohd7ee-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-05-27 06:40:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.16,PodIP:10.233.65.70,StartTime:2022-05-27 06:40:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-05-27 06:40:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.7,ImageID:k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c,ContainerID:cri-o://f82e060348452ba2df2cd712f4fe7783a2bd6ef09c83b0a19e971757d1be0e96,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.70,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
May 27 06:40:13.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4941" for this suite.

• [SLOW TEST:11.135 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","total":356,"completed":256,"skipped":4945,"failed":0}
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:40:13.127: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:40:13.249: INFO: created pod pod-service-account-defaultsa
May 27 06:40:13.249: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 27 06:40:13.272: INFO: created pod pod-service-account-mountsa
May 27 06:40:13.273: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 27 06:40:13.294: INFO: created pod pod-service-account-nomountsa
May 27 06:40:13.294: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 27 06:40:13.310: INFO: created pod pod-service-account-defaultsa-mountspec
May 27 06:40:13.310: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 27 06:40:13.320: INFO: created pod pod-service-account-mountsa-mountspec
May 27 06:40:13.320: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 27 06:40:13.351: INFO: created pod pod-service-account-nomountsa-mountspec
May 27 06:40:13.351: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 27 06:40:13.361: INFO: created pod pod-service-account-defaultsa-nomountspec
May 27 06:40:13.361: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 27 06:40:13.375: INFO: created pod pod-service-account-mountsa-nomountspec
May 27 06:40:13.375: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 27 06:40:13.387: INFO: created pod pod-service-account-nomountsa-nomountspec
May 27 06:40:13.387: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
May 27 06:40:13.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2303" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":356,"completed":257,"skipped":4952,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:40:13.430: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Deleting RuntimeClass runtimeclass-5434-delete-me
STEP: Waiting for the RuntimeClass to disappear
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
May 27 06:40:13.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-5434" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":258,"skipped":4975,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:40:13.582: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-4c634e01-0d34-4e3e-81e5-9da769b320f1
STEP: Creating a pod to test consume configMaps
May 27 06:40:13.694: INFO: Waiting up to 5m0s for pod "pod-configmaps-c3f92c6f-0529-4539-bcb4-66e453236240" in namespace "configmap-917" to be "Succeeded or Failed"
May 27 06:40:13.703: INFO: Pod "pod-configmaps-c3f92c6f-0529-4539-bcb4-66e453236240": Phase="Pending", Reason="", readiness=false. Elapsed: 8.997695ms
May 27 06:40:15.831: INFO: Pod "pod-configmaps-c3f92c6f-0529-4539-bcb4-66e453236240": Phase="Pending", Reason="", readiness=false. Elapsed: 2.136743444s
May 27 06:40:17.854: INFO: Pod "pod-configmaps-c3f92c6f-0529-4539-bcb4-66e453236240": Phase="Pending", Reason="", readiness=false. Elapsed: 4.160255635s
May 27 06:40:19.865: INFO: Pod "pod-configmaps-c3f92c6f-0529-4539-bcb4-66e453236240": Phase="Pending", Reason="", readiness=false. Elapsed: 6.170636214s
May 27 06:40:21.882: INFO: Pod "pod-configmaps-c3f92c6f-0529-4539-bcb4-66e453236240": Phase="Pending", Reason="", readiness=false. Elapsed: 8.187634078s
May 27 06:40:23.895: INFO: Pod "pod-configmaps-c3f92c6f-0529-4539-bcb4-66e453236240": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.200907879s
STEP: Saw pod success
May 27 06:40:23.895: INFO: Pod "pod-configmaps-c3f92c6f-0529-4539-bcb4-66e453236240" satisfied condition "Succeeded or Failed"
May 27 06:40:23.901: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-configmaps-c3f92c6f-0529-4539-bcb4-66e453236240 container agnhost-container: <nil>
STEP: delete the pod
May 27 06:40:23.949: INFO: Waiting for pod pod-configmaps-c3f92c6f-0529-4539-bcb4-66e453236240 to disappear
May 27 06:40:23.954: INFO: Pod pod-configmaps-c3f92c6f-0529-4539-bcb4-66e453236240 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
May 27 06:40:23.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-917" for this suite.

• [SLOW TEST:10.388 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":259,"skipped":4989,"failed":0}
SSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:40:23.971: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test env composition
May 27 06:40:24.040: INFO: Waiting up to 5m0s for pod "var-expansion-8cf35dde-7a59-4f15-9867-0cf636abc2e9" in namespace "var-expansion-2277" to be "Succeeded or Failed"
May 27 06:40:24.077: INFO: Pod "var-expansion-8cf35dde-7a59-4f15-9867-0cf636abc2e9": Phase="Pending", Reason="", readiness=false. Elapsed: 37.828811ms
May 27 06:40:26.096: INFO: Pod "var-expansion-8cf35dde-7a59-4f15-9867-0cf636abc2e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056677591s
May 27 06:40:28.214: INFO: Pod "var-expansion-8cf35dde-7a59-4f15-9867-0cf636abc2e9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.174552033s
May 27 06:40:30.225: INFO: Pod "var-expansion-8cf35dde-7a59-4f15-9867-0cf636abc2e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.185629322s
STEP: Saw pod success
May 27 06:40:30.225: INFO: Pod "var-expansion-8cf35dde-7a59-4f15-9867-0cf636abc2e9" satisfied condition "Succeeded or Failed"
May 27 06:40:30.232: INFO: Trying to get logs from node bohc9zohd7ee-1 pod var-expansion-8cf35dde-7a59-4f15-9867-0cf636abc2e9 container dapi-container: <nil>
STEP: delete the pod
May 27 06:40:30.305: INFO: Waiting for pod var-expansion-8cf35dde-7a59-4f15-9867-0cf636abc2e9 to disappear
May 27 06:40:30.311: INFO: Pod var-expansion-8cf35dde-7a59-4f15-9867-0cf636abc2e9 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
May 27 06:40:30.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2277" for this suite.

• [SLOW TEST:6.362 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":356,"completed":260,"skipped":4994,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:40:30.337: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:40:30.409: INFO: Creating ReplicaSet my-hostname-basic-acf810f4-9444-41b2-8f94-0aee022f3989
May 27 06:40:30.437: INFO: Pod name my-hostname-basic-acf810f4-9444-41b2-8f94-0aee022f3989: Found 0 pods out of 1
May 27 06:40:35.446: INFO: Pod name my-hostname-basic-acf810f4-9444-41b2-8f94-0aee022f3989: Found 1 pods out of 1
May 27 06:40:35.446: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-acf810f4-9444-41b2-8f94-0aee022f3989" is running
May 27 06:40:35.453: INFO: Pod "my-hostname-basic-acf810f4-9444-41b2-8f94-0aee022f3989-6bfbj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-27 06:40:30 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-27 06:40:32 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-27 06:40:32 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-05-27 06:40:30 +0000 UTC Reason: Message:}])
May 27 06:40:35.453: INFO: Trying to dial the pod
May 27 06:40:40.485: INFO: Controller my-hostname-basic-acf810f4-9444-41b2-8f94-0aee022f3989: Got expected result from replica 1 [my-hostname-basic-acf810f4-9444-41b2-8f94-0aee022f3989-6bfbj]: "my-hostname-basic-acf810f4-9444-41b2-8f94-0aee022f3989-6bfbj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
May 27 06:40:40.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6743" for this suite.

• [SLOW TEST:10.179 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":261,"skipped":5013,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:40:40.516: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on node default medium
May 27 06:40:40.592: INFO: Waiting up to 5m0s for pod "pod-318d94d3-3d3c-44e0-b6ec-02210345cd48" in namespace "emptydir-1357" to be "Succeeded or Failed"
May 27 06:40:40.615: INFO: Pod "pod-318d94d3-3d3c-44e0-b6ec-02210345cd48": Phase="Pending", Reason="", readiness=false. Elapsed: 23.368263ms
May 27 06:40:42.624: INFO: Pod "pod-318d94d3-3d3c-44e0-b6ec-02210345cd48": Phase="Running", Reason="", readiness=true. Elapsed: 2.031446638s
May 27 06:40:44.641: INFO: Pod "pod-318d94d3-3d3c-44e0-b6ec-02210345cd48": Phase="Running", Reason="", readiness=false. Elapsed: 4.048616319s
May 27 06:40:46.655: INFO: Pod "pod-318d94d3-3d3c-44e0-b6ec-02210345cd48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.06328643s
STEP: Saw pod success
May 27 06:40:46.655: INFO: Pod "pod-318d94d3-3d3c-44e0-b6ec-02210345cd48" satisfied condition "Succeeded or Failed"
May 27 06:40:46.662: INFO: Trying to get logs from node bohc9zohd7ee-1 pod pod-318d94d3-3d3c-44e0-b6ec-02210345cd48 container test-container: <nil>
STEP: delete the pod
May 27 06:40:46.701: INFO: Waiting for pod pod-318d94d3-3d3c-44e0-b6ec-02210345cd48 to disappear
May 27 06:40:46.710: INFO: Pod pod-318d94d3-3d3c-44e0-b6ec-02210345cd48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 06:40:46.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1357" for this suite.

• [SLOW TEST:6.224 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":262,"skipped":5015,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:40:46.742: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9138
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:40:46.861: INFO: Found 0 stateful pods, waiting for 1
May 27 06:40:56.884: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet
May 27 06:40:56.958: INFO: Found 1 stateful pods, waiting for 2
May 27 06:41:06.977: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 27 06:41:06.977: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets
STEP: Delete all of the StatefulSets
STEP: Verify that StatefulSets have been deleted
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May 27 06:41:07.024: INFO: Deleting all statefulset in ns statefulset-9138
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
May 27 06:41:07.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9138" for this suite.

• [SLOW TEST:20.337 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","total":356,"completed":263,"skipped":5045,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:41:07.081: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:41:07.219: INFO: created pod
May 27 06:41:07.219: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-8176" to be "Succeeded or Failed"
May 27 06:41:07.230: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.390334ms
May 27 06:41:09.464: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.245072018s
May 27 06:41:11.473: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.254194108s
May 27 06:41:13.486: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.267139356s
STEP: Saw pod success
May 27 06:41:13.486: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
May 27 06:41:43.490: INFO: polling logs
May 27 06:41:43.594: INFO: Pod logs: 
I0527 06:41:10.251843       1 log.go:195] OK: Got token
I0527 06:41:10.251935       1 log.go:195] validating with in-cluster discovery
I0527 06:41:10.254437       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I0527 06:41:10.254539       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-8176:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1653634268, NotBefore:1653633668, IssuedAt:1653633668, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8176", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"841da737-f483-4123-9f19-92605a2ec948"}}}
I0527 06:41:10.289425       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I0527 06:41:10.302745       1 log.go:195] OK: Validated signature on JWT
I0527 06:41:10.302912       1 log.go:195] OK: Got valid claims from token!
I0527 06:41:10.302949       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-8176:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1653634268, NotBefore:1653633668, IssuedAt:1653633668, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8176", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"841da737-f483-4123-9f19-92605a2ec948"}}}

May 27 06:41:43.595: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
May 27 06:41:43.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8176" for this suite.

• [SLOW TEST:36.582 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","total":356,"completed":264,"skipped":5067,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:41:43.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 06:41:43.819: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e5cd53b3-6593-42a8-aa44-bc55cf4cc496" in namespace "projected-3407" to be "Succeeded or Failed"
May 27 06:41:43.846: INFO: Pod "downwardapi-volume-e5cd53b3-6593-42a8-aa44-bc55cf4cc496": Phase="Pending", Reason="", readiness=false. Elapsed: 27.542341ms
May 27 06:41:45.867: INFO: Pod "downwardapi-volume-e5cd53b3-6593-42a8-aa44-bc55cf4cc496": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048118076s
May 27 06:41:47.880: INFO: Pod "downwardapi-volume-e5cd53b3-6593-42a8-aa44-bc55cf4cc496": Phase="Pending", Reason="", readiness=false. Elapsed: 4.060857123s
May 27 06:41:49.893: INFO: Pod "downwardapi-volume-e5cd53b3-6593-42a8-aa44-bc55cf4cc496": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.074075116s
STEP: Saw pod success
May 27 06:41:49.893: INFO: Pod "downwardapi-volume-e5cd53b3-6593-42a8-aa44-bc55cf4cc496" satisfied condition "Succeeded or Failed"
May 27 06:41:49.900: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-e5cd53b3-6593-42a8-aa44-bc55cf4cc496 container client-container: <nil>
STEP: delete the pod
May 27 06:41:49.953: INFO: Waiting for pod downwardapi-volume-e5cd53b3-6593-42a8-aa44-bc55cf4cc496 to disappear
May 27 06:41:49.964: INFO: Pod downwardapi-volume-e5cd53b3-6593-42a8-aa44-bc55cf4cc496 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
May 27 06:41:49.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3407" for this suite.

• [SLOW TEST:6.326 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":265,"skipped":5073,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:41:49.991: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 27 06:41:54.157: INFO: DNS probes using dns-6646/dns-test-e9b6902f-88d5-4b19-8281-0abea4fa834b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
May 27 06:41:54.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6646" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":356,"completed":266,"skipped":5076,"failed":0}
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:41:54.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 27 06:41:54.397: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 06:41:54.397: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 06:41:55.437: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 06:41:55.437: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 06:41:56.423: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 06:41:56.423: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 06:41:57.431: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May 27 06:41:57.431: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 06:41:58.415: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May 27 06:41:58.416: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status
May 27 06:41:58.436: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status
May 27 06:41:58.452: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated
May 27 06:41:58.455: INFO: Observed &DaemonSet event: ADDED
May 27 06:41:58.455: INFO: Observed &DaemonSet event: MODIFIED
May 27 06:41:58.456: INFO: Observed &DaemonSet event: MODIFIED
May 27 06:41:58.456: INFO: Observed &DaemonSet event: MODIFIED
May 27 06:41:58.456: INFO: Observed &DaemonSet event: MODIFIED
May 27 06:41:58.457: INFO: Observed &DaemonSet event: MODIFIED
May 27 06:41:58.457: INFO: Found daemon set daemon-set in namespace daemonsets-268 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
May 27 06:41:58.457: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status
STEP: watching for the daemon set status to be patched
May 27 06:41:58.473: INFO: Observed &DaemonSet event: ADDED
May 27 06:41:58.473: INFO: Observed &DaemonSet event: MODIFIED
May 27 06:41:58.474: INFO: Observed &DaemonSet event: MODIFIED
May 27 06:41:58.474: INFO: Observed &DaemonSet event: MODIFIED
May 27 06:41:58.474: INFO: Observed &DaemonSet event: MODIFIED
May 27 06:41:58.475: INFO: Observed &DaemonSet event: MODIFIED
May 27 06:41:58.475: INFO: Observed daemon set daemon-set in namespace daemonsets-268 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
May 27 06:41:58.475: INFO: Observed &DaemonSet event: MODIFIED
May 27 06:41:58.475: INFO: Found daemon set daemon-set in namespace daemonsets-268 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
May 27 06:41:58.475: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-268, will wait for the garbage collector to delete the pods
May 27 06:41:58.568: INFO: Deleting DaemonSet.extensions daemon-set took: 18.499468ms
May 27 06:41:58.669: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.042314ms
May 27 06:42:01.081: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 06:42:01.082: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May 27 06:42:01.086: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32034"},"items":null}

May 27 06:42:01.091: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32034"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
May 27 06:42:01.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-268" for this suite.

• [SLOW TEST:6.901 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","total":356,"completed":267,"skipped":5077,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:42:01.143: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
May 27 06:42:01.204: INFO: Waiting up to 5m0s for pod "downwardapi-volume-784c1a5a-fdcd-44fb-b262-b1d7cbc88b01" in namespace "downward-api-5659" to be "Succeeded or Failed"
May 27 06:42:01.212: INFO: Pod "downwardapi-volume-784c1a5a-fdcd-44fb-b262-b1d7cbc88b01": Phase="Pending", Reason="", readiness=false. Elapsed: 8.393319ms
May 27 06:42:03.237: INFO: Pod "downwardapi-volume-784c1a5a-fdcd-44fb-b262-b1d7cbc88b01": Phase="Running", Reason="", readiness=true. Elapsed: 2.033439979s
May 27 06:42:05.249: INFO: Pod "downwardapi-volume-784c1a5a-fdcd-44fb-b262-b1d7cbc88b01": Phase="Running", Reason="", readiness=false. Elapsed: 4.044691083s
May 27 06:42:07.262: INFO: Pod "downwardapi-volume-784c1a5a-fdcd-44fb-b262-b1d7cbc88b01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.058246911s
STEP: Saw pod success
May 27 06:42:07.262: INFO: Pod "downwardapi-volume-784c1a5a-fdcd-44fb-b262-b1d7cbc88b01" satisfied condition "Succeeded or Failed"
May 27 06:42:07.269: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downwardapi-volume-784c1a5a-fdcd-44fb-b262-b1d7cbc88b01 container client-container: <nil>
STEP: delete the pod
May 27 06:42:07.578: INFO: Waiting for pod downwardapi-volume-784c1a5a-fdcd-44fb-b262-b1d7cbc88b01 to disappear
May 27 06:42:07.586: INFO: Pod downwardapi-volume-784c1a5a-fdcd-44fb-b262-b1d7cbc88b01 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
May 27 06:42:07.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5659" for this suite.

• [SLOW TEST:6.462 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":356,"completed":268,"skipped":5131,"failed":0}
SSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:42:07.605: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:42:07.673: INFO: Endpoints addresses: [192.168.121.117 192.168.121.180] , ports: [6443]
May 27 06:42:07.674: INFO: EndpointSlices addresses: [192.168.121.117 192.168.121.180] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
May 27 06:42:07.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8294" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","total":356,"completed":269,"skipped":5138,"failed":0}
S
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:42:07.701: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption-release is created
May 27 06:42:07.801: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
May 27 06:42:09.810: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
May 27 06:42:11.814: INFO: The status of Pod pod-adoption-release is Running (Ready = true)
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 27 06:42:12.880: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
May 27 06:42:12.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3679" for this suite.

• [SLOW TEST:5.280 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":356,"completed":270,"skipped":5139,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:42:12.983: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 06:42:13.631: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 27 06:42:15.663: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 42, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 42, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 42, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 42, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 06:42:18.703: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:42:18.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1726" for this suite.
STEP: Destroying namespace "webhook-1726-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.071 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":356,"completed":271,"skipped":5146,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:42:19.055: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
STEP: referencing a single matching pod
STEP: referencing matching pods with named port
STEP: creating empty Endpoints and EndpointSlices for no matching Pods
STEP: recreating EndpointSlices after they've been deleted
May 27 06:42:39.684: INFO: EndpointSlice for Service endpointslice-3323/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
May 27 06:42:49.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-3323" for this suite.

• [SLOW TEST:30.703 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","total":356,"completed":272,"skipped":5168,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:42:49.761: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
May 27 06:42:49.846: INFO: Waiting up to 5m0s for pod "pod-234b31d4-e794-4182-917a-398d6f2f528f" in namespace "emptydir-4992" to be "Succeeded or Failed"
May 27 06:42:49.859: INFO: Pod "pod-234b31d4-e794-4182-917a-398d6f2f528f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.436919ms
May 27 06:42:51.869: INFO: Pod "pod-234b31d4-e794-4182-917a-398d6f2f528f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022910506s
May 27 06:42:53.889: INFO: Pod "pod-234b31d4-e794-4182-917a-398d6f2f528f": Phase="Running", Reason="", readiness=false. Elapsed: 4.042804682s
May 27 06:42:55.929: INFO: Pod "pod-234b31d4-e794-4182-917a-398d6f2f528f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.082858954s
STEP: Saw pod success
May 27 06:42:55.929: INFO: Pod "pod-234b31d4-e794-4182-917a-398d6f2f528f" satisfied condition "Succeeded or Failed"
May 27 06:42:55.942: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-234b31d4-e794-4182-917a-398d6f2f528f container test-container: <nil>
STEP: delete the pod
May 27 06:42:56.030: INFO: Waiting for pod pod-234b31d4-e794-4182-917a-398d6f2f528f to disappear
May 27 06:42:56.041: INFO: Pod pod-234b31d4-e794-4182-917a-398d6f2f528f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 06:42:56.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4992" for this suite.

• [SLOW TEST:6.439 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":273,"skipped":5171,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:42:56.201: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-b9de1b9b-c17b-461f-9997-3502ff69d842
STEP: Creating a pod to test consume configMaps
May 27 06:42:56.405: INFO: Waiting up to 5m0s for pod "pod-configmaps-4cc012f3-9b43-4a93-923f-1c6cc805fa2e" in namespace "configmap-8359" to be "Succeeded or Failed"
May 27 06:42:56.420: INFO: Pod "pod-configmaps-4cc012f3-9b43-4a93-923f-1c6cc805fa2e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.468926ms
May 27 06:42:58.435: INFO: Pod "pod-configmaps-4cc012f3-9b43-4a93-923f-1c6cc805fa2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029911026s
May 27 06:43:00.455: INFO: Pod "pod-configmaps-4cc012f3-9b43-4a93-923f-1c6cc805fa2e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049452213s
May 27 06:43:02.468: INFO: Pod "pod-configmaps-4cc012f3-9b43-4a93-923f-1c6cc805fa2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.062791443s
STEP: Saw pod success
May 27 06:43:02.468: INFO: Pod "pod-configmaps-4cc012f3-9b43-4a93-923f-1c6cc805fa2e" satisfied condition "Succeeded or Failed"
May 27 06:43:02.474: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-configmaps-4cc012f3-9b43-4a93-923f-1c6cc805fa2e container agnhost-container: <nil>
STEP: delete the pod
May 27 06:43:02.516: INFO: Waiting for pod pod-configmaps-4cc012f3-9b43-4a93-923f-1c6cc805fa2e to disappear
May 27 06:43:02.522: INFO: Pod pod-configmaps-4cc012f3-9b43-4a93-923f-1c6cc805fa2e no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
May 27 06:43:02.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8359" for this suite.

• [SLOW TEST:6.348 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":274,"skipped":5191,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:43:02.549: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override all
May 27 06:43:02.628: INFO: Waiting up to 5m0s for pod "client-containers-057dec20-df14-40a9-870b-3173611b2edf" in namespace "containers-7371" to be "Succeeded or Failed"
May 27 06:43:02.637: INFO: Pod "client-containers-057dec20-df14-40a9-870b-3173611b2edf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.049395ms
May 27 06:43:04.659: INFO: Pod "client-containers-057dec20-df14-40a9-870b-3173611b2edf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030913153s
May 27 06:43:06.672: INFO: Pod "client-containers-057dec20-df14-40a9-870b-3173611b2edf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043947971s
May 27 06:43:08.687: INFO: Pod "client-containers-057dec20-df14-40a9-870b-3173611b2edf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059210916s
STEP: Saw pod success
May 27 06:43:08.687: INFO: Pod "client-containers-057dec20-df14-40a9-870b-3173611b2edf" satisfied condition "Succeeded or Failed"
May 27 06:43:08.693: INFO: Trying to get logs from node bohc9zohd7ee-3 pod client-containers-057dec20-df14-40a9-870b-3173611b2edf container agnhost-container: <nil>
STEP: delete the pod
May 27 06:43:08.733: INFO: Waiting for pod client-containers-057dec20-df14-40a9-870b-3173611b2edf to disappear
May 27 06:43:08.738: INFO: Pod client-containers-057dec20-df14-40a9-870b-3173611b2edf no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
May 27 06:43:08.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7371" for this suite.

• [SLOW TEST:6.213 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":356,"completed":275,"skipped":5206,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:43:08.763: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 27 06:43:08.880: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 06:43:08.880: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 06:43:09.990: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 06:43:09.991: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 06:43:10.903: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
May 27 06:43:10.903: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 06:43:11.899: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May 27 06:43:11.899: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 27 06:43:11.954: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May 27 06:43:11.954: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8181, will wait for the garbage collector to delete the pods
May 27 06:43:13.086: INFO: Deleting DaemonSet.extensions daemon-set took: 25.819532ms
May 27 06:43:13.187: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.326368ms
May 27 06:43:15.301: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 06:43:15.301: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May 27 06:43:15.312: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32612"},"items":null}

May 27 06:43:15.334: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32613"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
May 27 06:43:15.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8181" for this suite.

• [SLOW TEST:6.640 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":356,"completed":276,"skipped":5221,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring 
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:43:15.405: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename endpointslicemirroring
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
STEP: mirroring a new custom Endpoint
May 27 06:43:15.492: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint
STEP: mirroring deletion of a custom Endpoint
May 27 06:43:17.625: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:188
May 27 06:43:19.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-9404" for this suite.
•{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","total":356,"completed":277,"skipped":5240,"failed":0}
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:43:19.661: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 27 06:43:23.791: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
May 27 06:43:23.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2390" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":278,"skipped":5244,"failed":0}
SS
------------------------------
[sig-node] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:43:23.852: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:58
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-8bb2b856-5e99-4897-98e9-a35f003f33ed in namespace container-probe-1575
May 27 06:43:27.948: INFO: Started pod busybox-8bb2b856-5e99-4897-98e9-a35f003f33ed in namespace container-probe-1575
STEP: checking the pod's current state and verifying that restartCount is present
May 27 06:43:27.954: INFO: Initial restart count of pod busybox-8bb2b856-5e99-4897-98e9-a35f003f33ed is 0
May 27 06:44:16.455: INFO: Restart count of pod container-probe-1575/busybox-8bb2b856-5e99-4897-98e9-a35f003f33ed is now 1 (48.500013269s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
May 27 06:44:16.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1575" for this suite.

• [SLOW TEST:52.671 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":279,"skipped":5246,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:44:16.524: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:44:16.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
May 27 06:44:20.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-6101 --namespace=crd-publish-openapi-6101 create -f -'
May 27 06:44:22.777: INFO: stderr: ""
May 27 06:44:22.777: INFO: stdout: "e2e-test-crd-publish-openapi-1762-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May 27 06:44:22.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-6101 --namespace=crd-publish-openapi-6101 delete e2e-test-crd-publish-openapi-1762-crds test-cr'
May 27 06:44:22.923: INFO: stderr: ""
May 27 06:44:22.923: INFO: stdout: "e2e-test-crd-publish-openapi-1762-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
May 27 06:44:22.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-6101 --namespace=crd-publish-openapi-6101 apply -f -'
May 27 06:44:24.267: INFO: stderr: ""
May 27 06:44:24.267: INFO: stdout: "e2e-test-crd-publish-openapi-1762-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May 27 06:44:24.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-6101 --namespace=crd-publish-openapi-6101 delete e2e-test-crd-publish-openapi-1762-crds test-cr'
May 27 06:44:24.521: INFO: stderr: ""
May 27 06:44:24.521: INFO: stdout: "e2e-test-crd-publish-openapi-1762-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
May 27 06:44:24.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=crd-publish-openapi-6101 explain e2e-test-crd-publish-openapi-1762-crds'
May 27 06:44:24.968: INFO: stderr: ""
May 27 06:44:24.968: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1762-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:44:29.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6101" for this suite.

• [SLOW TEST:12.737 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":356,"completed":280,"skipped":5249,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:44:29.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3155
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3155
STEP: creating replication controller externalsvc in namespace services-3155
I0527 06:44:29.420168      15 runners.go:193] Created replication controller with name: externalsvc, namespace: services-3155, replica count: 2
I0527 06:44:32.472119      15 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0527 06:44:35.472496      15 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
May 27 06:44:35.500: INFO: Creating new exec pod
May 27 06:44:39.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-3155 exec execpodh4mx4 -- /bin/sh -x -c nslookup clusterip-service.services-3155.svc.cluster.local'
May 27 06:44:40.105: INFO: stderr: "+ nslookup clusterip-service.services-3155.svc.cluster.local\n"
May 27 06:44:40.105: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-3155.svc.cluster.local\tcanonical name = externalsvc.services-3155.svc.cluster.local.\nName:\texternalsvc.services-3155.svc.cluster.local\nAddress: 10.233.35.30\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3155, will wait for the garbage collector to delete the pods
May 27 06:44:40.212: INFO: Deleting ReplicationController externalsvc took: 42.028497ms
May 27 06:44:40.313: INFO: Terminating ReplicationController externalsvc pods took: 100.610099ms
May 27 06:44:42.858: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 06:44:42.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3155" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:13.661 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":356,"completed":281,"skipped":5253,"failed":0}
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:44:42.924: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
May 27 06:44:42.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5212 create -f -'
May 27 06:44:44.313: INFO: stderr: ""
May 27 06:44:44.314: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
May 27 06:44:45.322: INFO: Selector matched 1 pods for map[app:agnhost]
May 27 06:44:45.322: INFO: Found 0 / 1
May 27 06:44:46.324: INFO: Selector matched 1 pods for map[app:agnhost]
May 27 06:44:46.324: INFO: Found 1 / 1
May 27 06:44:46.324: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 27 06:44:46.329: INFO: Selector matched 1 pods for map[app:agnhost]
May 27 06:44:46.329: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 27 06:44:46.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-5212 patch pod agnhost-primary-k5rhb -p {"metadata":{"annotations":{"x":"y"}}}'
May 27 06:44:46.545: INFO: stderr: ""
May 27 06:44:46.545: INFO: stdout: "pod/agnhost-primary-k5rhb patched\n"
STEP: checking annotations
May 27 06:44:46.554: INFO: Selector matched 1 pods for map[app:agnhost]
May 27 06:44:46.554: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:44:46.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5212" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":356,"completed":282,"skipped":5253,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:44:46.594: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:44:46.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:44:50.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1171" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":356,"completed":283,"skipped":5283,"failed":0}
SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:44:50.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
May 27 06:44:50.287: INFO: Waiting up to 5m0s for pod "downward-api-68bf90bd-eade-41f7-b7fa-6954a857f99e" in namespace "downward-api-8983" to be "Succeeded or Failed"
May 27 06:44:50.294: INFO: Pod "downward-api-68bf90bd-eade-41f7-b7fa-6954a857f99e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.15573ms
May 27 06:44:52.313: INFO: Pod "downward-api-68bf90bd-eade-41f7-b7fa-6954a857f99e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025475119s
May 27 06:44:54.337: INFO: Pod "downward-api-68bf90bd-eade-41f7-b7fa-6954a857f99e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050305335s
May 27 06:44:56.351: INFO: Pod "downward-api-68bf90bd-eade-41f7-b7fa-6954a857f99e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.064323937s
STEP: Saw pod success
May 27 06:44:56.352: INFO: Pod "downward-api-68bf90bd-eade-41f7-b7fa-6954a857f99e" satisfied condition "Succeeded or Failed"
May 27 06:44:56.359: INFO: Trying to get logs from node bohc9zohd7ee-3 pod downward-api-68bf90bd-eade-41f7-b7fa-6954a857f99e container dapi-container: <nil>
STEP: delete the pod
May 27 06:44:56.413: INFO: Waiting for pod downward-api-68bf90bd-eade-41f7-b7fa-6954a857f99e to disappear
May 27 06:44:56.420: INFO: Pod downward-api-68bf90bd-eade-41f7-b7fa-6954a857f99e no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
May 27 06:44:56.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8983" for this suite.

• [SLOW TEST:6.200 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":356,"completed":284,"skipped":5285,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:44:56.443: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a ReplicaSet
STEP: Verify that the required pods have come up
May 27 06:44:56.524: INFO: Pod name sample-pod: Found 0 pods out of 3
May 27 06:45:01.564: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running
May 27 06:45:01.575: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets
STEP: DeleteCollection of the ReplicaSets
STEP: After DeleteCollection verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
May 27 06:45:01.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5931" for this suite.

• [SLOW TEST:5.208 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","total":356,"completed":285,"skipped":5298,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:45:01.652: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating cluster-info
May 27 06:45:01.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-8696 cluster-info'
May 27 06:45:01.982: INFO: stderr: ""
May 27 06:45:01.982: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:45:01.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8696" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","total":356,"completed":286,"skipped":5303,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:45:02.028: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
May 27 06:45:04.382: INFO: running pods: 0 < 3
May 27 06:45:06.404: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
May 27 06:45:08.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1056" for this suite.

• [SLOW TEST:6.388 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","total":356,"completed":287,"skipped":5317,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:45:08.421: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-115bfd58-98b8-4015-96ad-93273b032428
STEP: Creating a pod to test consume secrets
May 27 06:45:08.485: INFO: Waiting up to 5m0s for pod "pod-secrets-7008aebe-ed2c-4048-ba24-09e1adc6761c" in namespace "secrets-3510" to be "Succeeded or Failed"
May 27 06:45:08.491: INFO: Pod "pod-secrets-7008aebe-ed2c-4048-ba24-09e1adc6761c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.918785ms
May 27 06:45:10.500: INFO: Pod "pod-secrets-7008aebe-ed2c-4048-ba24-09e1adc6761c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014845915s
May 27 06:45:12.514: INFO: Pod "pod-secrets-7008aebe-ed2c-4048-ba24-09e1adc6761c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029580431s
May 27 06:45:14.535: INFO: Pod "pod-secrets-7008aebe-ed2c-4048-ba24-09e1adc6761c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050354602s
STEP: Saw pod success
May 27 06:45:14.535: INFO: Pod "pod-secrets-7008aebe-ed2c-4048-ba24-09e1adc6761c" satisfied condition "Succeeded or Failed"
May 27 06:45:14.546: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-secrets-7008aebe-ed2c-4048-ba24-09e1adc6761c container secret-volume-test: <nil>
STEP: delete the pod
May 27 06:45:14.635: INFO: Waiting for pod pod-secrets-7008aebe-ed2c-4048-ba24-09e1adc6761c to disappear
May 27 06:45:14.650: INFO: Pod pod-secrets-7008aebe-ed2c-4048-ba24-09e1adc6761c no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
May 27 06:45:14.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3510" for this suite.

• [SLOW TEST:6.257 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":288,"skipped":5385,"failed":0}
SSS
------------------------------
[sig-node] ConfigMap 
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:45:14.678: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
May 27 06:45:14.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-52" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":356,"completed":289,"skipped":5388,"failed":0}
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:45:14.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-9b14d449-49a7-4474-96b0-c7428c2d840a
STEP: Creating a pod to test consume configMaps
May 27 06:45:14.942: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f05304d0-bb89-48f0-8490-c124a7e3c77e" in namespace "projected-5610" to be "Succeeded or Failed"
May 27 06:45:14.955: INFO: Pod "pod-projected-configmaps-f05304d0-bb89-48f0-8490-c124a7e3c77e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.454086ms
May 27 06:45:16.970: INFO: Pod "pod-projected-configmaps-f05304d0-bb89-48f0-8490-c124a7e3c77e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02823944s
May 27 06:45:18.984: INFO: Pod "pod-projected-configmaps-f05304d0-bb89-48f0-8490-c124a7e3c77e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042561777s
May 27 06:45:20.996: INFO: Pod "pod-projected-configmaps-f05304d0-bb89-48f0-8490-c124a7e3c77e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054094321s
STEP: Saw pod success
May 27 06:45:20.996: INFO: Pod "pod-projected-configmaps-f05304d0-bb89-48f0-8490-c124a7e3c77e" satisfied condition "Succeeded or Failed"
May 27 06:45:21.001: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-configmaps-f05304d0-bb89-48f0-8490-c124a7e3c77e container agnhost-container: <nil>
STEP: delete the pod
May 27 06:45:21.037: INFO: Waiting for pod pod-projected-configmaps-f05304d0-bb89-48f0-8490-c124a7e3c77e to disappear
May 27 06:45:21.046: INFO: Pod pod-projected-configmaps-f05304d0-bb89-48f0-8490-c124a7e3c77e no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
May 27 06:45:21.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5610" for this suite.

• [SLOW TEST:6.228 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":290,"skipped":5390,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:45:21.072: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-ccda8174-f417-415c-9839-5d904af1fa8d
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
May 27 06:45:25.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3009" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":291,"skipped":5404,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:45:25.413: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5403
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
May 27 06:45:25.502: INFO: Found 0 stateful pods, waiting for 3
May 27 06:45:35.522: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 27 06:45:35.522: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 27 06:45:35.522: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 27 06:45:35.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-5403 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 27 06:45:36.033: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 27 06:45:36.033: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 27 06:45:36.033: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
May 27 06:45:46.177: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 27 06:45:56.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-5403 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 27 06:45:56.826: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 27 06:45:56.826: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 27 06:45:56.826: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 27 06:46:06.877: INFO: Waiting for StatefulSet statefulset-5403/ss2 to complete update
May 27 06:46:06.877: INFO: Waiting for Pod statefulset-5403/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
May 27 06:46:06.877: INFO: Waiting for Pod statefulset-5403/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
May 27 06:46:16.908: INFO: Waiting for StatefulSet statefulset-5403/ss2 to complete update
May 27 06:46:16.908: INFO: Waiting for Pod statefulset-5403/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
May 27 06:46:26.898: INFO: Waiting for StatefulSet statefulset-5403/ss2 to complete update
May 27 06:46:36.896: INFO: Waiting for StatefulSet statefulset-5403/ss2 to complete update
STEP: Rolling back to a previous revision
May 27 06:46:46.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-5403 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 27 06:46:47.159: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 27 06:46:47.159: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 27 06:46:47.159: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 27 06:46:57.252: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 27 06:47:07.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=statefulset-5403 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 27 06:47:07.658: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 27 06:47:07.658: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 27 06:47:07.658: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 27 06:47:17.731: INFO: Waiting for StatefulSet statefulset-5403/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May 27 06:47:27.765: INFO: Deleting all statefulset in ns statefulset-5403
May 27 06:47:27.770: INFO: Scaling statefulset ss2 to 0
May 27 06:47:37.817: INFO: Waiting for statefulset status.replicas updated to 0
May 27 06:47:37.823: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
May 27 06:47:37.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5403" for this suite.

• [SLOW TEST:132.488 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":356,"completed":292,"skipped":5416,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:47:37.904: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
May 27 06:47:37.981: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-5020  367f0cee-d4d2-439a-96d4-47f870a4a392 34091 0 2022-05-27 06:47:37 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2022-05-27 06:47:37 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jlb5b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:k8s.gcr.io/e2e-test-images/agnhost:2.36,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jlb5b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 27 06:47:37.997: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
May 27 06:47:40.008: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
May 27 06:47:42.012: INFO: The status of Pod test-dns-nameservers is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
May 27 06:47:42.012: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-5020 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:42.013: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:42.014: INFO: ExecWithOptions: Clientset creation
May 27 06:47:42.014: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-5020/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod...
May 27 06:47:42.156: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-5020 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:42.157: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:42.161: INFO: ExecWithOptions: Clientset creation
May 27 06:47:42.161: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-5020/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May 27 06:47:42.396: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
May 27 06:47:42.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5020" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":356,"completed":293,"skipped":5436,"failed":0}
SSS
------------------------------
[sig-node] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:47:42.530: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
May 27 06:47:42.635: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
May 27 06:47:44.662: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
May 27 06:47:46.649: INFO: The status of Pod test-pod is Running (Ready = true)
STEP: Creating hostNetwork=true pod
May 27 06:47:46.684: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
May 27 06:47:48.696: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
May 27 06:47:50.693: INFO: The status of Pod test-host-network-pod is Running (Ready = true)
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 27 06:47:50.702: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4818 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:50.702: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:50.704: INFO: ExecWithOptions: Clientset creation
May 27 06:47:50.704: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4818/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
May 27 06:47:50.801: INFO: Exec stderr: ""
May 27 06:47:50.801: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4818 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:50.801: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:50.803: INFO: ExecWithOptions: Clientset creation
May 27 06:47:50.803: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4818/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
May 27 06:47:50.893: INFO: Exec stderr: ""
May 27 06:47:50.893: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4818 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:50.893: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:50.895: INFO: ExecWithOptions: Clientset creation
May 27 06:47:50.895: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4818/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
May 27 06:47:51.016: INFO: Exec stderr: ""
May 27 06:47:51.016: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4818 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:51.016: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:51.018: INFO: ExecWithOptions: Clientset creation
May 27 06:47:51.018: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4818/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
May 27 06:47:51.124: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 27 06:47:51.124: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4818 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:51.124: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:51.127: INFO: ExecWithOptions: Clientset creation
May 27 06:47:51.127: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4818/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
May 27 06:47:51.377: INFO: Exec stderr: ""
May 27 06:47:51.377: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4818 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:51.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:51.379: INFO: ExecWithOptions: Clientset creation
May 27 06:47:51.380: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4818/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
May 27 06:47:51.692: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 27 06:47:51.692: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4818 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:51.692: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:51.694: INFO: ExecWithOptions: Clientset creation
May 27 06:47:51.694: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4818/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
May 27 06:47:51.887: INFO: Exec stderr: ""
May 27 06:47:51.887: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4818 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:51.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:51.893: INFO: ExecWithOptions: Clientset creation
May 27 06:47:51.893: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4818/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
May 27 06:47:52.009: INFO: Exec stderr: ""
May 27 06:47:52.010: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4818 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:52.010: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:52.013: INFO: ExecWithOptions: Clientset creation
May 27 06:47:52.013: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4818/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
May 27 06:47:52.190: INFO: Exec stderr: ""
May 27 06:47:52.190: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4818 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:47:52.190: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:47:52.192: INFO: ExecWithOptions: Clientset creation
May 27 06:47:52.192: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4818/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
May 27 06:47:52.346: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:188
May 27 06:47:52.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4818" for this suite.

• [SLOW TEST:9.849 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":294,"skipped":5439,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:47:52.380: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-projected-2qcf
STEP: Creating a pod to test atomic-volume-subpath
May 27 06:47:52.521: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-2qcf" in namespace "subpath-5170" to be "Succeeded or Failed"
May 27 06:47:52.543: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Pending", Reason="", readiness=false. Elapsed: 21.357122ms
May 27 06:47:54.558: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=true. Elapsed: 2.036558772s
May 27 06:47:56.572: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=true. Elapsed: 4.050779015s
May 27 06:47:58.585: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=true. Elapsed: 6.063473521s
May 27 06:48:00.594: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=true. Elapsed: 8.072490278s
May 27 06:48:02.617: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=true. Elapsed: 10.095527147s
May 27 06:48:04.630: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=true. Elapsed: 12.109047914s
May 27 06:48:06.644: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=true. Elapsed: 14.122928464s
May 27 06:48:08.658: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=true. Elapsed: 16.136245137s
May 27 06:48:10.665: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=true. Elapsed: 18.144017662s
May 27 06:48:12.680: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=true. Elapsed: 20.158244389s
May 27 06:48:14.690: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=true. Elapsed: 22.168883153s
May 27 06:48:16.703: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Running", Reason="", readiness=false. Elapsed: 24.181733727s
May 27 06:48:18.716: INFO: Pod "pod-subpath-test-projected-2qcf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.194929466s
STEP: Saw pod success
May 27 06:48:18.716: INFO: Pod "pod-subpath-test-projected-2qcf" satisfied condition "Succeeded or Failed"
May 27 06:48:18.724: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-subpath-test-projected-2qcf container test-container-subpath-projected-2qcf: <nil>
STEP: delete the pod
May 27 06:48:18.785: INFO: Waiting for pod pod-subpath-test-projected-2qcf to disappear
May 27 06:48:18.790: INFO: Pod pod-subpath-test-projected-2qcf no longer exists
STEP: Deleting pod pod-subpath-test-projected-2qcf
May 27 06:48:18.790: INFO: Deleting pod "pod-subpath-test-projected-2qcf" in namespace "subpath-5170"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
May 27 06:48:18.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5170" for this suite.

• [SLOW TEST:26.438 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","total":356,"completed":295,"skipped":5450,"failed":0}
SSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:48:18.820: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's command
May 27 06:48:18.886: INFO: Waiting up to 5m0s for pod "var-expansion-e1ee2042-16cd-47f0-af8a-8022a638f0b1" in namespace "var-expansion-8062" to be "Succeeded or Failed"
May 27 06:48:18.891: INFO: Pod "var-expansion-e1ee2042-16cd-47f0-af8a-8022a638f0b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.866066ms
May 27 06:48:20.902: INFO: Pod "var-expansion-e1ee2042-16cd-47f0-af8a-8022a638f0b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015043583s
May 27 06:48:22.917: INFO: Pod "var-expansion-e1ee2042-16cd-47f0-af8a-8022a638f0b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030709244s
May 27 06:48:24.925: INFO: Pod "var-expansion-e1ee2042-16cd-47f0-af8a-8022a638f0b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038765145s
STEP: Saw pod success
May 27 06:48:24.925: INFO: Pod "var-expansion-e1ee2042-16cd-47f0-af8a-8022a638f0b1" satisfied condition "Succeeded or Failed"
May 27 06:48:24.930: INFO: Trying to get logs from node bohc9zohd7ee-3 pod var-expansion-e1ee2042-16cd-47f0-af8a-8022a638f0b1 container dapi-container: <nil>
STEP: delete the pod
May 27 06:48:24.962: INFO: Waiting for pod var-expansion-e1ee2042-16cd-47f0-af8a-8022a638f0b1 to disappear
May 27 06:48:24.968: INFO: Pod var-expansion-e1ee2042-16cd-47f0-af8a-8022a638f0b1 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
May 27 06:48:24.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8062" for this suite.

• [SLOW TEST:6.170 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":356,"completed":296,"skipped":5455,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:48:24.998: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service nodeport-test with type=NodePort in namespace services-2547
STEP: creating replication controller nodeport-test in namespace services-2547
I0527 06:48:25.097592      15 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-2547, replica count: 2
I0527 06:48:28.151551      15 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 27 06:48:28.151: INFO: Creating new exec pod
May 27 06:48:31.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-2547 exec execpodkz5rb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
May 27 06:48:31.807: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
May 27 06:48:31.808: INFO: stdout: "nodeport-test-sxw2f"
May 27 06:48:31.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-2547 exec execpodkz5rb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.54.103 80'
May 27 06:48:32.292: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.54.103 80\nConnection to 10.233.54.103 80 port [tcp/http] succeeded!\n"
May 27 06:48:32.292: INFO: stdout: "nodeport-test-sxw2f"
May 27 06:48:32.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-2547 exec execpodkz5rb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.16 31817'
May 27 06:48:32.563: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.16 31817\nConnection to 192.168.121.16 31817 port [tcp/*] succeeded!\n"
May 27 06:48:32.563: INFO: stdout: ""
May 27 06:48:33.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-2547 exec execpodkz5rb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.16 31817'
May 27 06:48:33.861: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.16 31817\nConnection to 192.168.121.16 31817 port [tcp/*] succeeded!\n"
May 27 06:48:33.861: INFO: stdout: "nodeport-test-sxw2f"
May 27 06:48:33.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-2547 exec execpodkz5rb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.180 31817'
May 27 06:48:34.154: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.180 31817\nConnection to 192.168.121.180 31817 port [tcp/*] succeeded!\n"
May 27 06:48:34.154: INFO: stdout: "nodeport-test-zrlm6"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 06:48:34.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2547" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:9.180 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":356,"completed":297,"skipped":5533,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:48:34.179: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
May 27 06:48:36.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2432" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","total":356,"completed":298,"skipped":5546,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:48:36.336: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
May 27 06:48:36.390: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 27 06:48:36.404: INFO: Waiting for terminating namespaces to be deleted...
May 27 06:48:36.409: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-1 before test
May 27 06:48:36.424: INFO: echo-other-node-6cd597cddc-nc274 from cilium-test started at 2022-05-27 05:12:14 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.425: INFO: 	Container echo-other-node ready: true, restart count 0
May 27 06:48:36.425: INFO: cilium-5bg94 from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.425: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:48:36.425: INFO: cilium-node-init-b2j7g from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.425: INFO: 	Container node-init ready: true, restart count 0
May 27 06:48:36.425: INFO: coredns-6d4b75cb6d-rlht9 from kube-system started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.425: INFO: 	Container coredns ready: true, restart count 0
May 27 06:48:36.425: INFO: kube-addon-manager-bohc9zohd7ee-1 from kube-system started at 2022-05-27 05:09:45 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.425: INFO: 	Container kube-addon-manager ready: true, restart count 0
May 27 06:48:36.425: INFO: kube-apiserver-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:56:59 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.425: INFO: 	Container kube-apiserver ready: true, restart count 0
May 27 06:48:36.425: INFO: kube-controller-manager-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:57:00 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.425: INFO: 	Container kube-controller-manager ready: true, restart count 0
May 27 06:48:36.425: INFO: kube-proxy-lfbdj from kube-system started at 2022-05-27 04:57:12 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.426: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:48:36.426: INFO: kube-scheduler-bohc9zohd7ee-1 from kube-system started at 2022-05-27 04:57:00 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.426: INFO: 	Container kube-scheduler ready: true, restart count 0
May 27 06:48:36.426: INFO: nodeport-test-sxw2f from services-2547 started at 2022-05-27 06:48:25 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.426: INFO: 	Container nodeport-test ready: true, restart count 0
May 27 06:48:36.426: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-wh4kx from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:48:36.426: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:48:36.426: INFO: 	Container systemd-logs ready: true, restart count 0
May 27 06:48:36.426: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-2 before test
May 27 06:48:36.444: INFO: client-7df6cfbf7b-zqjl4 from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.444: INFO: 	Container client ready: true, restart count 0
May 27 06:48:36.444: INFO: client2-547996d7d8-lrnhm from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.444: INFO: 	Container client2 ready: true, restart count 0
May 27 06:48:36.444: INFO: echo-same-node-6f4976ddbd-2v7fp from cilium-test started at 2022-05-27 05:43:00 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.444: INFO: 	Container echo-same-node ready: true, restart count 0
May 27 06:48:36.444: INFO: cilium-fcn4c from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.444: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:48:36.444: INFO: cilium-node-init-stvc7 from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.444: INFO: 	Container node-init ready: true, restart count 0
May 27 06:48:36.444: INFO: coredns-6d4b75cb6d-fhr75 from kube-system started at 2022-05-27 05:11:02 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.445: INFO: 	Container coredns ready: true, restart count 0
May 27 06:48:36.445: INFO: kube-addon-manager-bohc9zohd7ee-2 from kube-system started at 2022-05-27 05:09:45 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.445: INFO: 	Container kube-addon-manager ready: true, restart count 0
May 27 06:48:36.445: INFO: kube-apiserver-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.445: INFO: 	Container kube-apiserver ready: true, restart count 0
May 27 06:48:36.445: INFO: kube-controller-manager-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.445: INFO: 	Container kube-controller-manager ready: true, restart count 0
May 27 06:48:36.445: INFO: kube-proxy-grpx7 from kube-system started at 2022-05-27 04:57:48 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.445: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:48:36.445: INFO: kube-scheduler-bohc9zohd7ee-2 from kube-system started at 2022-05-27 04:57:57 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.445: INFO: 	Container kube-scheduler ready: true, restart count 0
May 27 06:48:36.445: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-vhrdj from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:48:36.445: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:48:36.445: INFO: 	Container systemd-logs ready: true, restart count 0
May 27 06:48:36.446: INFO: 
Logging pods the apiserver thinks is on node bohc9zohd7ee-3 before test
May 27 06:48:36.461: INFO: cilium-cdd2v from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.461: INFO: 	Container cilium-agent ready: true, restart count 0
May 27 06:48:36.461: INFO: cilium-node-init-qd8vn from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.461: INFO: 	Container node-init ready: true, restart count 0
May 27 06:48:36.461: INFO: cilium-operator-75876f779d-pzjgf from kube-system started at 2022-05-27 05:09:56 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.461: INFO: 	Container cilium-operator ready: true, restart count 0
May 27 06:48:36.462: INFO: kube-proxy-sg7pn from kube-system started at 2022-05-27 04:58:22 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.462: INFO: 	Container kube-proxy ready: true, restart count 0
May 27 06:48:36.462: INFO: test-runtimeclass-runtimeclass-2432-preconfigured-handler-q6tsk from runtimeclass-2432 started at 2022-05-27 06:48:34 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.462: INFO: 	Container test ready: false, restart count 0
May 27 06:48:36.462: INFO: execpodkz5rb from services-2547 started at 2022-05-27 06:48:28 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.462: INFO: 	Container agnhost-container ready: true, restart count 0
May 27 06:48:36.462: INFO: nodeport-test-zrlm6 from services-2547 started at 2022-05-27 06:48:25 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.462: INFO: 	Container nodeport-test ready: true, restart count 0
May 27 06:48:36.462: INFO: sonobuoy from sonobuoy started at 2022-05-27 05:16:01 +0000 UTC (1 container statuses recorded)
May 27 06:48:36.463: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 27 06:48:36.463: INFO: sonobuoy-e2e-job-117750ad95a24373 from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:48:36.463: INFO: 	Container e2e ready: true, restart count 0
May 27 06:48:36.463: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:48:36.463: INFO: sonobuoy-systemd-logs-daemon-set-3573eea6f70a4f17-2m5xp from sonobuoy started at 2022-05-27 05:16:15 +0000 UTC (2 container statuses recorded)
May 27 06:48:36.463: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 27 06:48:36.463: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-92941c6c-4a96-479e-acab-e69ff5dade09 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-92941c6c-4a96-479e-acab-e69ff5dade09 off the node bohc9zohd7ee-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-92941c6c-4a96-479e-acab-e69ff5dade09
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
May 27 06:48:42.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9498" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83

• [SLOW TEST:6.548 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":356,"completed":299,"skipped":5579,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:48:42.884: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
May 27 06:48:43.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-526" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":356,"completed":300,"skipped":5608,"failed":0}
SS
------------------------------
[sig-apps] CronJob 
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:48:43.230: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: Ensuring more than one job is running at a time
STEP: Ensuring at least two running jobs exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
May 27 06:50:01.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4290" for this suite.

• [SLOW TEST:78.224 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","total":356,"completed":301,"skipped":5610,"failed":0}
S
------------------------------
[sig-node] RuntimeClass 
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:50:01.456: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
May 27 06:50:01.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6739" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":302,"skipped":5611,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:50:01.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:58
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
May 27 06:51:01.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5166" for this suite.

• [SLOW TEST:60.108 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":356,"completed":303,"skipped":5629,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:51:01.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap that has name configmap-test-emptyKey-d187819a-5f47-4ae5-bc70-803defc50004
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
May 27 06:51:01.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4509" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":356,"completed":304,"skipped":5663,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:51:01.845: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:51:01.894: INFO: Creating pod...
May 27 06:51:05.936: INFO: Creating service...
May 27 06:51:05.969: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/pods/agnhost/proxy/some/path/with/DELETE
May 27 06:51:05.985: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
May 27 06:51:05.985: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/pods/agnhost/proxy/some/path/with/GET
May 27 06:51:05.994: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
May 27 06:51:05.995: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/pods/agnhost/proxy/some/path/with/HEAD
May 27 06:51:06.005: INFO: http.Client request:HEAD | StatusCode:200
May 27 06:51:06.005: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/pods/agnhost/proxy/some/path/with/OPTIONS
May 27 06:51:06.014: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
May 27 06:51:06.014: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/pods/agnhost/proxy/some/path/with/PATCH
May 27 06:51:06.027: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
May 27 06:51:06.027: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/pods/agnhost/proxy/some/path/with/POST
May 27 06:51:06.060: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
May 27 06:51:06.060: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/pods/agnhost/proxy/some/path/with/PUT
May 27 06:51:06.070: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
May 27 06:51:06.070: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/services/test-service/proxy/some/path/with/DELETE
May 27 06:51:06.125: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
May 27 06:51:06.125: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/services/test-service/proxy/some/path/with/GET
May 27 06:51:06.148: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
May 27 06:51:06.148: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/services/test-service/proxy/some/path/with/HEAD
May 27 06:51:06.200: INFO: http.Client request:HEAD | StatusCode:200
May 27 06:51:06.201: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/services/test-service/proxy/some/path/with/OPTIONS
May 27 06:51:06.228: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
May 27 06:51:06.228: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/services/test-service/proxy/some/path/with/PATCH
May 27 06:51:06.258: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
May 27 06:51:06.258: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/services/test-service/proxy/some/path/with/POST
May 27 06:51:06.282: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
May 27 06:51:06.282: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8357/services/test-service/proxy/some/path/with/PUT
May 27 06:51:06.301: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:188
May 27 06:51:06.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8357" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","total":356,"completed":305,"skipped":5739,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:51:06.349: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service nodeport-service with the type=NodePort in namespace services-4591
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-4591
STEP: creating replication controller externalsvc in namespace services-4591
I0527 06:51:06.533447      15 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4591, replica count: 2
I0527 06:51:09.586404      15 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0527 06:51:12.587541      15 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
May 27 06:51:12.643: INFO: Creating new exec pod
May 27 06:51:18.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-4591 exec execpodk8xt9 -- /bin/sh -x -c nslookup nodeport-service.services-4591.svc.cluster.local'
May 27 06:51:19.030: INFO: stderr: "+ nslookup nodeport-service.services-4591.svc.cluster.local\n"
May 27 06:51:19.030: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-4591.svc.cluster.local\tcanonical name = externalsvc.services-4591.svc.cluster.local.\nName:\texternalsvc.services-4591.svc.cluster.local\nAddress: 10.233.61.98\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4591, will wait for the garbage collector to delete the pods
May 27 06:51:19.107: INFO: Deleting ReplicationController externalsvc took: 13.112819ms
May 27 06:51:19.308: INFO: Terminating ReplicationController externalsvc pods took: 200.74334ms
May 27 06:51:23.196: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 06:51:23.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4591" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:16.965 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":356,"completed":306,"skipped":5744,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:51:23.317: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-6f3728b0-a69b-458d-977c-c9e773629281
STEP: Creating secret with name s-test-opt-upd-d14e80ad-dc54-4f76-9eaf-12b9eb0bea83
STEP: Creating the pod
May 27 06:51:23.465: INFO: The status of Pod pod-projected-secrets-76cba256-304d-42d3-9b8c-93c1d0e10e27 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:51:25.476: INFO: The status of Pod pod-projected-secrets-76cba256-304d-42d3-9b8c-93c1d0e10e27 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:51:27.479: INFO: The status of Pod pod-projected-secrets-76cba256-304d-42d3-9b8c-93c1d0e10e27 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-6f3728b0-a69b-458d-977c-c9e773629281
STEP: Updating secret s-test-opt-upd-d14e80ad-dc54-4f76-9eaf-12b9eb0bea83
STEP: Creating secret with name s-test-opt-create-ea9a9996-43ce-46ea-8dc3-99b071caf0bb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
May 27 06:51:29.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9408" for this suite.

• [SLOW TEST:6.585 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":307,"skipped":5750,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:51:29.903: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 27 06:51:29.996: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8173  a574a925-cfe7-489d-9c1a-5a3e3629d6b2 35234 0 2022-05-27 06:51:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-27 06:51:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 06:51:29.996: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8173  a574a925-cfe7-489d-9c1a-5a3e3629d6b2 35235 0 2022-05-27 06:51:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-27 06:51:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 06:51:29.997: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8173  a574a925-cfe7-489d-9c1a-5a3e3629d6b2 35236 0 2022-05-27 06:51:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-27 06:51:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 27 06:51:40.056: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8173  a574a925-cfe7-489d-9c1a-5a3e3629d6b2 35279 0 2022-05-27 06:51:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-27 06:51:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 06:51:40.056: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8173  a574a925-cfe7-489d-9c1a-5a3e3629d6b2 35280 0 2022-05-27 06:51:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-27 06:51:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
May 27 06:51:40.056: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8173  a574a925-cfe7-489d-9c1a-5a3e3629d6b2 35281 0 2022-05-27 06:51:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-05-27 06:51:29 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
May 27 06:51:40.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8173" for this suite.

• [SLOW TEST:10.201 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":356,"completed":308,"skipped":5787,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:51:40.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
May 27 06:52:09.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4662" for this suite.

• [SLOW TEST:29.835 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":356,"completed":309,"skipped":5829,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:52:09.945: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting the proxy server
May 27 06:52:09.997: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-644 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 06:52:10.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-644" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":356,"completed":310,"skipped":5887,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:52:10.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
May 27 06:52:26.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9072" for this suite.

• [SLOW TEST:16.446 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":356,"completed":311,"skipped":5909,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:52:26.630: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 06:52:27.858: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 27 06:52:29.958: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 52, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 52, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 52, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 52, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 06:52:32.991: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:52:33.002: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-112-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:52:36.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1274" for this suite.
STEP: Destroying namespace "webhook-1274-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:9.981 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":356,"completed":312,"skipped":5946,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:52:36.616: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
May 27 06:52:36.750: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:53:13.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7422" for this suite.

• [SLOW TEST:36.603 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":356,"completed":313,"skipped":5969,"failed":0}
SSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:53:13.219: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:53:13.270: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5227
I0527 06:53:13.292771      15 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5227, replica count: 1
I0527 06:53:14.345649      15 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0527 06:53:15.346516      15 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0527 06:53:16.347460      15 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 27 06:53:16.475: INFO: Created: latency-svc-9qw5w
May 27 06:53:16.495: INFO: Got endpoints: latency-svc-9qw5w [47.561434ms]
May 27 06:53:16.529: INFO: Created: latency-svc-rp2x4
May 27 06:53:16.555: INFO: Got endpoints: latency-svc-rp2x4 [59.540527ms]
May 27 06:53:16.590: INFO: Created: latency-svc-psjhs
May 27 06:53:16.650: INFO: Created: latency-svc-hpqxq
May 27 06:53:16.651: INFO: Got endpoints: latency-svc-psjhs [154.731895ms]
May 27 06:53:16.669: INFO: Got endpoints: latency-svc-hpqxq [172.273192ms]
May 27 06:53:16.710: INFO: Created: latency-svc-8wmxt
May 27 06:53:16.736: INFO: Got endpoints: latency-svc-8wmxt [238.84948ms]
May 27 06:53:16.751: INFO: Created: latency-svc-f7v2h
May 27 06:53:16.769: INFO: Got endpoints: latency-svc-f7v2h [272.192717ms]
May 27 06:53:16.821: INFO: Created: latency-svc-lgfng
May 27 06:53:16.835: INFO: Got endpoints: latency-svc-lgfng [337.398363ms]
May 27 06:53:16.841: INFO: Created: latency-svc-9jz7d
May 27 06:53:16.880: INFO: Got endpoints: latency-svc-9jz7d [382.043126ms]
May 27 06:53:16.922: INFO: Created: latency-svc-mcfr9
May 27 06:53:16.937: INFO: Created: latency-svc-phw6t
May 27 06:53:16.942: INFO: Got endpoints: latency-svc-mcfr9 [444.521226ms]
May 27 06:53:16.987: INFO: Got endpoints: latency-svc-phw6t [489.168679ms]
May 27 06:53:17.003: INFO: Created: latency-svc-6pl7c
May 27 06:53:17.037: INFO: Got endpoints: latency-svc-6pl7c [538.869829ms]
May 27 06:53:17.076: INFO: Created: latency-svc-tqz6q
May 27 06:53:17.104: INFO: Got endpoints: latency-svc-tqz6q [605.363913ms]
May 27 06:53:17.127: INFO: Created: latency-svc-8trbb
May 27 06:53:17.142: INFO: Got endpoints: latency-svc-8trbb [643.726267ms]
May 27 06:53:17.166: INFO: Created: latency-svc-6nkh5
May 27 06:53:17.203: INFO: Got endpoints: latency-svc-6nkh5 [703.808054ms]
May 27 06:53:17.224: INFO: Created: latency-svc-44k55
May 27 06:53:17.238: INFO: Got endpoints: latency-svc-44k55 [738.562548ms]
May 27 06:53:17.304: INFO: Created: latency-svc-fd9hp
May 27 06:53:17.338: INFO: Got endpoints: latency-svc-fd9hp [782.132783ms]
May 27 06:53:17.363: INFO: Created: latency-svc-b6v9k
May 27 06:53:17.379: INFO: Got endpoints: latency-svc-b6v9k [727.469649ms]
May 27 06:53:17.399: INFO: Created: latency-svc-p5wdq
May 27 06:53:17.412: INFO: Got endpoints: latency-svc-p5wdq [742.719634ms]
May 27 06:53:17.424: INFO: Created: latency-svc-7kpg6
May 27 06:53:17.434: INFO: Got endpoints: latency-svc-7kpg6 [698.066726ms]
May 27 06:53:17.449: INFO: Created: latency-svc-cxd67
May 27 06:53:17.455: INFO: Got endpoints: latency-svc-cxd67 [685.478083ms]
May 27 06:53:17.469: INFO: Created: latency-svc-g7m5p
May 27 06:53:17.501: INFO: Got endpoints: latency-svc-g7m5p [665.828277ms]
May 27 06:53:17.519: INFO: Created: latency-svc-w7cdc
May 27 06:53:17.523: INFO: Created: latency-svc-bxx86
May 27 06:53:17.552: INFO: Got endpoints: latency-svc-w7cdc [609.57274ms]
May 27 06:53:17.559: INFO: Created: latency-svc-h4fts
May 27 06:53:17.573: INFO: Got endpoints: latency-svc-bxx86 [585.495981ms]
May 27 06:53:17.597: INFO: Got endpoints: latency-svc-h4fts [1.098414951s]
May 27 06:53:17.619: INFO: Created: latency-svc-c6rks
May 27 06:53:17.619: INFO: Created: latency-svc-5zj45
May 27 06:53:17.619: INFO: Got endpoints: latency-svc-5zj45 [582.532681ms]
May 27 06:53:17.657: INFO: Got endpoints: latency-svc-c6rks [553.454417ms]
May 27 06:53:17.686: INFO: Created: latency-svc-n7kxj
May 27 06:53:17.715: INFO: Created: latency-svc-xmvwz
May 27 06:53:17.732: INFO: Got endpoints: latency-svc-n7kxj [589.513603ms]
May 27 06:53:17.733: INFO: Got endpoints: latency-svc-xmvwz [530.526985ms]
May 27 06:53:17.764: INFO: Created: latency-svc-svpbf
May 27 06:53:17.786: INFO: Got endpoints: latency-svc-svpbf [548.038965ms]
May 27 06:53:17.801: INFO: Created: latency-svc-p57ft
May 27 06:53:17.822: INFO: Created: latency-svc-npwwq
May 27 06:53:17.833: INFO: Got endpoints: latency-svc-p57ft [495.119985ms]
May 27 06:53:17.858: INFO: Got endpoints: latency-svc-npwwq [478.48166ms]
May 27 06:53:17.868: INFO: Created: latency-svc-xpxp9
May 27 06:53:17.885: INFO: Got endpoints: latency-svc-xpxp9 [472.935976ms]
May 27 06:53:18.161: INFO: Created: latency-svc-zbdzk
May 27 06:53:18.161: INFO: Created: latency-svc-5b92l
May 27 06:53:18.161: INFO: Created: latency-svc-8khpg
May 27 06:53:18.161: INFO: Created: latency-svc-6vbpp
May 27 06:53:18.161: INFO: Created: latency-svc-xm8qg
May 27 06:53:18.183: INFO: Created: latency-svc-ccc8z
May 27 06:53:18.184: INFO: Created: latency-svc-xj6zg
May 27 06:53:18.184: INFO: Created: latency-svc-2hfnb
May 27 06:53:18.184: INFO: Created: latency-svc-bj858
May 27 06:53:18.184: INFO: Created: latency-svc-w95l9
May 27 06:53:18.185: INFO: Created: latency-svc-kmgr2
May 27 06:53:18.185: INFO: Created: latency-svc-f6x57
May 27 06:53:18.217: INFO: Got endpoints: latency-svc-ccc8z [384.054774ms]
May 27 06:53:18.225: INFO: Created: latency-svc-jtffn
May 27 06:53:18.225: INFO: Created: latency-svc-5r6fs
May 27 06:53:18.225: INFO: Created: latency-svc-tzj5t
May 27 06:53:18.233: INFO: Got endpoints: latency-svc-xj6zg [500.964149ms]
May 27 06:53:18.253: INFO: Got endpoints: latency-svc-bj858 [633.366848ms]
May 27 06:53:18.270: INFO: Got endpoints: latency-svc-2hfnb [718.034314ms]
May 27 06:53:18.291: INFO: Created: latency-svc-ffqbr
May 27 06:53:18.303: INFO: Got endpoints: latency-svc-w95l9 [848.470874ms]
May 27 06:53:18.319: INFO: Got endpoints: latency-svc-6vbpp [884.231413ms]
May 27 06:53:18.325: INFO: Got endpoints: latency-svc-zbdzk [467.741617ms]
May 27 06:53:18.334: INFO: Created: latency-svc-gmqbx
May 27 06:53:18.353: INFO: Created: latency-svc-l4v7c
May 27 06:53:18.361: INFO: Got endpoints: latency-svc-f6x57 [475.556992ms]
May 27 06:53:18.381: INFO: Created: latency-svc-xhdtr
May 27 06:53:18.401: INFO: Created: latency-svc-rmgfq
May 27 06:53:18.413: INFO: Got endpoints: latency-svc-kmgr2 [627.187551ms]
May 27 06:53:18.431: INFO: Created: latency-svc-bz2z5
May 27 06:53:18.453: INFO: Created: latency-svc-92cbx
May 27 06:53:18.459: INFO: Got endpoints: latency-svc-5b92l [957.379326ms]
May 27 06:53:18.478: INFO: Created: latency-svc-8nwrr
May 27 06:53:18.503: INFO: Created: latency-svc-c6wsb
May 27 06:53:18.506: INFO: Created: latency-svc-svmnp
May 27 06:53:18.546: INFO: Got endpoints: latency-svc-8khpg [944.246506ms]
May 27 06:53:18.574: INFO: Created: latency-svc-9h82p
May 27 06:53:18.609: INFO: Got endpoints: latency-svc-tzj5t [1.034299863s]
May 27 06:53:18.619: INFO: Got endpoints: latency-svc-xm8qg [885.802462ms]
May 27 06:53:18.619: INFO: Got endpoints: latency-svc-5r6fs [1.739386469s]
May 27 06:53:18.667: INFO: Created: latency-svc-nvpr9
May 27 06:53:18.681: INFO: Created: latency-svc-fpzs5
May 27 06:53:18.699: INFO: Created: latency-svc-z5sfz
May 27 06:53:18.711: INFO: Got endpoints: latency-svc-jtffn [1.053676734s]
May 27 06:53:18.726: INFO: Got endpoints: latency-svc-ffqbr [509.218908ms]
May 27 06:53:18.804: INFO: Created: latency-svc-fwflx
May 27 06:53:18.804: INFO: Got endpoints: latency-svc-gmqbx [571.120468ms]
May 27 06:53:18.823: INFO: Created: latency-svc-w7j2x
May 27 06:53:18.846: INFO: Got endpoints: latency-svc-xhdtr [575.244541ms]
May 27 06:53:18.847: INFO: Got endpoints: latency-svc-l4v7c [594.391933ms]
May 27 06:53:18.879: INFO: Created: latency-svc-lsfc6
May 27 06:53:18.888: INFO: Got endpoints: latency-svc-rmgfq [584.033374ms]
May 27 06:53:18.946: INFO: Created: latency-svc-9vlnc
May 27 06:53:18.950: INFO: Got endpoints: latency-svc-bz2z5 [631.037568ms]
May 27 06:53:19.001: INFO: Got endpoints: latency-svc-8nwrr [640.264636ms]
May 27 06:53:19.002: INFO: Got endpoints: latency-svc-svmnp [588.878079ms]
May 27 06:53:19.004: INFO: Got endpoints: latency-svc-92cbx [678.512439ms]
May 27 06:53:19.004: INFO: Got endpoints: latency-svc-c6wsb [545.260221ms]
May 27 06:53:19.015: INFO: Got endpoints: latency-svc-9h82p [468.600116ms]
May 27 06:53:19.016: INFO: Created: latency-svc-tz749
May 27 06:53:19.080: INFO: Created: latency-svc-9ggfp
May 27 06:53:19.100: INFO: Got endpoints: latency-svc-fwflx [389.215969ms]
May 27 06:53:19.101: INFO: Got endpoints: latency-svc-fpzs5 [481.240592ms]
May 27 06:53:19.111: INFO: Got endpoints: latency-svc-w7j2x [384.581661ms]
May 27 06:53:19.112: INFO: Got endpoints: latency-svc-nvpr9 [502.767417ms]
May 27 06:53:19.112: INFO: Got endpoints: latency-svc-z5sfz [492.688826ms]
May 27 06:53:19.132: INFO: Created: latency-svc-24gnw
May 27 06:53:19.170: INFO: Created: latency-svc-8v9xp
May 27 06:53:19.190: INFO: Got endpoints: latency-svc-tz749 [342.259736ms]
May 27 06:53:19.190: INFO: Got endpoints: latency-svc-lsfc6 [385.732745ms]
May 27 06:53:19.191: INFO: Got endpoints: latency-svc-9ggfp [302.796919ms]
May 27 06:53:19.211: INFO: Got endpoints: latency-svc-9vlnc [364.914061ms]
May 27 06:53:19.220: INFO: Created: latency-svc-7pzzj
May 27 06:53:19.232: INFO: Got endpoints: latency-svc-24gnw [282.27596ms]
May 27 06:53:19.279: INFO: Got endpoints: latency-svc-8v9xp [278.030092ms]
May 27 06:53:19.280: INFO: Created: latency-svc-5n8jr
May 27 06:53:19.315: INFO: Got endpoints: latency-svc-7pzzj [310.946871ms]
May 27 06:53:19.328: INFO: Created: latency-svc-lcbcx
May 27 06:53:19.373: INFO: Created: latency-svc-pzbf6
May 27 06:53:19.375: INFO: Created: latency-svc-gn7xb
May 27 06:53:19.387: INFO: Got endpoints: latency-svc-5n8jr [382.709469ms]
May 27 06:53:19.391: INFO: Got endpoints: latency-svc-lcbcx [388.351011ms]
May 27 06:53:19.420: INFO: Created: latency-svc-w464s
May 27 06:53:19.435: INFO: Got endpoints: latency-svc-gn7xb [419.686535ms]
May 27 06:53:19.435: INFO: Created: latency-svc-c4ksd
May 27 06:53:19.457: INFO: Created: latency-svc-97mkl
May 27 06:53:19.466: INFO: Got endpoints: latency-svc-pzbf6 [365.139561ms]
May 27 06:53:19.472: INFO: Created: latency-svc-6wwlp
May 27 06:53:19.490: INFO: Created: latency-svc-5jjr6
May 27 06:53:19.504: INFO: Created: latency-svc-zztqj
May 27 06:53:19.517: INFO: Created: latency-svc-lzfct
May 27 06:53:19.532: INFO: Created: latency-svc-kvrxq
May 27 06:53:19.562: INFO: Got endpoints: latency-svc-w464s [461.887096ms]
May 27 06:53:19.563: INFO: Got endpoints: latency-svc-c4ksd [451.39516ms]
May 27 06:53:19.564: INFO: Created: latency-svc-rxqln
May 27 06:53:19.579: INFO: Created: latency-svc-mzbhr
May 27 06:53:19.606: INFO: Created: latency-svc-bhppt
May 27 06:53:19.626: INFO: Created: latency-svc-jzwfk
May 27 06:53:19.649: INFO: Created: latency-svc-dx754
May 27 06:53:19.653: INFO: Got endpoints: latency-svc-97mkl [540.577541ms]
May 27 06:53:19.673: INFO: Created: latency-svc-82p5x
May 27 06:53:19.693: INFO: Created: latency-svc-zmc4c
May 27 06:53:19.705: INFO: Got endpoints: latency-svc-6wwlp [592.885072ms]
May 27 06:53:19.718: INFO: Created: latency-svc-h4bh6
May 27 06:53:19.734: INFO: Got endpoints: latency-svc-5jjr6 [544.138185ms]
May 27 06:53:19.756: INFO: Created: latency-svc-g4qxs
May 27 06:53:19.764: INFO: Got endpoints: latency-svc-zztqj [574.269434ms]
May 27 06:53:19.767: INFO: Created: latency-svc-jrldm
May 27 06:53:19.774: INFO: Got endpoints: latency-svc-rxqln [541.551154ms]
May 27 06:53:19.787: INFO: Got endpoints: latency-svc-kvrxq [575.5157ms]
May 27 06:53:19.787: INFO: Got endpoints: latency-svc-lzfct [596.038668ms]
May 27 06:53:19.805: INFO: Created: latency-svc-skqrm
May 27 06:53:19.824: INFO: Got endpoints: latency-svc-bhppt [508.583483ms]
May 27 06:53:19.829: INFO: Got endpoints: latency-svc-jzwfk [441.506312ms]
May 27 06:53:19.832: INFO: Got endpoints: latency-svc-mzbhr [553.049089ms]
May 27 06:53:19.844: INFO: Got endpoints: latency-svc-dx754 [453.840179ms]
May 27 06:53:19.849: INFO: Got endpoints: latency-svc-zmc4c [383.41076ms]
May 27 06:53:19.861: INFO: Got endpoints: latency-svc-h4bh6 [298.554677ms]
May 27 06:53:19.885: INFO: Got endpoints: latency-svc-82p5x [449.791526ms]
May 27 06:53:19.886: INFO: Got endpoints: latency-svc-jrldm [323.23874ms]
May 27 06:53:19.892: INFO: Got endpoints: latency-svc-skqrm [186.491816ms]
May 27 06:53:19.895: INFO: Got endpoints: latency-svc-g4qxs [241.781003ms]
May 27 06:53:19.899: INFO: Created: latency-svc-m8m52
May 27 06:53:19.917: INFO: Created: latency-svc-m2mfw
May 27 06:53:19.936: INFO: Got endpoints: latency-svc-m8m52 [201.483083ms]
May 27 06:53:19.961: INFO: Created: latency-svc-ghkkh
May 27 06:53:19.974: INFO: Got endpoints: latency-svc-m2mfw [209.741318ms]
May 27 06:53:20.006: INFO: Got endpoints: latency-svc-ghkkh [232.422353ms]
May 27 06:53:20.017: INFO: Created: latency-svc-pnfrq
May 27 06:53:20.058: INFO: Created: latency-svc-n4ncz
May 27 06:53:20.069: INFO: Created: latency-svc-ptwz4
May 27 06:53:20.148: INFO: Created: latency-svc-s44vw
May 27 06:53:20.305: INFO: Got endpoints: latency-svc-n4ncz [517.578556ms]
May 27 06:53:20.307: INFO: Got endpoints: latency-svc-ptwz4 [483.011238ms]
May 27 06:53:20.307: INFO: Got endpoints: latency-svc-pnfrq [520.318181ms]
May 27 06:53:20.308: INFO: Got endpoints: latency-svc-s44vw [478.960623ms]
May 27 06:53:20.395: INFO: Created: latency-svc-bjw9x
May 27 06:53:20.427: INFO: Got endpoints: latency-svc-bjw9x [594.257765ms]
May 27 06:53:20.440: INFO: Created: latency-svc-qbddf
May 27 06:53:20.448: INFO: Created: latency-svc-mjndx
May 27 06:53:20.468: INFO: Created: latency-svc-wwdkv
May 27 06:53:20.514: INFO: Got endpoints: latency-svc-qbddf [669.120904ms]
May 27 06:53:20.523: INFO: Created: latency-svc-xflsv
May 27 06:53:20.526: INFO: Got endpoints: latency-svc-mjndx [677.12404ms]
May 27 06:53:20.544: INFO: Got endpoints: latency-svc-wwdkv [682.022876ms]
May 27 06:53:20.545: INFO: Created: latency-svc-6zh58
May 27 06:53:20.586: INFO: Got endpoints: latency-svc-xflsv [699.623235ms]
May 27 06:53:20.599: INFO: Created: latency-svc-pqbrp
May 27 06:53:20.635: INFO: Created: latency-svc-d9srt
May 27 06:53:20.659: INFO: Got endpoints: latency-svc-6zh58 [774.150773ms]
May 27 06:53:20.668: INFO: Created: latency-svc-4bl5b
May 27 06:53:20.694: INFO: Created: latency-svc-2v6bf
May 27 06:53:20.731: INFO: Created: latency-svc-pzp2x
May 27 06:53:20.762: INFO: Got endpoints: latency-svc-pqbrp [870.282388ms]
May 27 06:53:20.763: INFO: Got endpoints: latency-svc-4bl5b [826.718954ms]
May 27 06:53:20.764: INFO: Created: latency-svc-qrhxj
May 27 06:53:20.763: INFO: Got endpoints: latency-svc-d9srt [868.211475ms]
May 27 06:53:20.791: INFO: Created: latency-svc-hlxvh
May 27 06:53:20.839: INFO: Got endpoints: latency-svc-pzp2x [832.137244ms]
May 27 06:53:20.850: INFO: Got endpoints: latency-svc-2v6bf [875.501896ms]
May 27 06:53:20.856: INFO: Created: latency-svc-pjhg9
May 27 06:53:20.885: INFO: Got endpoints: latency-svc-qrhxj [577.167927ms]
May 27 06:53:20.920: INFO: Created: latency-svc-c24ls
May 27 06:53:20.920: INFO: Got endpoints: latency-svc-hlxvh [611.187152ms]
May 27 06:53:20.936: INFO: Got endpoints: latency-svc-pjhg9 [627.768817ms]
May 27 06:53:20.982: INFO: Got endpoints: latency-svc-c24ls [677.632042ms]
May 27 06:53:20.985: INFO: Created: latency-svc-qxs54
May 27 06:53:21.011: INFO: Created: latency-svc-bbm8z
May 27 06:53:21.072: INFO: Got endpoints: latency-svc-qxs54 [645.48065ms]
May 27 06:53:21.075: INFO: Got endpoints: latency-svc-bbm8z [561.500775ms]
May 27 06:53:21.076: INFO: Created: latency-svc-fgzjj
May 27 06:53:21.122: INFO: Got endpoints: latency-svc-fgzjj [595.623854ms]
May 27 06:53:21.178: INFO: Created: latency-svc-c4hd9
May 27 06:53:21.208: INFO: Got endpoints: latency-svc-c4hd9 [664.014559ms]
May 27 06:53:21.221: INFO: Created: latency-svc-ltbpr
May 27 06:53:21.271: INFO: Got endpoints: latency-svc-ltbpr [685.501359ms]
May 27 06:53:21.279: INFO: Created: latency-svc-stjnk
May 27 06:53:21.304: INFO: Got endpoints: latency-svc-stjnk [644.516647ms]
May 27 06:53:21.359: INFO: Created: latency-svc-l8czd
May 27 06:53:21.359: INFO: Got endpoints: latency-svc-l8czd [594.286735ms]
May 27 06:53:21.375: INFO: Created: latency-svc-qrhtr
May 27 06:53:21.400: INFO: Got endpoints: latency-svc-qrhtr [635.213237ms]
May 27 06:53:21.416: INFO: Created: latency-svc-pjbmn
May 27 06:53:21.455: INFO: Got endpoints: latency-svc-pjbmn [692.17923ms]
May 27 06:53:21.489: INFO: Created: latency-svc-rd75l
May 27 06:53:21.530: INFO: Got endpoints: latency-svc-rd75l [690.64911ms]
May 27 06:53:21.531: INFO: Created: latency-svc-97fmh
May 27 06:53:21.581: INFO: Got endpoints: latency-svc-97fmh [730.639877ms]
May 27 06:53:21.584: INFO: Created: latency-svc-kz4r6
May 27 06:53:21.601: INFO: Got endpoints: latency-svc-kz4r6 [716.035496ms]
May 27 06:53:21.669: INFO: Created: latency-svc-5srkh
May 27 06:53:21.669: INFO: Got endpoints: latency-svc-5srkh [748.630973ms]
May 27 06:53:21.688: INFO: Created: latency-svc-dvlgx
May 27 06:53:21.714: INFO: Got endpoints: latency-svc-dvlgx [778.238457ms]
May 27 06:53:21.758: INFO: Created: latency-svc-bplf5
May 27 06:53:21.786: INFO: Got endpoints: latency-svc-bplf5 [803.399441ms]
May 27 06:53:21.816: INFO: Created: latency-svc-wd8hs
May 27 06:53:21.847: INFO: Got endpoints: latency-svc-wd8hs [774.888729ms]
May 27 06:53:21.867: INFO: Created: latency-svc-gdqtk
May 27 06:53:21.877: INFO: Got endpoints: latency-svc-gdqtk [801.806123ms]
May 27 06:53:21.888: INFO: Created: latency-svc-ctgpm
May 27 06:53:21.899: INFO: Created: latency-svc-45qs7
May 27 06:53:21.913: INFO: Got endpoints: latency-svc-ctgpm [790.956482ms]
May 27 06:53:21.939: INFO: Got endpoints: latency-svc-45qs7 [731.369573ms]
May 27 06:53:21.969: INFO: Created: latency-svc-j5gff
May 27 06:53:21.976: INFO: Created: latency-svc-h874q
May 27 06:53:21.981: INFO: Got endpoints: latency-svc-j5gff [709.024539ms]
May 27 06:53:21.990: INFO: Created: latency-svc-85pjv
May 27 06:53:22.023: INFO: Got endpoints: latency-svc-h874q [719.155994ms]
May 27 06:53:22.113: INFO: Got endpoints: latency-svc-85pjv [754.220086ms]
May 27 06:53:22.124: INFO: Created: latency-svc-ptpxm
May 27 06:53:22.144: INFO: Created: latency-svc-z7q6l
May 27 06:53:22.152: INFO: Created: latency-svc-vzxnr
May 27 06:53:22.166: INFO: Got endpoints: latency-svc-z7q6l [766.515293ms]
May 27 06:53:22.176: INFO: Got endpoints: latency-svc-ptpxm [720.998167ms]
May 27 06:53:22.238: INFO: Created: latency-svc-d4sh7
May 27 06:53:22.249: INFO: Got endpoints: latency-svc-vzxnr [718.98779ms]
May 27 06:53:22.255: INFO: Created: latency-svc-8lwt6
May 27 06:53:22.266: INFO: Got endpoints: latency-svc-d4sh7 [684.978124ms]
May 27 06:53:22.273: INFO: Created: latency-svc-2xqpt
May 27 06:53:22.322: INFO: Created: latency-svc-ngzgn
May 27 06:53:22.340: INFO: Created: latency-svc-t2nmk
May 27 06:53:22.354: INFO: Got endpoints: latency-svc-8lwt6 [753.013981ms]
May 27 06:53:22.367: INFO: Created: latency-svc-vzwzx
May 27 06:53:22.376: INFO: Got endpoints: latency-svc-2xqpt [707.564353ms]
May 27 06:53:22.386: INFO: Got endpoints: latency-svc-ngzgn [671.869017ms]
May 27 06:53:22.398: INFO: Got endpoints: latency-svc-t2nmk [612.359317ms]
May 27 06:53:22.418: INFO: Created: latency-svc-2xg2b
May 27 06:53:22.432: INFO: Got endpoints: latency-svc-vzwzx [584.437237ms]
May 27 06:53:22.437: INFO: Created: latency-svc-7cxs7
May 27 06:53:22.449: INFO: Created: latency-svc-czrkh
May 27 06:53:22.469: INFO: Created: latency-svc-z976l
May 27 06:53:22.479: INFO: Got endpoints: latency-svc-2xg2b [601.880171ms]
May 27 06:53:22.490: INFO: Created: latency-svc-c4dzm
May 27 06:53:22.500: INFO: Created: latency-svc-dqx4c
May 27 06:53:22.530: INFO: Got endpoints: latency-svc-7cxs7 [616.551261ms]
May 27 06:53:22.549: INFO: Created: latency-svc-qw2p2
May 27 06:53:22.576: INFO: Got endpoints: latency-svc-czrkh [636.48582ms]
May 27 06:53:22.585: INFO: Created: latency-svc-6cgml
May 27 06:53:22.602: INFO: Created: latency-svc-btfsf
May 27 06:53:22.615: INFO: Got endpoints: latency-svc-z976l [633.988739ms]
May 27 06:53:22.630: INFO: Created: latency-svc-cx7wk
May 27 06:53:22.659: INFO: Created: latency-svc-9m8b8
May 27 06:53:22.677: INFO: Got endpoints: latency-svc-c4dzm [653.553667ms]
May 27 06:53:22.705: INFO: Created: latency-svc-dqnrh
May 27 06:53:22.728: INFO: Got endpoints: latency-svc-dqx4c [614.521632ms]
May 27 06:53:22.750: INFO: Created: latency-svc-nxgxc
May 27 06:53:22.769: INFO: Created: latency-svc-crj5p
May 27 06:53:22.840: INFO: Got endpoints: latency-svc-6cgml [663.861052ms]
May 27 06:53:22.842: INFO: Got endpoints: latency-svc-qw2p2 [675.917895ms]
May 27 06:53:22.874: INFO: Created: latency-svc-58kh4
May 27 06:53:22.877: INFO: Got endpoints: latency-svc-btfsf [627.730532ms]
May 27 06:53:22.906: INFO: Got endpoints: latency-svc-cx7wk [640.09788ms]
May 27 06:53:22.926: INFO: Created: latency-svc-pmdsh
May 27 06:53:22.964: INFO: Got endpoints: latency-svc-9m8b8 [609.219318ms]
May 27 06:53:22.971: INFO: Created: latency-svc-l98sr
May 27 06:53:23.007: INFO: Created: latency-svc-rf7tl
May 27 06:53:23.048: INFO: Created: latency-svc-25zb6
May 27 06:53:23.059: INFO: Got endpoints: latency-svc-dqnrh [682.769835ms]
May 27 06:53:23.079: INFO: Created: latency-svc-65vmv
May 27 06:53:23.090: INFO: Got endpoints: latency-svc-nxgxc [703.446776ms]
May 27 06:53:23.117: INFO: Created: latency-svc-dkgsm
May 27 06:53:23.126: INFO: Got endpoints: latency-svc-crj5p [727.422542ms]
May 27 06:53:23.155: INFO: Created: latency-svc-txnkb
May 27 06:53:23.177: INFO: Got endpoints: latency-svc-58kh4 [745.34377ms]
May 27 06:53:23.194: INFO: Created: latency-svc-r85ql
May 27 06:53:23.264: INFO: Got endpoints: latency-svc-pmdsh [784.723323ms]
May 27 06:53:23.266: INFO: Created: latency-svc-pn2t6
May 27 06:53:23.268: INFO: Got endpoints: latency-svc-l98sr [737.196235ms]
May 27 06:53:23.298: INFO: Created: latency-svc-skh2k
May 27 06:53:23.324: INFO: Got endpoints: latency-svc-rf7tl [747.938686ms]
May 27 06:53:23.331: INFO: Created: latency-svc-6tmlf
May 27 06:53:23.361: INFO: Created: latency-svc-d77hj
May 27 06:53:23.378: INFO: Got endpoints: latency-svc-25zb6 [763.464865ms]
May 27 06:53:23.417: INFO: Created: latency-svc-57z76
May 27 06:53:23.418: INFO: Got endpoints: latency-svc-65vmv [741.043044ms]
May 27 06:53:23.452: INFO: Created: latency-svc-cxlzv
May 27 06:53:23.465: INFO: Got endpoints: latency-svc-dkgsm [737.029937ms]
May 27 06:53:23.473: INFO: Created: latency-svc-kwsh6
May 27 06:53:23.501: INFO: Got endpoints: latency-svc-txnkb [660.956883ms]
May 27 06:53:23.504: INFO: Created: latency-svc-z5jrw
May 27 06:53:23.546: INFO: Created: latency-svc-456cv
May 27 06:53:23.571: INFO: Got endpoints: latency-svc-r85ql [728.633875ms]
May 27 06:53:23.587: INFO: Created: latency-svc-rgqzg
May 27 06:53:23.606: INFO: Got endpoints: latency-svc-pn2t6 [729.510018ms]
May 27 06:53:23.616: INFO: Created: latency-svc-qfz27
May 27 06:53:23.648: INFO: Created: latency-svc-lwgkp
May 27 06:53:23.668: INFO: Got endpoints: latency-svc-skh2k [761.587404ms]
May 27 06:53:23.683: INFO: Created: latency-svc-l7gwp
May 27 06:53:23.701: INFO: Got endpoints: latency-svc-6tmlf [737.325094ms]
May 27 06:53:23.723: INFO: Created: latency-svc-5lszn
May 27 06:53:23.746: INFO: Created: latency-svc-87fpd
May 27 06:53:23.747: INFO: Created: latency-svc-2fpvp
May 27 06:53:23.754: INFO: Got endpoints: latency-svc-d77hj [694.579215ms]
May 27 06:53:23.773: INFO: Created: latency-svc-rgpcs
May 27 06:53:23.807: INFO: Created: latency-svc-6r8n9
May 27 06:53:23.808: INFO: Got endpoints: latency-svc-57z76 [717.538838ms]
May 27 06:53:23.823: INFO: Created: latency-svc-9m66h
May 27 06:53:23.849: INFO: Got endpoints: latency-svc-cxlzv [722.624356ms]
May 27 06:53:23.859: INFO: Created: latency-svc-mb246
May 27 06:53:23.886: INFO: Created: latency-svc-m69hs
May 27 06:53:23.910: INFO: Got endpoints: latency-svc-kwsh6 [732.226698ms]
May 27 06:53:23.947: INFO: Created: latency-svc-l72zx
May 27 06:53:23.948: INFO: Got endpoints: latency-svc-z5jrw [680.313606ms]
May 27 06:53:23.982: INFO: Created: latency-svc-gpxqw
May 27 06:53:23.996: INFO: Got endpoints: latency-svc-456cv [732.268359ms]
May 27 06:53:24.043: INFO: Created: latency-svc-xzl5g
May 27 06:53:24.057: INFO: Got endpoints: latency-svc-rgqzg [733.450927ms]
May 27 06:53:24.106: INFO: Got endpoints: latency-svc-qfz27 [727.597659ms]
May 27 06:53:24.111: INFO: Created: latency-svc-z8cxp
May 27 06:53:24.143: INFO: Got endpoints: latency-svc-lwgkp [678.05385ms]
May 27 06:53:24.362: INFO: Got endpoints: latency-svc-l7gwp [859.701983ms]
May 27 06:53:24.366: INFO: Got endpoints: latency-svc-5lszn [794.69465ms]
May 27 06:53:24.368: INFO: Got endpoints: latency-svc-87fpd [950.526705ms]
May 27 06:53:24.373: INFO: Got endpoints: latency-svc-2fpvp [767.116441ms]
May 27 06:53:24.398: INFO: Created: latency-svc-8hh7t
May 27 06:53:24.453: INFO: Got endpoints: latency-svc-rgpcs [785.206391ms]
May 27 06:53:24.454: INFO: Got endpoints: latency-svc-6r8n9 [752.911801ms]
May 27 06:53:24.472: INFO: Created: latency-svc-cvl2p
May 27 06:53:24.489: INFO: Created: latency-svc-88bjs
May 27 06:53:24.503: INFO: Got endpoints: latency-svc-9m66h [749.024448ms]
May 27 06:53:24.516: INFO: Created: latency-svc-gqhw2
May 27 06:53:24.540: INFO: Created: latency-svc-gmfnv
May 27 06:53:24.552: INFO: Created: latency-svc-k5r95
May 27 06:53:24.574: INFO: Got endpoints: latency-svc-mb246 [765.569309ms]
May 27 06:53:24.583: INFO: Created: latency-svc-t25rb
May 27 06:53:24.602: INFO: Got endpoints: latency-svc-m69hs [753.221059ms]
May 27 06:53:24.649: INFO: Got endpoints: latency-svc-l72zx [739.198363ms]
May 27 06:53:24.698: INFO: Got endpoints: latency-svc-gpxqw [749.782646ms]
May 27 06:53:24.766: INFO: Got endpoints: latency-svc-xzl5g [768.945573ms]
May 27 06:53:24.808: INFO: Got endpoints: latency-svc-z8cxp [750.715993ms]
May 27 06:53:24.893: INFO: Got endpoints: latency-svc-8hh7t [786.482914ms]
May 27 06:53:24.911: INFO: Got endpoints: latency-svc-cvl2p [767.470073ms]
May 27 06:53:24.946: INFO: Got endpoints: latency-svc-88bjs [584.244358ms]
May 27 06:53:25.008: INFO: Got endpoints: latency-svc-gqhw2 [642.009473ms]
May 27 06:53:25.044: INFO: Got endpoints: latency-svc-gmfnv [675.966301ms]
May 27 06:53:25.097: INFO: Got endpoints: latency-svc-k5r95 [724.048429ms]
May 27 06:53:25.154: INFO: Got endpoints: latency-svc-t25rb [699.477917ms]
May 27 06:53:25.154: INFO: Latencies: [59.540527ms 154.731895ms 172.273192ms 186.491816ms 201.483083ms 209.741318ms 232.422353ms 238.84948ms 241.781003ms 272.192717ms 278.030092ms 282.27596ms 298.554677ms 302.796919ms 310.946871ms 323.23874ms 337.398363ms 342.259736ms 364.914061ms 365.139561ms 382.043126ms 382.709469ms 383.41076ms 384.054774ms 384.581661ms 385.732745ms 388.351011ms 389.215969ms 419.686535ms 441.506312ms 444.521226ms 449.791526ms 451.39516ms 453.840179ms 461.887096ms 467.741617ms 468.600116ms 472.935976ms 475.556992ms 478.48166ms 478.960623ms 481.240592ms 483.011238ms 489.168679ms 492.688826ms 495.119985ms 500.964149ms 502.767417ms 508.583483ms 509.218908ms 517.578556ms 520.318181ms 530.526985ms 538.869829ms 540.577541ms 541.551154ms 544.138185ms 545.260221ms 548.038965ms 553.049089ms 553.454417ms 561.500775ms 571.120468ms 574.269434ms 575.244541ms 575.5157ms 577.167927ms 582.532681ms 584.033374ms 584.244358ms 584.437237ms 585.495981ms 588.878079ms 589.513603ms 592.885072ms 594.257765ms 594.286735ms 594.391933ms 595.623854ms 596.038668ms 601.880171ms 605.363913ms 609.219318ms 609.57274ms 611.187152ms 612.359317ms 614.521632ms 616.551261ms 627.187551ms 627.730532ms 627.768817ms 631.037568ms 633.366848ms 633.988739ms 635.213237ms 636.48582ms 640.09788ms 640.264636ms 642.009473ms 643.726267ms 644.516647ms 645.48065ms 653.553667ms 660.956883ms 663.861052ms 664.014559ms 665.828277ms 669.120904ms 671.869017ms 675.917895ms 675.966301ms 677.12404ms 677.632042ms 678.05385ms 678.512439ms 680.313606ms 682.022876ms 682.769835ms 684.978124ms 685.478083ms 685.501359ms 690.64911ms 692.17923ms 694.579215ms 698.066726ms 699.477917ms 699.623235ms 703.446776ms 703.808054ms 707.564353ms 709.024539ms 716.035496ms 717.538838ms 718.034314ms 718.98779ms 719.155994ms 720.998167ms 722.624356ms 724.048429ms 727.422542ms 727.469649ms 727.597659ms 728.633875ms 729.510018ms 730.639877ms 731.369573ms 732.226698ms 732.268359ms 733.450927ms 737.029937ms 737.196235ms 737.325094ms 738.562548ms 739.198363ms 741.043044ms 742.719634ms 745.34377ms 747.938686ms 748.630973ms 749.024448ms 749.782646ms 750.715993ms 752.911801ms 753.013981ms 753.221059ms 754.220086ms 761.587404ms 763.464865ms 765.569309ms 766.515293ms 767.116441ms 767.470073ms 768.945573ms 774.150773ms 774.888729ms 778.238457ms 782.132783ms 784.723323ms 785.206391ms 786.482914ms 790.956482ms 794.69465ms 801.806123ms 803.399441ms 826.718954ms 832.137244ms 848.470874ms 859.701983ms 868.211475ms 870.282388ms 875.501896ms 884.231413ms 885.802462ms 944.246506ms 950.526705ms 957.379326ms 1.034299863s 1.053676734s 1.098414951s 1.739386469s]
May 27 06:53:25.154: INFO: 50 %ile: 644.516647ms
May 27 06:53:25.154: INFO: 90 %ile: 790.956482ms
May 27 06:53:25.154: INFO: 99 %ile: 1.098414951s
May 27 06:53:25.154: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:188
May 27 06:53:25.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5227" for this suite.

• [SLOW TEST:11.968 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":356,"completed":314,"skipped":5973,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:53:25.188: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-77c32dcf-42e8-43fb-85e5-ea8a283bed09
STEP: Creating a pod to test consume configMaps
May 27 06:53:25.328: INFO: Waiting up to 5m0s for pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5" in namespace "configmap-1322" to be "Succeeded or Failed"
May 27 06:53:25.334: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.862727ms
May 27 06:53:27.348: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019293575s
May 27 06:53:29.359: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031031429s
May 27 06:53:31.374: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.045984119s
May 27 06:53:33.481: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.152656643s
May 27 06:53:35.494: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.165741415s
May 27 06:53:37.510: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.181140654s
May 27 06:53:39.521: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.192555625s
May 27 06:53:41.549: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.220866139s
May 27 06:53:43.564: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.235601435s
May 27 06:53:45.585: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 20.256859488s
STEP: Saw pod success
May 27 06:53:45.585: INFO: Pod "pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5" satisfied condition "Succeeded or Failed"
May 27 06:53:45.592: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5 container agnhost-container: <nil>
STEP: delete the pod
May 27 06:53:45.899: INFO: Waiting for pod pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5 to disappear
May 27 06:53:45.906: INFO: Pod pod-configmaps-cb0a38aa-999a-4653-829f-258955ecd4f5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
May 27 06:53:45.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1322" for this suite.

• [SLOW TEST:20.762 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":315,"skipped":5987,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:53:45.955: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-1595
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 27 06:53:46.017: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May 27 06:53:46.225: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:53:48.312: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:53:50.250: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:53:52.248: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 06:53:54.246: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 06:53:56.237: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 06:53:58.240: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 06:54:00.242: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 06:54:02.244: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 06:54:04.242: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 06:54:06.239: INFO: The status of Pod netserver-0 is Running (Ready = false)
May 27 06:54:08.240: INFO: The status of Pod netserver-0 is Running (Ready = true)
May 27 06:54:08.261: INFO: The status of Pod netserver-1 is Running (Ready = true)
May 27 06:54:08.279: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
May 27 06:54:12.337: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
May 27 06:54:12.337: INFO: Breadth first check of 10.233.66.188 on host 192.168.121.180...
May 27 06:54:12.349: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.162:9080/dial?request=hostname&protocol=http&host=10.233.66.188&port=8083&tries=1'] Namespace:pod-network-test-1595 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:54:12.349: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:54:12.354: INFO: ExecWithOptions: Clientset creation
May 27 06:54:12.354: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1595/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.65.162%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.188%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May 27 06:54:12.574: INFO: Waiting for responses: map[]
May 27 06:54:12.574: INFO: reached 10.233.66.188 after 0/1 tries
May 27 06:54:12.575: INFO: Breadth first check of 10.233.64.72 on host 192.168.121.117...
May 27 06:54:12.586: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.162:9080/dial?request=hostname&protocol=http&host=10.233.64.72&port=8083&tries=1'] Namespace:pod-network-test-1595 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:54:12.586: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:54:12.588: INFO: ExecWithOptions: Clientset creation
May 27 06:54:12.588: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1595/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.65.162%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.72%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May 27 06:54:12.729: INFO: Waiting for responses: map[]
May 27 06:54:12.729: INFO: reached 10.233.64.72 after 0/1 tries
May 27 06:54:12.729: INFO: Breadth first check of 10.233.65.65 on host 192.168.121.16...
May 27 06:54:12.738: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.65.162:9080/dial?request=hostname&protocol=http&host=10.233.65.65&port=8083&tries=1'] Namespace:pod-network-test-1595 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 06:54:12.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 06:54:12.740: INFO: ExecWithOptions: Clientset creation
May 27 06:54:12.741: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1595/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.65.162%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.65%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May 27 06:54:12.885: INFO: Waiting for responses: map[]
May 27 06:54:12.885: INFO: reached 10.233.65.65 after 0/1 tries
May 27 06:54:12.885: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
May 27 06:54:12.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1595" for this suite.

• [SLOW TEST:26.960 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":356,"completed":316,"skipped":6022,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:54:12.919: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-3313c0bc-24d2-40ec-aa4f-e633279e4b54
STEP: Creating a pod to test consume secrets
May 27 06:54:13.003: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-73f48135-b6bc-4da7-bd61-20b5cb999b5a" in namespace "projected-5793" to be "Succeeded or Failed"
May 27 06:54:13.015: INFO: Pod "pod-projected-secrets-73f48135-b6bc-4da7-bd61-20b5cb999b5a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.785772ms
May 27 06:54:15.027: INFO: Pod "pod-projected-secrets-73f48135-b6bc-4da7-bd61-20b5cb999b5a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024079068s
May 27 06:54:17.039: INFO: Pod "pod-projected-secrets-73f48135-b6bc-4da7-bd61-20b5cb999b5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035874344s
STEP: Saw pod success
May 27 06:54:17.039: INFO: Pod "pod-projected-secrets-73f48135-b6bc-4da7-bd61-20b5cb999b5a" satisfied condition "Succeeded or Failed"
May 27 06:54:17.045: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-secrets-73f48135-b6bc-4da7-bd61-20b5cb999b5a container projected-secret-volume-test: <nil>
STEP: delete the pod
May 27 06:54:17.081: INFO: Waiting for pod pod-projected-secrets-73f48135-b6bc-4da7-bd61-20b5cb999b5a to disappear
May 27 06:54:17.086: INFO: Pod pod-projected-secrets-73f48135-b6bc-4da7-bd61-20b5cb999b5a no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
May 27 06:54:17.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5793" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":317,"skipped":6064,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:54:17.113: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ReplicationController
STEP: waiting for RC to be added
STEP: waiting for available Replicas
STEP: patching ReplicationController
STEP: waiting for RC to be modified
STEP: patching ReplicationController status
STEP: waiting for RC to be modified
STEP: waiting for available Replicas
STEP: fetching ReplicationController status
STEP: patching ReplicationController scale
STEP: waiting for RC to be modified
STEP: waiting for ReplicationController's scale to be the max amount
STEP: fetching ReplicationController; ensuring that it's patched
STEP: updating ReplicationController status
STEP: waiting for RC to be modified
STEP: listing all ReplicationControllers
STEP: checking that ReplicationController has expected values
STEP: deleting ReplicationControllers by collection
STEP: waiting for ReplicationController to have a DELETED watchEvent
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
May 27 06:54:25.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4851" for this suite.

• [SLOW TEST:8.082 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","total":356,"completed":318,"skipped":6081,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:54:25.199: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
May 27 06:54:25.332: INFO: created test-event-1
May 27 06:54:25.343: INFO: created test-event-2
May 27 06:54:25.352: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
May 27 06:54:25.359: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
May 27 06:54:25.411: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
May 27 06:54:25.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5218" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","total":356,"completed":319,"skipped":6107,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:54:25.451: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 06:54:26.316: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 27 06:54:28.355: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 26, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 26, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 06:54:31.396: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 06:54:31.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8272" for this suite.
STEP: Destroying namespace "webhook-8272-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.072 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":356,"completed":320,"skipped":6129,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:54:31.529: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not conflict [Conformance]
  test/e2e/framework/framework.go:652
May 27 06:54:31.843: INFO: The status of Pod pod-secrets-6805f522-950e-4089-aea4-a1caaf533f2b is Pending, waiting for it to be Running (with Ready = true)
May 27 06:54:33.930: INFO: The status of Pod pod-secrets-6805f522-950e-4089-aea4-a1caaf533f2b is Pending, waiting for it to be Running (with Ready = true)
May 27 06:54:35.857: INFO: The status of Pod pod-secrets-6805f522-950e-4089-aea4-a1caaf533f2b is Running (Ready = true)
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
May 27 06:54:35.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5936" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":356,"completed":321,"skipped":6144,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:54:35.941: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name projected-secret-test-31778987-5208-4809-a888-f13689421838
STEP: Creating a pod to test consume secrets
May 27 06:54:36.024: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fcbbb4c1-d15c-4102-8050-772df4a287e6" in namespace "projected-927" to be "Succeeded or Failed"
May 27 06:54:36.034: INFO: Pod "pod-projected-secrets-fcbbb4c1-d15c-4102-8050-772df4a287e6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.194193ms
May 27 06:54:38.051: INFO: Pod "pod-projected-secrets-fcbbb4c1-d15c-4102-8050-772df4a287e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02675762s
May 27 06:54:40.081: INFO: Pod "pod-projected-secrets-fcbbb4c1-d15c-4102-8050-772df4a287e6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056994896s
May 27 06:54:42.104: INFO: Pod "pod-projected-secrets-fcbbb4c1-d15c-4102-8050-772df4a287e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.080015325s
STEP: Saw pod success
May 27 06:54:42.104: INFO: Pod "pod-projected-secrets-fcbbb4c1-d15c-4102-8050-772df4a287e6" satisfied condition "Succeeded or Failed"
May 27 06:54:42.111: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-secrets-fcbbb4c1-d15c-4102-8050-772df4a287e6 container secret-volume-test: <nil>
STEP: delete the pod
May 27 06:54:42.165: INFO: Waiting for pod pod-projected-secrets-fcbbb4c1-d15c-4102-8050-772df4a287e6 to disappear
May 27 06:54:42.171: INFO: Pod pod-projected-secrets-fcbbb4c1-d15c-4102-8050-772df4a287e6 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
May 27 06:54:42.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-927" for this suite.

• [SLOW TEST:6.255 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":322,"skipped":6181,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:54:42.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pdb
STEP: Waiting for the pdb to be processed
STEP: updating the pdb
STEP: Waiting for the pdb to be processed
STEP: patching the pdb
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be deleted
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
May 27 06:54:48.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4668" for this suite.

• [SLOW TEST:6.274 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","total":356,"completed":323,"skipped":6192,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:54:48.477: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
May 27 06:54:48.576: INFO: The status of Pod annotationupdate7d3e0405-ee4c-4600-aaa7-416971eafe50 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:54:50.589: INFO: The status of Pod annotationupdate7d3e0405-ee4c-4600-aaa7-416971eafe50 is Pending, waiting for it to be Running (with Ready = true)
May 27 06:54:52.590: INFO: The status of Pod annotationupdate7d3e0405-ee4c-4600-aaa7-416971eafe50 is Running (Ready = true)
May 27 06:54:53.139: INFO: Successfully updated pod "annotationupdate7d3e0405-ee4c-4600-aaa7-416971eafe50"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
May 27 06:54:55.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2650" for this suite.

• [SLOW TEST:6.715 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":324,"skipped":6209,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:54:55.191: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:79
May 27 06:54:55.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the sample API server.
May 27 06:54:55.946: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
May 27 06:54:58.057: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:00.079: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:02.085: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:04.073: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:06.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:08.096: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:10.086: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:12.075: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:14.103: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:16.073: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:18.083: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:20.092: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:22.096: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:24.089: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:26.082: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 54, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:28.075: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 6, 55, 26, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 54, 55, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" has successfully progressed."}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 6, 55, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 6, 55, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
May 27 06:55:30.266: INFO: Waited 164.138612ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}'
STEP: List APIServices
May 27 06:55:30.409: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:69
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:188
May 27 06:55:30.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-905" for this suite.

• [SLOW TEST:35.803 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":356,"completed":325,"skipped":6220,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:55:31.004: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: creating
STEP: getting
STEP: listing
STEP: watching
May 27 06:55:31.159: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
May 27 06:55:31.170: INFO: starting watch
STEP: patching
STEP: updating
May 27 06:55:31.214: INFO: waiting for watch events with expected annotations
May 27 06:55:31.214: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
May 27 06:55:31.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1320" for this suite.
•{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","total":356,"completed":326,"skipped":6277,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 06:55:31.379: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a suspended cronjob
STEP: Ensuring no jobs are scheduled
STEP: Ensuring no job exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
May 27 07:00:31.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-3167" for this suite.

• [SLOW TEST:300.133 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","total":356,"completed":327,"skipped":6304,"failed":0}
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:00:31.517: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota
May 27 07:00:31.606: INFO: Pod name sample-pod: Found 0 pods out of 1
May 27 07:00:36.645: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the replicaset Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
May 27 07:00:36.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8822" for this suite.

• [SLOW TEST:5.348 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","total":356,"completed":328,"skipped":6309,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:00:36.866: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:58
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-cb7bc6ff-9dde-430b-a6f0-e6bdeddc2a7b in namespace container-probe-9176
May 27 07:00:39.081: INFO: Started pod liveness-cb7bc6ff-9dde-430b-a6f0-e6bdeddc2a7b in namespace container-probe-9176
STEP: checking the pod's current state and verifying that restartCount is present
May 27 07:00:39.089: INFO: Initial restart count of pod liveness-cb7bc6ff-9dde-430b-a6f0-e6bdeddc2a7b is 0
May 27 07:00:59.264: INFO: Restart count of pod container-probe-9176/liveness-cb7bc6ff-9dde-430b-a6f0-e6bdeddc2a7b is now 1 (20.17489595s elapsed)
May 27 07:01:19.419: INFO: Restart count of pod container-probe-9176/liveness-cb7bc6ff-9dde-430b-a6f0-e6bdeddc2a7b is now 2 (40.329641374s elapsed)
May 27 07:01:39.564: INFO: Restart count of pod container-probe-9176/liveness-cb7bc6ff-9dde-430b-a6f0-e6bdeddc2a7b is now 3 (1m0.474637117s elapsed)
May 27 07:01:59.729: INFO: Restart count of pod container-probe-9176/liveness-cb7bc6ff-9dde-430b-a6f0-e6bdeddc2a7b is now 4 (1m20.639814817s elapsed)
May 27 07:03:08.458: INFO: Restart count of pod container-probe-9176/liveness-cb7bc6ff-9dde-430b-a6f0-e6bdeddc2a7b is now 5 (2m29.368617526s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
May 27 07:03:08.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9176" for this suite.

• [SLOW TEST:151.680 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":356,"completed":329,"skipped":6317,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:03:08.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 07:03:09.494: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 27 07:03:11.614: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 7, 3, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 7, 3, 9, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 7, 3, 9, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 7, 3, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 07:03:14.653: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
May 27 07:03:14.664: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5224-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 07:03:18.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2232" for this suite.
STEP: Destroying namespace "webhook-2232-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:10.051 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":356,"completed":330,"skipped":6326,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:03:18.602: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 27 07:03:18.861: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 07:03:18.861: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 07:03:19.890: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 07:03:19.890: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 07:03:20.882: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May 27 07:03:20.882: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 07:03:21.889: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
May 27 07:03:21.889: INFO: Node bohc9zohd7ee-1 is running 0 daemon pod, expected 1
May 27 07:03:22.882: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May 27 07:03:22.882: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets
STEP: DeleteCollection of the DaemonSets
STEP: Verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
May 27 07:03:22.946: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39420"},"items":null}

May 27 07:03:22.958: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39422"},"items":[{"metadata":{"name":"daemon-set-bw9tf","generateName":"daemon-set-","namespace":"daemonsets-3263","uid":"95262d9d-921c-4c20-acc7-128a8d38a035","resourceVersion":"39420","creationTimestamp":"2022-05-27T07:03:18Z","deletionTimestamp":"2022-05-27T07:03:52Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"86b9edf6-b811-4c4f-8b97-4823106ef52a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-05-27T07:03:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"86b9edf6-b811-4c4f-8b97-4823106ef52a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-05-27T07:03:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.109\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bnz5g","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bnz5g","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"bohc9zohd7ee-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["bohc9zohd7ee-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:18Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:21Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:21Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:18Z"}],"hostIP":"192.168.121.180","podIP":"10.233.66.109","podIPs":[{"ip":"10.233.66.109"}],"startTime":"2022-05-27T07:03:18Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-05-27T07:03:21Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://d0426d60966f4e8f56ecde0c57784c2865aa0604dd026161b744d69e3af9d4e3","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-sjfzh","generateName":"daemon-set-","namespace":"daemonsets-3263","uid":"ee13869d-db0b-49ed-9a11-b00ed1919421","resourceVersion":"39421","creationTimestamp":"2022-05-27T07:03:18Z","deletionTimestamp":"2022-05-27T07:03:52Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"86b9edf6-b811-4c4f-8b97-4823106ef52a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-05-27T07:03:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"86b9edf6-b811-4c4f-8b97-4823106ef52a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-05-27T07:03:22Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.216\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-zf4bv","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-zf4bv","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"bohc9zohd7ee-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["bohc9zohd7ee-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:19Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:22Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:22Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:18Z"}],"hostIP":"192.168.121.16","podIP":"10.233.65.216","podIPs":[{"ip":"10.233.65.216"}],"startTime":"2022-05-27T07:03:19Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-05-27T07:03:22Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://666e2de7fe6e2b1a5d4a895f1f56f4c00c70dfbe0c1df1d05af1a65e3d052f27","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-w79gr","generateName":"daemon-set-","namespace":"daemonsets-3263","uid":"090cba15-643e-4d16-a147-b5d8666faad9","resourceVersion":"39419","creationTimestamp":"2022-05-27T07:03:18Z","deletionTimestamp":"2022-05-27T07:03:52Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"86b9edf6-b811-4c4f-8b97-4823106ef52a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-05-27T07:03:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"86b9edf6-b811-4c4f-8b97-4823106ef52a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-05-27T07:03:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.87\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-qxs99","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-qxs99","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"bohc9zohd7ee-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["bohc9zohd7ee-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:19Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:20Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:20Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-05-27T07:03:18Z"}],"hostIP":"192.168.121.117","podIP":"10.233.64.87","podIPs":[{"ip":"10.233.64.87"}],"startTime":"2022-05-27T07:03:19Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-05-27T07:03:20Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://0e05b35f3453f52bed2f2674ef5ecc4c0574154a905b3c5c2f388398b33bc6e7","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
May 27 07:03:23.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3263" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","total":356,"completed":331,"skipped":6349,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:03:23.037: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
May 27 07:03:23.097: INFO: The status of Pod labelsupdatee4c11e65-c00b-41d4-8808-56b09d000fc6 is Pending, waiting for it to be Running (with Ready = true)
May 27 07:03:25.112: INFO: The status of Pod labelsupdatee4c11e65-c00b-41d4-8808-56b09d000fc6 is Pending, waiting for it to be Running (with Ready = true)
May 27 07:03:27.113: INFO: The status of Pod labelsupdatee4c11e65-c00b-41d4-8808-56b09d000fc6 is Running (Ready = true)
May 27 07:03:27.675: INFO: Successfully updated pod "labelsupdatee4c11e65-c00b-41d4-8808-56b09d000fc6"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
May 27 07:03:29.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5254" for this suite.

• [SLOW TEST:6.746 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":332,"skipped":6356,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:03:29.786: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-5faec83f-dfa7-4cca-916a-6dad3d0c2b4f
STEP: Creating a pod to test consume secrets
May 27 07:03:29.896: INFO: Waiting up to 5m0s for pod "pod-secrets-f3035658-c904-449b-9bf2-07b4722377d0" in namespace "secrets-5312" to be "Succeeded or Failed"
May 27 07:03:29.903: INFO: Pod "pod-secrets-f3035658-c904-449b-9bf2-07b4722377d0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.411731ms
May 27 07:03:31.918: INFO: Pod "pod-secrets-f3035658-c904-449b-9bf2-07b4722377d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022078997s
May 27 07:03:33.932: INFO: Pod "pod-secrets-f3035658-c904-449b-9bf2-07b4722377d0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035767908s
May 27 07:03:35.944: INFO: Pod "pod-secrets-f3035658-c904-449b-9bf2-07b4722377d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.048501628s
STEP: Saw pod success
May 27 07:03:35.945: INFO: Pod "pod-secrets-f3035658-c904-449b-9bf2-07b4722377d0" satisfied condition "Succeeded or Failed"
May 27 07:03:35.956: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-secrets-f3035658-c904-449b-9bf2-07b4722377d0 container secret-volume-test: <nil>
STEP: delete the pod
May 27 07:03:35.992: INFO: Waiting for pod pod-secrets-f3035658-c904-449b-9bf2-07b4722377d0 to disappear
May 27 07:03:35.997: INFO: Pod pod-secrets-f3035658-c904-449b-9bf2-07b4722377d0 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
May 27 07:03:35.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5312" for this suite.

• [SLOW TEST:6.232 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":333,"skipped":6373,"failed":0}
SSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:03:36.019: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
May 27 07:03:40.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4417" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","total":356,"completed":334,"skipped":6381,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:03:40.367: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Creating a NodePort Service
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota
STEP: Ensuring resource quota status captures service creation
STEP: Deleting Services
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
May 27 07:03:51.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5731" for this suite.

• [SLOW TEST:11.487 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":356,"completed":335,"skipped":6387,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:03:51.855: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
May 27 07:03:52.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8215" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","total":356,"completed":336,"skipped":6389,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:03:52.036: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
May 27 07:03:52.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5770" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":356,"completed":337,"skipped":6401,"failed":0}
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:03:52.337: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
May 27 07:03:52.422: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 27 07:03:57.460: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 27 07:03:57.460: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May 27 07:03:57.518: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-1403  2e1f8a5a-352a-4fab-982e-0141ceb2beba 39679 1 2022-05-27 07:03:57 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2022-05-27 07:03:57 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.36 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005f5fad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

May 27 07:03:57.529: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
May 27 07:03:57.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1403" for this suite.

• [SLOW TEST:5.227 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":356,"completed":338,"skipped":6402,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:03:57.565: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
May 27 07:03:57.781: INFO: Waiting up to 5m0s for pod "pod-5e09911e-5d69-4727-b9aa-69eeb47f3783" in namespace "emptydir-8453" to be "Succeeded or Failed"
May 27 07:03:57.796: INFO: Pod "pod-5e09911e-5d69-4727-b9aa-69eeb47f3783": Phase="Pending", Reason="", readiness=false. Elapsed: 14.251104ms
May 27 07:03:59.812: INFO: Pod "pod-5e09911e-5d69-4727-b9aa-69eeb47f3783": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030675228s
May 27 07:04:01.826: INFO: Pod "pod-5e09911e-5d69-4727-b9aa-69eeb47f3783": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044616226s
May 27 07:04:03.838: INFO: Pod "pod-5e09911e-5d69-4727-b9aa-69eeb47f3783": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.056073759s
STEP: Saw pod success
May 27 07:04:03.838: INFO: Pod "pod-5e09911e-5d69-4727-b9aa-69eeb47f3783" satisfied condition "Succeeded or Failed"
May 27 07:04:03.845: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-5e09911e-5d69-4727-b9aa-69eeb47f3783 container test-container: <nil>
STEP: delete the pod
May 27 07:04:03.910: INFO: Waiting for pod pod-5e09911e-5d69-4727-b9aa-69eeb47f3783 to disappear
May 27 07:04:03.918: INFO: Pod pod-5e09911e-5d69-4727-b9aa-69eeb47f3783 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 07:04:03.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8453" for this suite.

• [SLOW TEST:6.385 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":339,"skipped":6410,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:04:03.954: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1334
STEP: creating the pod
May 27 07:04:04.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-2443 create -f -'
May 27 07:04:06.605: INFO: stderr: ""
May 27 07:04:06.605: INFO: stdout: "pod/pause created\n"
May 27 07:04:06.605: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 27 07:04:06.605: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2443" to be "running and ready"
May 27 07:04:06.618: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 12.435929ms
May 27 07:04:08.635: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029964147s
May 27 07:04:10.655: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.049822714s
May 27 07:04:10.655: INFO: Pod "pause" satisfied condition "running and ready"
May 27 07:04:10.655: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
STEP: adding the label testing-label with value testing-label-value to a pod
May 27 07:04:10.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-2443 label pods pause testing-label=testing-label-value'
May 27 07:04:10.881: INFO: stderr: ""
May 27 07:04:10.881: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 27 07:04:10.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-2443 get pod pause -L testing-label'
May 27 07:04:11.078: INFO: stderr: ""
May 27 07:04:11.078: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 27 07:04:11.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-2443 label pods pause testing-label-'
May 27 07:04:11.238: INFO: stderr: ""
May 27 07:04:11.238: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 27 07:04:11.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-2443 get pod pause -L testing-label'
May 27 07:04:11.453: INFO: stderr: ""
May 27 07:04:11.453: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1340
STEP: using delete to clean up resources
May 27 07:04:11.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-2443 delete --grace-period=0 --force -f -'
May 27 07:04:11.632: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 27 07:04:11.632: INFO: stdout: "pod \"pause\" force deleted\n"
May 27 07:04:11.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-2443 get rc,svc -l name=pause --no-headers'
May 27 07:04:11.824: INFO: stderr: "No resources found in kubectl-2443 namespace.\n"
May 27 07:04:11.824: INFO: stdout: ""
May 27 07:04:11.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=kubectl-2443 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 27 07:04:11.976: INFO: stderr: ""
May 27 07:04:11.976: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
May 27 07:04:11.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2443" for this suite.

• [SLOW TEST:8.042 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1332
    should update the label on a resource  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":356,"completed":340,"skipped":6420,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:04:11.998: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
May 27 07:04:12.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5487" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","total":356,"completed":341,"skipped":6423,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:04:12.352: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
May 27 07:04:25.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4455" for this suite.

• [SLOW TEST:13.311 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":356,"completed":342,"skipped":6439,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:04:25.674: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-bd49fa90-78d1-4cfe-8128-f3cbe21a4cda
STEP: Creating a pod to test consume configMaps
May 27 07:04:25.769: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5a7b61df-57a6-45e6-b4c5-822e0c11fef0" in namespace "projected-9644" to be "Succeeded or Failed"
May 27 07:04:25.780: INFO: Pod "pod-projected-configmaps-5a7b61df-57a6-45e6-b4c5-822e0c11fef0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.551276ms
May 27 07:04:27.802: INFO: Pod "pod-projected-configmaps-5a7b61df-57a6-45e6-b4c5-822e0c11fef0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033406563s
May 27 07:04:29.818: INFO: Pod "pod-projected-configmaps-5a7b61df-57a6-45e6-b4c5-822e0c11fef0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049439122s
May 27 07:04:31.850: INFO: Pod "pod-projected-configmaps-5a7b61df-57a6-45e6-b4c5-822e0c11fef0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.081020955s
STEP: Saw pod success
May 27 07:04:31.850: INFO: Pod "pod-projected-configmaps-5a7b61df-57a6-45e6-b4c5-822e0c11fef0" satisfied condition "Succeeded or Failed"
May 27 07:04:31.855: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-configmaps-5a7b61df-57a6-45e6-b4c5-822e0c11fef0 container agnhost-container: <nil>
STEP: delete the pod
May 27 07:04:31.907: INFO: Waiting for pod pod-projected-configmaps-5a7b61df-57a6-45e6-b4c5-822e0c11fef0 to disappear
May 27 07:04:31.913: INFO: Pod pod-projected-configmaps-5a7b61df-57a6-45e6-b4c5-822e0c11fef0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
May 27 07:04:31.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9644" for this suite.

• [SLOW TEST:6.262 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":343,"skipped":6488,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:04:31.937: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-fc665a0f-b2e5-456f-9249-e2c562d9e536
STEP: Creating a pod to test consume configMaps
May 27 07:04:32.024: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-21fe415f-173c-4616-93da-2854232c3180" in namespace "projected-8941" to be "Succeeded or Failed"
May 27 07:04:32.049: INFO: Pod "pod-projected-configmaps-21fe415f-173c-4616-93da-2854232c3180": Phase="Pending", Reason="", readiness=false. Elapsed: 25.416245ms
May 27 07:04:34.069: INFO: Pod "pod-projected-configmaps-21fe415f-173c-4616-93da-2854232c3180": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045372989s
May 27 07:04:36.147: INFO: Pod "pod-projected-configmaps-21fe415f-173c-4616-93da-2854232c3180": Phase="Pending", Reason="", readiness=false. Elapsed: 4.122937782s
May 27 07:04:38.160: INFO: Pod "pod-projected-configmaps-21fe415f-173c-4616-93da-2854232c3180": Phase="Pending", Reason="", readiness=false. Elapsed: 6.136384772s
May 27 07:04:40.189: INFO: Pod "pod-projected-configmaps-21fe415f-173c-4616-93da-2854232c3180": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.164885813s
STEP: Saw pod success
May 27 07:04:40.189: INFO: Pod "pod-projected-configmaps-21fe415f-173c-4616-93da-2854232c3180" satisfied condition "Succeeded or Failed"
May 27 07:04:40.196: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-projected-configmaps-21fe415f-173c-4616-93da-2854232c3180 container agnhost-container: <nil>
STEP: delete the pod
May 27 07:04:40.283: INFO: Waiting for pod pod-projected-configmaps-21fe415f-173c-4616-93da-2854232c3180 to disappear
May 27 07:04:40.291: INFO: Pod pod-projected-configmaps-21fe415f-173c-4616-93da-2854232c3180 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
May 27 07:04:40.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8941" for this suite.

• [SLOW TEST:8.386 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":344,"skipped":6499,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:04:40.324: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-1877/configmap-test-768ab1bc-650c-47a4-992d-06b228747d44
STEP: Creating a pod to test consume configMaps
May 27 07:04:40.429: INFO: Waiting up to 5m0s for pod "pod-configmaps-83cd4fd3-aea8-4543-b0fb-93c2ba65ecc4" in namespace "configmap-1877" to be "Succeeded or Failed"
May 27 07:04:40.441: INFO: Pod "pod-configmaps-83cd4fd3-aea8-4543-b0fb-93c2ba65ecc4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.099828ms
May 27 07:04:42.465: INFO: Pod "pod-configmaps-83cd4fd3-aea8-4543-b0fb-93c2ba65ecc4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035559278s
May 27 07:04:44.479: INFO: Pod "pod-configmaps-83cd4fd3-aea8-4543-b0fb-93c2ba65ecc4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049681877s
May 27 07:04:46.493: INFO: Pod "pod-configmaps-83cd4fd3-aea8-4543-b0fb-93c2ba65ecc4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.063236525s
STEP: Saw pod success
May 27 07:04:46.493: INFO: Pod "pod-configmaps-83cd4fd3-aea8-4543-b0fb-93c2ba65ecc4" satisfied condition "Succeeded or Failed"
May 27 07:04:46.499: INFO: Trying to get logs from node bohc9zohd7ee-3 pod pod-configmaps-83cd4fd3-aea8-4543-b0fb-93c2ba65ecc4 container env-test: <nil>
STEP: delete the pod
May 27 07:04:46.552: INFO: Waiting for pod pod-configmaps-83cd4fd3-aea8-4543-b0fb-93c2ba65ecc4 to disappear
May 27 07:04:46.558: INFO: Pod pod-configmaps-83cd4fd3-aea8-4543-b0fb-93c2ba65ecc4 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
May 27 07:04:46.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1877" for this suite.

• [SLOW TEST:6.259 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":345,"skipped":6521,"failed":0}
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:04:46.584: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
May 27 07:04:46.762: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"72c0cb77-00ac-4864-822d-4bf526a91eac", Controller:(*bool)(0xc000ad54b6), BlockOwnerDeletion:(*bool)(0xc000ad54b7)}}
May 27 07:04:46.788: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"24cd8568-e397-47db-b0f2-6dd934c7dd61", Controller:(*bool)(0xc00617f2c6), BlockOwnerDeletion:(*bool)(0xc00617f2c7)}}
May 27 07:04:46.798: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"de526a99-3f38-41df-ae4e-7da050df7bfb", Controller:(*bool)(0xc00617f59e), BlockOwnerDeletion:(*bool)(0xc00617f59f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
May 27 07:04:51.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2865" for this suite.

• [SLOW TEST:5.336 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":356,"completed":346,"skipped":6521,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:04:51.921: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5158
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
May 27 07:04:52.042: INFO: Found 0 stateful pods, waiting for 3
May 27 07:05:02.124: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 27 07:05:02.125: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 27 07:05:02.125: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
May 27 07:05:12.108: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 27 07:05:12.109: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 27 07:05:12.109: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
May 27 07:05:12.284: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 27 07:05:22.397: INFO: Updating stateful set ss2
May 27 07:05:22.415: INFO: Waiting for Pod statefulset-5158/ss2-2 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
STEP: Restoring Pods to the correct revision when they are deleted
May 27 07:05:32.652: INFO: Found 2 stateful pods, waiting for 3
May 27 07:05:42.689: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 27 07:05:42.689: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 27 07:05:42.689: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 27 07:05:42.739: INFO: Updating stateful set ss2
May 27 07:05:42.751: INFO: Waiting for Pod statefulset-5158/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
May 27 07:05:52.834: INFO: Updating stateful set ss2
May 27 07:05:52.868: INFO: Waiting for StatefulSet statefulset-5158/ss2 to complete update
May 27 07:05:52.868: INFO: Waiting for Pod statefulset-5158/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May 27 07:06:02.920: INFO: Deleting all statefulset in ns statefulset-5158
May 27 07:06:02.925: INFO: Scaling statefulset ss2 to 0
May 27 07:06:12.989: INFO: Waiting for statefulset status.replicas updated to 0
May 27 07:06:12.996: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
May 27 07:06:13.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5158" for this suite.

• [SLOW TEST:81.129 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":356,"completed":347,"skipped":6544,"failed":0}
SSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:06:13.057: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
May 27 07:06:17.670: INFO: Successfully updated pod "adopt-release-4mkln"
STEP: Checking that the Job readopts the Pod
May 27 07:06:17.671: INFO: Waiting up to 15m0s for pod "adopt-release-4mkln" in namespace "job-4964" to be "adopted"
May 27 07:06:17.680: INFO: Pod "adopt-release-4mkln": Phase="Running", Reason="", readiness=true. Elapsed: 9.010789ms
May 27 07:06:19.694: INFO: Pod "adopt-release-4mkln": Phase="Running", Reason="", readiness=true. Elapsed: 2.022888695s
May 27 07:06:19.694: INFO: Pod "adopt-release-4mkln" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
May 27 07:06:20.221: INFO: Successfully updated pod "adopt-release-4mkln"
STEP: Checking that the Job releases the Pod
May 27 07:06:20.221: INFO: Waiting up to 15m0s for pod "adopt-release-4mkln" in namespace "job-4964" to be "released"
May 27 07:06:20.229: INFO: Pod "adopt-release-4mkln": Phase="Running", Reason="", readiness=true. Elapsed: 7.614975ms
May 27 07:06:22.250: INFO: Pod "adopt-release-4mkln": Phase="Running", Reason="", readiness=true. Elapsed: 2.028351705s
May 27 07:06:22.250: INFO: Pod "adopt-release-4mkln" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
May 27 07:06:22.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4964" for this suite.

• [SLOW TEST:9.222 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":356,"completed":348,"skipped":6550,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:06:22.280: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 27 07:06:24.475: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 27 07:06:26.510: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 7, 6, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 7, 6, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 7, 6, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 7, 6, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 27 07:06:28.527: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.May, 27, 7, 6, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 7, 6, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.May, 27, 7, 6, 24, 0, time.Local), LastTransitionTime:time.Date(2022, time.May, 27, 7, 6, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f978cd6d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 27 07:06:31.552: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
May 27 07:06:31.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2409" for this suite.
STEP: Destroying namespace "webhook-2409-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:9.518 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":356,"completed":349,"skipped":6551,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:06:31.800: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 07:06:32.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7145" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760
•{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":356,"completed":350,"skipped":6555,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:06:32.380: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 27 07:06:41.679: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
May 27 07:06:41.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9082" for this suite.

• [SLOW TEST:9.372 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":351,"skipped":6573,"failed":0}
SSSSSS
------------------------------
[sig-network] Services 
  should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:06:41.757: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Service
STEP: watching for the Service to be added
May 27 07:06:41.848: INFO: Found Service test-service-92gtj in namespace services-3029 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
May 27 07:06:41.848: INFO: Service test-service-92gtj created
STEP: Getting /status
May 27 07:06:41.856: INFO: Service test-service-92gtj has LoadBalancer: {[]}
STEP: patching the ServiceStatus
STEP: watching for the Service to be patched
May 27 07:06:41.899: INFO: observed Service test-service-92gtj in namespace services-3029 with annotations: map[] & LoadBalancer: {[]}
May 27 07:06:41.899: INFO: Found Service test-service-92gtj in namespace services-3029 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
May 27 07:06:41.899: INFO: Service test-service-92gtj has service status patched
STEP: updating the ServiceStatus
May 27 07:06:41.930: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated
May 27 07:06:41.936: INFO: Observed Service test-service-92gtj in namespace services-3029 with annotations: map[] & Conditions: {[]}
May 27 07:06:41.936: INFO: Observed event: &Service{ObjectMeta:{test-service-92gtj  services-3029  60eed9a3-02a1-4108-89c9-1301de19349d 40772 0 2022-05-27 07:06:41 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2022-05-27 07:06:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-05-27 07:06:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.59.245,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.59.245],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
May 27 07:06:41.937: INFO: Found Service test-service-92gtj in namespace services-3029 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
May 27 07:06:41.939: INFO: Service test-service-92gtj has service status updated
STEP: patching the service
STEP: watching for the Service to be patched
May 27 07:06:41.974: INFO: observed Service test-service-92gtj in namespace services-3029 with labels: map[test-service-static:true]
May 27 07:06:41.974: INFO: observed Service test-service-92gtj in namespace services-3029 with labels: map[test-service-static:true]
May 27 07:06:41.975: INFO: observed Service test-service-92gtj in namespace services-3029 with labels: map[test-service-static:true]
May 27 07:06:41.975: INFO: Found Service test-service-92gtj in namespace services-3029 with labels: map[test-service:patched test-service-static:true]
May 27 07:06:41.975: INFO: Service test-service-92gtj patched
STEP: deleting the service
STEP: watching for the Service to be deleted
May 27 07:06:42.005: INFO: Observed event: ADDED
May 27 07:06:42.005: INFO: Observed event: MODIFIED
May 27 07:06:42.005: INFO: Observed event: MODIFIED
May 27 07:06:42.005: INFO: Observed event: MODIFIED
May 27 07:06:42.006: INFO: Found Service test-service-92gtj in namespace services-3029 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
May 27 07:06:42.006: INFO: Service test-service-92gtj deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 07:06:42.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3029" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760
•{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","total":356,"completed":352,"skipped":6579,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:06:42.046: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Pod
STEP: Reading file content from the nginx-container
May 27 07:06:46.210: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-314 PodName:pod-sharedvolume-06127efc-03bb-4976-8d1c-2f95d1df50c4 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May 27 07:06:46.210: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
May 27 07:06:46.212: INFO: ExecWithOptions: Clientset creation
May 27 07:06:46.212: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-314/pods/pod-sharedvolume-06127efc-03bb-4976-8d1c-2f95d1df50c4/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
May 27 07:06:46.347: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
May 27 07:06:46.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-314" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":356,"completed":353,"skipped":6583,"failed":0}
SSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:06:46.371: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
May 27 07:06:46.438: INFO: Waiting up to 5m0s for pod "downward-api-cba658be-d6f5-43b9-b9e7-cb2822ef700f" in namespace "downward-api-3435" to be "Succeeded or Failed"
May 27 07:06:46.445: INFO: Pod "downward-api-cba658be-d6f5-43b9-b9e7-cb2822ef700f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.691549ms
May 27 07:06:48.461: INFO: Pod "downward-api-cba658be-d6f5-43b9-b9e7-cb2822ef700f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022126212s
May 27 07:06:50.480: INFO: Pod "downward-api-cba658be-d6f5-43b9-b9e7-cb2822ef700f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041519698s
STEP: Saw pod success
May 27 07:06:50.480: INFO: Pod "downward-api-cba658be-d6f5-43b9-b9e7-cb2822ef700f" satisfied condition "Succeeded or Failed"
May 27 07:06:50.492: INFO: Trying to get logs from node bohc9zohd7ee-1 pod downward-api-cba658be-d6f5-43b9-b9e7-cb2822ef700f container dapi-container: <nil>
STEP: delete the pod
May 27 07:06:50.606: INFO: Waiting for pod downward-api-cba658be-d6f5-43b9-b9e7-cb2822ef700f to disappear
May 27 07:06:50.613: INFO: Pod downward-api-cba658be-d6f5-43b9-b9e7-cb2822ef700f no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
May 27 07:06:50.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3435" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":356,"completed":354,"skipped":6587,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:06:50.638: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:756
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1520
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-1520
I0527 07:06:50.801532      15 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1520, replica count: 2
I0527 07:06:53.852422      15 runners.go:193] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0527 07:06:56.853126      15 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 27 07:06:56.853: INFO: Creating new exec pod
May 27 07:07:03.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-1520 exec execpod5s2c6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May 27 07:07:04.494: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May 27 07:07:04.494: INFO: stdout: "externalname-service-qdm4n"
May 27 07:07:04.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3813432716 --namespace=services-1520 exec execpod5s2c6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.3.108 80'
May 27 07:07:04.814: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.3.108 80\nConnection to 10.233.3.108 80 port [tcp/http] succeeded!\n"
May 27 07:07:04.814: INFO: stdout: "externalname-service-fnfdm"
May 27 07:07:04.814: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
May 27 07:07:04.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1520" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:760

• [SLOW TEST:14.291 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":356,"completed":355,"skipped":6603,"failed":0}
SSSSSS
------------------------------
[sig-node] PodTemplates 
  should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
May 27 07:07:04.930: INFO: >>> kubeConfig: /tmp/kubeconfig-3813432716
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a pod template
STEP: Replace a pod template
May 27 07:07:05.057: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
May 27 07:07:05.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6892" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","total":356,"completed":356,"skipped":6609,"failed":0}
May 27 07:07:05.096: INFO: Running AfterSuite actions on all nodes
May 27 07:07:05.096: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func19.2
May 27 07:07:05.096: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
May 27 07:07:05.096: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
May 27 07:07:05.096: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
May 27 07:07:05.096: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
May 27 07:07:05.097: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
May 27 07:07:05.097: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
May 27 07:07:05.097: INFO: Running AfterSuite actions on node 1
May 27 07:07:05.097: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/sonobuoy/results/junit_01.xml
{"msg":"Test Suite completed","total":356,"completed":356,"skipped":6609,"failed":0}

Ran 356 of 6965 Specs in 6612.393 seconds
SUCCESS! -- 356 Passed | 0 Failed | 0 Pending | 6609 Skipped
PASS

Ginkgo ran 1 suite in 1h50m15.832634449s
Test Suite Passed
